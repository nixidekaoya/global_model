Optimizer: SGD
Learning Rate: 0.05
Momentum: 0.9
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.001727086873771623
Epoch: 0 , Test Loss: 0.0015716640300583093
Epoch: 0 , D11: 0.7067497658276715 , D22: 1.3807369894776544
Epoch: 0 , D11*: 0.7091293489158211, D22*: 1.3785401656508283, D12*: 1.432168371334666
Epoch: 0 , Coefficient 1: 1.003366938629775 , Coefficient 2: 0.9984089483778824 , Coefficient 3: 0.728849189924893
Epoch: 1 , Train Loss: 0.0005054851429158589
Epoch: 1 , Test Loss: 0.00045633852889295675
Epoch: 1 , D11: 0.5338812541173394 , D22: 0.8361086262112745
Epoch: 1 , D11*: 0.5345812437019521, D22*: 0.8351069319374147, D12*: 1.3808857580965368
Epoch: 1 , Coefficient 1: 1.0013111334762446 , Coefficient 2: 0.9988019567763595 , Coefficient 3: 0.4959455072979371
Epoch: 2 , Train Loss: 0.0002431941363920486
Epoch: 2 , Test Loss: 0.0002305994097943767
Epoch: 2 , D11: 0.5624691251395427 , D22: 0.7479348862470718
Epoch: 2 , D11*: 0.5630435969474092, D22*: 0.7470740373554104, D12*: 1.369182818922045
Epoch: 2 , Coefficient 1: 1.0010213392739096 , Coefficient 2: 0.998849032305498 , Coefficient 3: 0.47843049744601407
Epoch: 3 , Train Loss: 0.0001491170284589316
Epoch: 3 , Test Loss: 0.0001443817697290797
Epoch: 3 , D11: 0.5337395419225988 , D22: 0.6560444181418345
Epoch: 3 , D11*: 0.5342762902244372, D22*: 0.6552353503950447, D12*: 1.3669075227598804
Epoch: 3 , Coefficient 1: 1.0010056371313714 , Coefficient 2: 0.9987667485243128 , Coefficient 3: 0.4351105033856921
Epoch: 4 , Train Loss: 0.00011487819959766056
Epoch: 4 , Test Loss: 0.00011330283784482162
Epoch: 4 , D11: 0.5137616123953272 , D22: 0.632715493167851
Epoch: 4 , D11*: 0.5141014353971344, D22*: 0.6321981197101204, D12*: 1.490111533025296
Epoch: 4 , Coefficient 1: 1.0006614410139028 , Coefficient 2: 0.9991822968406538 , Coefficient 3: 0.384635488586543
Epoch: 5 , Train Loss: 0.00010240272916453249
Epoch: 5 , Test Loss: 0.00010187753991922363
Epoch: 5 , D11: 0.5649450381459474 , D22: 0.5995784485752308
Epoch: 5 , D11*: 0.5653016194625317, D22*: 0.5991761226041629, D12*: 1.401521851940501
Epoch: 5 , Coefficient 1: 1.000631178774053 , Coefficient 2: 0.9993289852695273 , Coefficient 3: 0.41543331645325293
Epoch: 6 , Train Loss: 9.716082347877092e-05
Epoch: 6 , Test Loss: 9.69944894866785e-05
Epoch: 6 , D11: 0.5617784545520144 , D22: 0.6315836543912426
Epoch: 6 , D11*: 0.5619576278945764, D22*: 0.6311245109267887, D12*: 1.375690862066999
Epoch: 6 , Coefficient 1: 1.0003189395056187 , Coefficient 2: 0.9992730282659127 , Coefficient 3: 0.4336301751066147
Epoch: 7 , Train Loss: 9.456138777422894e-05
Epoch: 7 , Test Loss: 9.455642949906178e-05
Epoch: 7 , D11: 0.501971372068201 , D22: 0.6207660767967976
Epoch: 7 , D11*: 0.5021798644164562, D22*: 0.6205318307636283, D12*: 1.406438588997679
Epoch: 7 , Coefficient 1: 1.0004153470892099 , Coefficient 2: 0.9996226500739569 , Coefficient 3: 0.3991328537068238
Epoch: 8 , Train Loss: 9.311347802795354e-05
Epoch: 8 , Test Loss: 9.317046323558316e-05
Epoch: 8 , D11: 0.5304528997423863 , D22: 0.5713030431657555
Epoch: 8 , D11*: 0.5307206865904559, D22*: 0.5710823612841163, D12*: 1.361926400102579
Epoch: 8 , Coefficient 1: 1.0005048268153491 , Coefficient 2: 0.9996137218516877 , Coefficient 3: 0.40450168518342305
Epoch: 9 , Train Loss: 9.214215150641393e-05
Epoch: 9 , Test Loss: 9.22305147338193e-05
Epoch: 9 , D11: 0.5443193757898627 , D22: 0.6207926781917783
Epoch: 9 , D11*: 0.5445049830312685, D22*: 0.6205995349684931, D12*: 1.4162245506257596
Epoch: 9 , Coefficient 1: 1.0003409895911504 , Coefficient 2: 0.999688876447693 , Coefficient 3: 0.41134173160780174
Epoch: 10 , Train Loss: 9.14078292200429e-05
Epoch: 10 , Test Loss: 9.151556482393061e-05
Epoch: 10 , D11: 0.5336965110030465 , D22: 0.5835576910082314
Epoch: 10 , D11*: 0.5339895428871287, D22*: 0.5834072903124282, D12*: 1.4076036388147943
Epoch: 10 , Coefficient 1: 1.0005490608951735 , Coefficient 2: 0.9997422693623601 , Coefficient 3: 0.3969145867441803
Epoch: 11 , Train Loss: 9.080720230595033e-05
Epoch: 11 , Test Loss: 9.092171824886463e-05
Epoch: 11 , D11: 0.5442375313180544 , D22: 0.589381681044962
Epoch: 11 , D11*: 0.5443555299685044, D22*: 0.5891833972054944, D12*: 1.4571116247472342
Epoch: 11 , Coefficient 1: 1.0002168146143178 , Coefficient 2: 0.9996635731210443 , Coefficient 3: 0.38896777292907614
Epoch: 12 , Train Loss: 9.028326394727631e-05
Epoch: 12 , Test Loss: 9.041352517378981e-05
Epoch: 12 , D11: 0.5374083724251452 , D22: 0.5755174279508879
Epoch: 12 , D11*: 0.537579429172611, D22*: 0.5753625990518855, D12*: 1.433905332520573
Epoch: 12 , Coefficient 1: 1.0003182993720288 , Coefficient 2: 0.9997309744388564 , Coefficient 3: 0.3880807201784112
Epoch: 13 , Train Loss: 8.980865205849114e-05
Epoch: 13 , Test Loss: 8.99563991406467e-05
Epoch: 13 , D11: 0.530708965557031 , D22: 0.5531831113185216
Epoch: 13 , D11*: 0.5308205409688403, D22*: 0.553103241891861, D12*: 1.431926225826598
Epoch: 13 , Coefficient 1: 1.0002102384151212 , Coefficient 2: 0.9998556184651585 , Coefficient 3: 0.37848450685194773
Epoch: 14 , Train Loss: 8.939285031046891e-05
Epoch: 14 , Test Loss: 8.95230081223417e-05
Epoch: 14 , D11: 0.5315393334526286 , D22: 0.6087534524711837
Epoch: 14 , D11*: 0.5316261315603982, D22*: 0.6086849664294084, D12*: 1.4158452504451984
Epoch: 14 , Coefficient 1: 1.0001632957380704 , Coefficient 2: 0.9998874979000163 , Coefficient 3: 0.40269623309159214
Epoch: 15 , Train Loss: 8.899042132834439e-05
Epoch: 15 , Test Loss: 8.914224903273861e-05
Epoch: 15 , D11: 0.5427482593008136 , D22: 0.6082879532080084
Epoch: 15 , D11*: 0.5427884988060842, D22*: 0.6082385769342092, D12*: 1.4375184429862964
Epoch: 15 , Coefficient 1: 1.0000741402751294 , Coefficient 2: 0.9999188274672566 , Coefficient 3: 0.4003521072568479
Epoch: 16 , Train Loss: 8.860454639543604e-05
Epoch: 16 , Test Loss: 8.876006042701194e-05
Epoch: 16 , D11: 0.5466517521219313 , D22: 0.633745403422749
Epoch: 16 , D11*: 0.5466675844291015, D22*: 0.6337341829840933, D12*: 1.442015039942394
Epoch: 16 , Coefficient 1: 1.000028962327677 , Coefficient 2: 0.9999822950374155 , Coefficient 3: 0.40928899308163585
Epoch: 17 , Train Loss: 8.821672626145298e-05
Epoch: 17 , Test Loss: 8.839520412147977e-05
Epoch: 17 , D11: 0.5364513885804449 , D22: 0.594343351804337
Epoch: 17 , D11*: 0.5364539948011355, D22*: 0.594339352235295, D12*: 1.3944513400284033
Epoch: 17 , Coefficient 1: 1.000004858260685 , Coefficient 2: 0.9999932706085972 , Coefficient 3: 0.4054617449087171
Epoch: 18 , Train Loss: 8.785671979021572e-05
Epoch: 18 , Test Loss: 8.804357874905692e-05
Epoch: 18 , D11: 0.5274974918982587 , D22: 0.649572076330467
Epoch: 18 , D11*: 0.5274977614713007, D22*: 0.6495716988231318, D12*: 1.4117187101769095
Epoch: 18 , Coefficient 1: 1.000000511041372 , Coefficient 2: 0.999999418836879 , Coefficient 3: 0.4168923496618275
Epoch: 19 , Train Loss: 8.75259750169789e-05
Epoch: 19 , Test Loss: 8.76754567725584e-05
Epoch: 19 , D11: 0.5421324129731492 , D22: 0.6147459174557717
Epoch: 19 , D11*: 0.5421324129731492, D22*: 0.6147459174557717, D12*: 1.4072576447681509
Epoch: 19 , Coefficient 1: 1.0 , Coefficient 2: 1.0 , Coefficient 3: 0.4110399878550738
Epoch: 20 , Train Loss: 8.722855941232411e-05
Epoch: 20 , Test Loss: 8.742472203302894e-05
Epoch: 20 , D11: 0.5526034132230624 , D22: 0.61766022988442
Epoch: 20 , D11*: 0.5526034195669176, D22*: 0.6176602191974131, D12*: 1.4318263248643128
Epoch: 20 , Coefficient 1: 1.000000011479942 , Coefficient 2: 0.9999999826975958 , Coefficient 3: 0.40866116876124303
Epoch: 21 , Train Loss: 8.694145806475718e-05
Epoch: 21 , Test Loss: 8.712342164071742e-05
Epoch: 21 , D11: 0.5444875162036538 , D22: 0.5580857781953008
Epoch: 21 , D11*: 0.5444875162036538, D22*: 0.5580857752061331, D12*: 1.4074313746894969
Epoch: 21 , Coefficient 1: 1.0 , Coefficient 2: 0.999999994643892 , Coefficient 3: 0.39169699895777627
Epoch: 22 , Train Loss: 8.665106025691784e-05
Epoch: 22 , Test Loss: 8.682760164083443e-05
Epoch: 22 , D11: 0.5480593917885427 , D22: 0.6177333751672879
Epoch: 22 , D11*: 0.5480593875734684, D22*: 0.6177333774677154, D12*: 1.4299258832316768
Epoch: 22 , Coefficient 1: 0.9999999923090921 , Coefficient 2: 1.0000000037239813 , Coefficient 3: 0.40764097591074305
Epoch: 23 , Train Loss: 8.636852951603941e-05
Epoch: 23 , Test Loss: 8.655769606411923e-05
Epoch: 23 , D11: 0.5160719115033942 , D22: 0.6164627664531263
Epoch: 23 , D11*: 0.5160719115033942, D22*: 0.6164627664531263, D12*: 1.3440949061698946
Epoch: 23 , Coefficient 1: 1.0 , Coefficient 2: 1.0 , Coefficient 3: 0.4213001153258471
Epoch: 24 , Train Loss: 8.611928605205323e-05
Epoch: 24 , Test Loss: 8.628888957900929e-05
Epoch: 24 , D11: 0.57381823529286 , D22: 0.5925438644735969
Epoch: 24 , D11*: 0.5738182354670314, D22*: 0.5925438551473766, D12*: 1.4287666287066694
Epoch: 24 , Coefficient 1: 1.0000000003035305 , Coefficient 2: 0.9999999842607091 , Coefficient 3: 0.4081709591965372
Epoch: 25 , Train Loss: 8.585979288509407e-05
Epoch: 25 , Test Loss: 8.603459020087027e-05
Epoch: 25 , D11: 0.5496523320563546 , D22: 0.6100628737661958
Epoch: 25 , D11*: 0.5496523373708264, D22*: 0.6100628724595935, D12*: 1.403318728898329
Epoch: 25 , Coefficient 1: 1.000000009668788 , Coefficient 2: 0.9999999978582497 , Coefficient 3: 0.41320449372925094
Epoch: 26 , Train Loss: 8.560601290337217e-05
Epoch: 26 , Test Loss: 8.581392534833868e-05
Epoch: 26 , D11: 0.5475687411043666 , D22: 0.621736060120914
Epoch: 26 , D11*: 0.5475687436643001, D22*: 0.6217360594819048, D12*: 1.4524085023512328
Epoch: 26 , Coefficient 1: 1.0000000046750905 , Coefficient 2: 0.9999999989722179 , Coefficient 3: 0.4025399194693762
Epoch: 27 , Train Loss: 8.538414094073232e-05
Epoch: 27 , Test Loss: 8.560313483467325e-05
Epoch: 27 , D11: 0.5493770623448142 , D22: 0.600409416457692
Epoch: 27 , D11*: 0.5493770630333251, D22*: 0.6004094155018397, D12*: 1.409928775621056
Epoch: 27 , Coefficient 1: 1.0000000012532575 , Coefficient 2: 0.9999999984079991 , Coefficient 3: 0.40774629840032106
Epoch: 28 , Train Loss: 8.514933314181689e-05
Epoch: 28 , Test Loss: 8.53531937333173e-05
Epoch: 28 , D11: 0.5372833709167677 , D22: 0.567571525923905
Epoch: 28 , D11*: 0.5372833718690105, D22*: 0.567571525923905, D12*: 1.3727839885432862
Epoch: 28 , Coefficient 1: 1.000000001772329 , Coefficient 2: 1.0 , Coefficient 3: 0.4024139657125953
Epoch: 29 , Train Loss: 8.491047605712083e-05
Epoch: 29 , Test Loss: 8.512512312154289e-05
Epoch: 29 , D11: 0.5627949422812668 , D22: 0.5566427575826959
Epoch: 29 , D11*: 0.5627949603609623, D22*: 0.5566427416119611, D12*: 1.3872184248214616
Epoch: 29 , Coefficient 1: 1.0000000321248366 , Coefficient 2: 0.999999971308825 , Coefficient 3: 0.40348285531061834
