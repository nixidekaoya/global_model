Optimizer: SGD
Learning Rate: 0.05
Momentum: 0.9
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.0019710018193582076
Epoch: 0 , Test Loss: 0.0018238600420765582
Epoch: 0 , D11: 0.8508823463772611 , D22: 1.3698403570350677
Epoch: 0 , D11*: 0.8553059191761145, D22*: 1.3677366233383441, D12*: 1.5360510805624956
Epoch: 0 , Coefficient 1: 1.0051988066478137 , Coefficient 2: 0.9984642490010464 , Coefficient 3: 0.7236225964895613
Epoch: 1 , Train Loss: 0.0005626698360902083
Epoch: 1 , Test Loss: 0.0004909398865391267
Epoch: 1 , D11: 0.5149595787442871 , D22: 0.9498754673602218
Epoch: 1 , D11*: 0.5165058285686454, D22*: 0.94741847502548, D12*: 1.420351786121102
Epoch: 1 , Coefficient 1: 1.0030026625160149 , Coefficient 2: 0.9974133532034785 , Coefficient 3: 0.5153386357868488
Epoch: 2 , Train Loss: 0.0002246306384149648
Epoch: 2 , Test Loss: 0.00021076424823259009
Epoch: 2 , D11: 0.4992626824253544 , D22: 0.736137971553216
Epoch: 2 , D11*: 0.49999364906610533, D22*: 0.7347143647994763, D12*: 1.4343254644072434
Epoch: 2 , Coefficient 1: 1.0014640922834448 , Coefficient 2: 0.998066114222126 , Coefficient 3: 0.4304141718545878
Epoch: 3 , Train Loss: 0.00012657655982329746
Epoch: 3 , Test Loss: 0.00012205199196177998
Epoch: 3 , D11: 0.5347424904243989 , D22: 0.62672065653124
Epoch: 3 , D11*: 0.535060407239635, D22*: 0.6255321498430312, D12*: 1.3844580141345455
Epoch: 3 , Coefficient 1: 1.000594523197481 , Coefficient 2: 0.9981036101557799 , Coefficient 3: 0.4191505069975623
Epoch: 4 , Train Loss: 9.660301144249388e-05
Epoch: 4 , Test Loss: 9.540389301255349e-05
Epoch: 4 , D11: 0.5337032463025441 , D22: 0.586724123843326
Epoch: 4 , D11*: 0.5340870924013135, D22*: 0.5858035537813672, D12*: 1.4420800422797313
Epoch: 4 , Coefficient 1: 1.0007192125988154 , Coefficient 2: 0.9984310001505843 , Coefficient 3: 0.3882900440159641
Epoch: 5 , Train Loss: 8.792542769442665e-05
Epoch: 5 , Test Loss: 8.762722174433292e-05
Epoch: 5 , D11: 0.5556634461410156 , D22: 0.5842921500101412
Epoch: 5 , D11*: 0.5558562625685374, D22*: 0.5837982971756331, D12*: 1.4764022219692121
Epoch: 5 , Coefficient 1: 1.000347002180656 , Coefficient 2: 0.9991547844096493 , Coefficient 3: 0.38595666641035986
Epoch: 6 , Train Loss: 8.512979328334039e-05
Epoch: 6 , Test Loss: 8.509295902331362e-05
Epoch: 6 , D11: 0.5794232713236958 , D22: 0.5928419403802033
Epoch: 6 , D11*: 0.579760802606894, D22*: 0.5925659595522424, D12*: 1.4892289598356976
Epoch: 6 , Coefficient 1: 1.0005825297324134 , Coefficient 2: 0.9995344782324546 , Coefficient 3: 0.39360192212770156
Epoch: 7 , Train Loss: 8.40859083327814e-05
Epoch: 7 , Test Loss: 8.414845459774372e-05
Epoch: 7 , D11: 0.5277738202983419 , D22: 0.5939618745078045
Epoch: 7 , D11*: 0.528079255226995, D22*: 0.5936386551442739, D12*: 1.400640932753398
Epoch: 7 , Coefficient 1: 1.000578723151672 , Coefficient 2: 0.9994558247298307 , Coefficient 3: 0.40043021881638907
Epoch: 8 , Train Loss: 8.360859012464062e-05
Epoch: 8 , Test Loss: 8.369086487218737e-05
Epoch: 8 , D11: 0.52766666795368 , D22: 0.5369447878721735
Epoch: 8 , D11*: 0.5279318965079963, D22*: 0.5366862120897743, D12*: 1.4687079334383326
Epoch: 8 , Coefficient 1: 1.000502644132033 , Coefficient 2: 0.9995184313392371 , Coefficient 3: 0.3624335663883276
Epoch: 9 , Train Loss: 8.331799103289084e-05
Epoch: 9 , Test Loss: 8.341909320879493e-05
Epoch: 9 , D11: 0.5233731344564687 , D22: 0.5898183129293947
Epoch: 9 , D11*: 0.5236010485606253, D22*: 0.589515992598055, D12*: 1.417519617130407
Epoch: 9 , Coefficient 1: 1.000435471538663 , Coefficient 2: 0.9994874348172775 , Coefficient 3: 0.3926284432705235
Epoch: 10 , Train Loss: 8.311009491699223e-05
Epoch: 10 , Test Loss: 8.321678660577165e-05
Epoch: 10 , D11: 0.5360071908127989 , D22: 0.5870743383938496
Epoch: 10 , D11*: 0.5361290362780665, D22*: 0.586821874993303, D12*: 1.458883558950259
Epoch: 10 , Coefficient 1: 1.0002273205795669 , Coefficient 2: 0.9995699634883763 , Coefficient 3: 0.3848665318016846
Epoch: 11 , Train Loss: 8.293809330134537e-05
Epoch: 11 , Test Loss: 8.305507825280075e-05
Epoch: 11 , D11: 0.5285538011841675 , D22: 0.5509179420789005
Epoch: 11 , D11*: 0.5287427754632672, D22*: 0.5507644613242292, D12*: 1.4431941705442948
Epoch: 11 , Coefficient 1: 1.00035753082974 , Coefficient 2: 0.9997214090467045 , Coefficient 3: 0.37399930612952953
Epoch: 12 , Train Loss: 8.278933169312949e-05
Epoch: 12 , Test Loss: 8.291567490377925e-05
Epoch: 12 , D11: 0.5424355656628241 , D22: 0.571979311188493
Epoch: 12 , D11*: 0.5425461159448581, D22*: 0.571829153627003, D12*: 1.45129683117566
Epoch: 12 , Coefficient 1: 1.0002038035280723 , Coefficient 2: 0.999737477285362 , Coefficient 3: 0.38392396566770326
Epoch: 13 , Train Loss: 8.264575754765248e-05
Epoch: 13 , Test Loss: 8.277994343225146e-05
Epoch: 13 , D11: 0.5439808335029976 , D22: 0.5956965134708008
Epoch: 13 , D11*: 0.5440716967996023, D22*: 0.5955896864025098, D12*: 1.4742151939033876
Epoch: 13 , Coefficient 1: 1.0001670340037894 , Coefficient 2: 0.9998206686359996 , Coefficient 3: 0.3865315552014313
Epoch: 14 , Train Loss: 8.250272349760054e-05
Epoch: 14 , Test Loss: 8.261997034423986e-05
Epoch: 14 , D11: 0.5087753502237372 , D22: 0.5366559836035961
Epoch: 14 , D11*: 0.5088681709996092, D22*: 0.5365621793476578, D12*: 1.4649296138673367
Epoch: 14 , Coefficient 1: 1.00018243960882 , Coefficient 2: 0.9998252059814774 , Coefficient 3: 0.3568193107883819
Epoch: 15 , Train Loss: 8.234963033610258e-05
Epoch: 15 , Test Loss: 8.248942425852874e-05
Epoch: 15 , D11: 0.5285688302347598 , D22: 0.5933808864989857
Epoch: 15 , D11*: 0.5286174304704023, D22*: 0.5933353770065148, D12*: 1.4457007776590836
Epoch: 15 , Coefficient 1: 1.000091946843746 , Coefficient 2: 0.9999233047549958 , Coefficient 3: 0.3880307823080833
Epoch: 16 , Train Loss: 8.219468879324268e-05
Epoch: 16 , Test Loss: 8.234795718453823e-05
Epoch: 16 , D11: 0.5512454725409839 , D22: 0.5885517384675423
Epoch: 16 , D11*: 0.5512755378121089, D22*: 0.5885003263796224, D12*: 1.3917430256030947
Epoch: 16 , Coefficient 1: 1.000054540622323 , Coefficient 2: 0.9999126464428535 , Coefficient 3: 0.4094778429724207
Epoch: 17 , Train Loss: 8.205490358232055e-05
Epoch: 17 , Test Loss: 8.221454346785324e-05
Epoch: 17 , D11: 0.5525517930029219 , D22: 0.5803526795760817
Epoch: 17 , D11*: 0.5525595803643125, D22*: 0.5803284647172021, D12*: 1.4594438189780452
Epoch: 17 , Coefficient 1: 1.0000140934505855 , Coefficient 2: 0.9999582756145844 , Coefficient 3: 0.3881232118529932
Epoch: 18 , Train Loss: 8.192449983107509e-05
Epoch: 18 , Test Loss: 8.205538746260571e-05
Epoch: 18 , D11: 0.5235578456451502 , D22: 0.606722502244432
Epoch: 18 , D11*: 0.5235718441281849, D22*: 0.606716868986932, D12*: 1.4443154959605589
Epoch: 18 , Coefficient 1: 1.00002673722331 , Coefficient 2: 0.9999907152652503 , Coefficient 3: 0.3912887164460578
Epoch: 19 , Train Loss: 8.178404718746604e-05
Epoch: 19 , Test Loss: 8.196344390598828e-05
Epoch: 19 , D11: 0.504545633943033 , D22: 0.6249054652075512
Epoch: 19 , D11*: 0.5045538878618456, D22*: 0.6248986831397153, D12*: 1.5088341449844918
Epoch: 19 , Coefficient 1: 1.0000163591125508 , Coefficient 2: 0.9999891470498924 , Coefficient 3: 0.37427989509515297
Epoch: 20 , Train Loss: 8.163769037164457e-05
Epoch: 20 , Test Loss: 8.17924689341453e-05
Epoch: 20 , D11: 0.5567472094869962 , D22: 0.592634187340158
Epoch: 20 , D11*: 0.5567474889249548, D22*: 0.5926339888206635, D12*: 1.4916931098959496
Epoch: 20 , Coefficient 1: 1.0000005019117364 , Coefficient 2: 0.9999996650218655 , Coefficient 3: 0.3852607048060279
Epoch: 21 , Train Loss: 8.150268672034143e-05
Epoch: 21 , Test Loss: 8.165356739627897e-05
Epoch: 21 , D11: 0.5308783441152776 , D22: 0.5920964602559287
Epoch: 21 , D11*: 0.530878346607658, D22*: 0.5920964522106049, D12*: 1.4152721123968965
Epoch: 21 , Coefficient 1: 1.000000004694824 , Coefficient 2: 0.9999999864121402 , Coefficient 3: 0.3967345886991298
Epoch: 22 , Train Loss: 8.137670609394262e-05
Epoch: 22 , Test Loss: 8.153339007985777e-05
Epoch: 22 , D11: 0.5364650360648965 , D22: 0.6008703561927339
Epoch: 22 , D11*: 0.5364650372267646, D22*: 0.600870345530072, D12*: 1.3695902302618717
Epoch: 22 , Coefficient 1: 1.0000000021657853 , Coefficient 2: 0.9999999822546382 , Coefficient 3: 0.4152100962852857
Epoch: 23 , Train Loss: 8.124324820928449e-05
Epoch: 23 , Test Loss: 8.140868373739067e-05
Epoch: 23 , D11: 0.55824433692762 , D22: 0.5894347911855461
Epoch: 23 , D11*: 0.5582443385823767, D22*: 0.5894347906958171, D12*: 1.4228993427766607
Epoch: 23 , Coefficient 1: 1.0000000029642158 , Coefficient 2: 0.9999999991691548 , Coefficient 3: 0.4032889378663288
Epoch: 24 , Train Loss: 8.112192787084498e-05
Epoch: 24 , Test Loss: 8.128820000274573e-05
Epoch: 24 , D11: 0.5363141426860754 , D22: 0.5827753572446002
Epoch: 24 , D11*: 0.5363141426860754, D22*: 0.5827753572446002, D12*: 1.4427877658140653
Epoch: 24 , Coefficient 1: 1.0 , Coefficient 2: 1.0 , Coefficient 3: 0.38782193973597034
Epoch: 25 , Train Loss: 8.101019163041199e-05
Epoch: 25 , Test Loss: 8.116296832740771e-05
Epoch: 25 , D11: 0.5265901476998254 , D22: 0.5614043088620273
Epoch: 25 , D11*: 0.5265901494919129, D22*: 0.5614043034232882, D12*: 1.4522383646184587
Epoch: 25 , Coefficient 1: 1.0000000034031922 , Coefficient 2: 0.9999999903122597 , Coefficient 3: 0.3745922430582
Epoch: 26 , Train Loss: 8.091003671615908e-05
Epoch: 26 , Test Loss: 8.11074693890987e-05
Epoch: 26 , D11: 0.5459345335725299 , D22: 0.5678705192114502
Epoch: 26 , D11*: 0.5459345370163041, D22*: 0.5678705192114502, D12*: 1.4726746390790348
Epoch: 26 , Coefficient 1: 1.0000000063080352 , Coefficient 2: 1.0 , Coefficient 3: 0.37815720685062293
Epoch: 27 , Train Loss: 8.081975665772916e-05
Epoch: 27 , Test Loss: 8.101172078604576e-05
Epoch: 27 , D11: 0.5321322767413731 , D22: 0.5814146372394385
Epoch: 27 , D11*: 0.5321322767413731, D22*: 0.5814146372394385, D12*: 1.3349789292445715
Epoch: 27 , Coefficient 1: 1.0 , Coefficient 2: 1.0 , Coefficient 3: 0.4170653519643706
Epoch: 28 , Train Loss: 8.07400974095799e-05
Epoch: 28 , Test Loss: 8.092631705658282e-05
Epoch: 28 , D11: 0.5114237777625407 , D22: 0.5773282218250061
Epoch: 28 , D11*: 0.5114237779911113, D22*: 0.5773282221819626, D12*: 1.465812591142713
Epoch: 28 , Coefficient 1: 1.00000000044693 , Coefficient 2: 1.0000000006182903 , Coefficient 3: 0.3713817191747236
Epoch: 29 , Train Loss: 8.065126716974191e-05
Epoch: 29 , Test Loss: 8.083772440149917e-05
Epoch: 29 , D11: 0.5625887348832627 , D22: 0.6343120241558964
Epoch: 29 , D11*: 0.5625887485556471, D22*: 0.6343120103171636, D12*: 1.45813391090986
Epoch: 29 , Coefficient 1: 1.0000000243026275 , Coefficient 2: 0.999999978183083 , Coefficient 3: 0.4104220983811964
