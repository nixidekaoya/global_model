Optimizer: SGD
Learning Rate: 0.05
Momentum: 0.9
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.004241405861685052
Epoch: 0 , Test Loss: 0.004176885445602239
Epoch: 0 , D11: 1.6545505174579904 , D22: 1.2344194309745358
Epoch: 0 , D11*: 1.6531580869556506, D22*: 1.2347154681658812, D12*: 1.6045921500164952
Epoch: 0 , Coefficient 1: 0.9991584237001847 , Coefficient 2: 1.000239818965837 , Coefficient 3: 0.8998777524531216
Epoch: 1 , Train Loss: 0.0034399398749228568
Epoch: 1 , Test Loss: 0.003338063437957317
Epoch: 1 , D11: 1.093279420719644 , D22: 1.19626424173519
Epoch: 1 , D11*: 1.0912864438131022, D22*: 1.1967779977626571, D12*: 1.4308384293483023
Epoch: 1 , Coefficient 1: 0.9981770653789223 , Coefficient 2: 1.0004294670103338 , Coefficient 3: 0.7995537422830802
Epoch: 2 , Train Loss: 0.00225130609201733
Epoch: 2 , Test Loss: 0.0021204241036903116
Epoch: 2 , D11: 0.8741569822375173 , D22: 0.9682663454858901
Epoch: 2 , D11*: 0.8743172823235218, D22*: 0.9698024046912095, D12*: 1.4139744628826019
Epoch: 2 , Coefficient 1: 1.0001833767724353 , Coefficient 2: 1.0015864015231766 , Coefficient 3: 0.652105018663213
Epoch: 3 , Train Loss: 0.0010492832592281047
Epoch: 3 , Test Loss: 0.0009531258478527888
Epoch: 3 , D11: 0.6054727491677122 , D22: 0.7189513259813949
Epoch: 3 , D11*: 0.6054832091876328, D22*: 0.7191113581156569, D12*: 1.4051642803228905
Epoch: 3 , Coefficient 1: 1.000017275789761 , Coefficient 2: 1.0002225910551643 , Coefficient 3: 0.47133085641734107
Epoch: 4 , Train Loss: 0.00037574386682535986
Epoch: 4 , Test Loss: 0.0003378339791088365
Epoch: 4 , D11: 0.5291353736414357 , D22: 0.6186704356403638
Epoch: 4 , D11*: 0.5290202535299001, D22*: 0.6184329076772106, D12*: 1.371446632919561
Epoch: 4 , Coefficient 1: 0.9997824373170454 , Coefficient 2: 0.9996160670536852 , Coefficient 3: 0.4183367889293626
Epoch: 5 , Train Loss: 0.00014490597997428268
Epoch: 5 , Test Loss: 0.0001338184381456813
Epoch: 5 , D11: 0.5276608534522719 , D22: 0.5676700957211213
Epoch: 5 , D11*: 0.5275253679924058, D22*: 0.5678527749433874, D12*: 1.4656567436414016
Epoch: 5 , Coefficient 1: 0.999743233823431 , Coefficient 2: 1.0003218052591516 , Coefficient 3: 0.37368167809003594
Epoch: 6 , Train Loss: 7.622488209563016e-05
Epoch: 6 , Test Loss: 7.270756648358657e-05
Epoch: 6 , D11: 0.5213019884249099 , D22: 0.5623363371980074
Epoch: 6 , D11*: 0.5212954499061033, D22*: 0.5622220592509386, D12*: 1.4868487176834582
Epoch: 6 , Coefficient 1: 0.9999874573300087 , Coefficient 2: 0.9997967800771365 , Coefficient 3: 0.36436709944680357
Epoch: 7 , Train Loss: 5.259269294219848e-05
Epoch: 7 , Test Loss: 5.1196168766182374e-05
Epoch: 7 , D11: 0.5302738123034155 , D22: 0.5544524726372706
Epoch: 7 , D11*: 0.5303139372606934, D22*: 0.5545768711981329, D12*: 1.5009062716212287
Epoch: 7 , Coefficient 1: 1.0000756683742378 , Coefficient 2: 1.000224362893127 , Coefficient 3: 0.36141191124711725
Epoch: 8 , Train Loss: 4.226831519736152e-05
Epoch: 8 , Test Loss: 4.1551807895302777e-05
Epoch: 8 , D11: 0.5093035141013249 , D22: 0.5454945516942592
Epoch: 8 , D11*: 0.5094658967600668, D22*: 0.5456683192896017, D12*: 1.4483659426432043
Epoch: 8 , Coefficient 1: 1.0003188327868273 , Coefficient 2: 1.0003185505607761 , Coefficient 3: 0.3642498711769261
Epoch: 9 , Train Loss: 3.6501991859040574e-05
Epoch: 9 , Test Loss: 3.605109680211171e-05
Epoch: 9 , D11: 0.5006700693189977 , D22: 0.5410841603504912
Epoch: 9 , D11*: 0.5006968911533494, D22*: 0.5412383910164208, D12*: 1.4612437237331972
Epoch: 9 , Coefficient 1: 1.0000535718749637 , Coefficient 2: 1.0002850400681285 , Coefficient 3: 0.3565234413831478
Epoch: 10 , Train Loss: 3.267729535218677e-05
Epoch: 10 , Test Loss: 3.2355503841245083e-05
Epoch: 10 , D11: 0.5337366654035692 , D22: 0.590234464213408
Epoch: 10 , D11*: 0.5337525527723872, D22*: 0.5901688840481367, D12*: 1.4860751471371174
Epoch: 10 , Coefficient 1: 1.0000297663058353 , Coefficient 2: 0.9998888913317546 , Coefficient 3: 0.3781509431019445
Epoch: 11 , Train Loss: 2.9812036913426707e-05
Epoch: 11 , Test Loss: 2.9554266286140773e-05
Epoch: 11 , D11: 0.5390794149274125 , D22: 0.566232643935774
Epoch: 11 , D11*: 0.5391061264512903, D22*: 0.5661775517679507, D12*: 1.451315033851429
Epoch: 11 , Coefficient 1: 1.0000495502576023 , Coefficient 2: 0.9999027040061831 , Coefficient 3: 0.3807869595638699
Epoch: 12 , Train Loss: 2.7446881103969643e-05
Epoch: 12 , Test Loss: 2.7228700477280656e-05
Epoch: 12 , D11: 0.5107625691243418 , D22: 0.5535539615036653
Epoch: 12 , D11*: 0.5107737667335231, D22*: 0.5535978218434288, D12*: 1.4675800983416987
Epoch: 12 , Coefficient 1: 1.0000219233159557 , Coefficient 2: 1.0000792340816138 , Coefficient 3: 0.3626281079239373
Epoch: 13 , Train Loss: 2.5407282612832204e-05
Epoch: 13 , Test Loss: 2.5214271565346283e-05
Epoch: 13 , D11: 0.5256467635893511 , D22: 0.5833642796626142
Epoch: 13 , D11*: 0.5256175054131925, D22*: 0.5833031772381592, D12*: 1.51674533728209
Epoch: 13 , Coefficient 1: 0.9999443387114973 , Coefficient 2: 0.9998952585432719 , Coefficient 3: 0.36555928519894654
Epoch: 14 , Train Loss: 2.363103506650077e-05
Epoch: 14 , Test Loss: 2.3466800452297315e-05
Epoch: 14 , D11: 0.5043720073456014 , D22: 0.532414075834604
Epoch: 14 , D11*: 0.5043361861510962, D22*: 0.5324100515415401, D12*: 1.456294418230517
Epoch: 14 , Coefficient 1: 0.9999289786229539 , Coefficient 2: 0.999992441422482 , Coefficient 3: 0.35595351623758315
Epoch: 15 , Train Loss: 2.2086591524384862e-05
Epoch: 15 , Test Loss: 2.19441485896823e-05
Epoch: 15 , D11: 0.47601871583857863 , D22: 0.5669233963552186
Epoch: 15 , D11*: 0.47615145067387415, D22*: 0.5669723613387769, D12*: 1.4879157239004521
Epoch: 15 , Coefficient 1: 1.0002788437321455 , Coefficient 2: 1.0000863696645317 , Coefficient 3: 0.350531886738244
Epoch: 16 , Train Loss: 2.0759475216436842e-05
Epoch: 16 , Test Loss: 2.0631567393138542e-05
Epoch: 16 , D11: 0.5164418726862239 , D22: 0.5363512810974492
Epoch: 16 , D11*: 0.5163656347602393, D22*: 0.5363880980642892, D12*: 1.458818413665327
Epoch: 16 , Coefficient 1: 0.9998523784959806 , Coefficient 2: 1.0000686433838 , Coefficient 3: 0.3608241173003334
Epoch: 17 , Train Loss: 1.9594944905293233e-05
Epoch: 17 , Test Loss: 1.948057161280303e-05
Epoch: 17 , D11: 0.5322911382961403 , D22: 0.5758714780454964
Epoch: 17 , D11*: 0.5323372322348771, D22*: 0.575830847384995, D12*: 1.4512499524102014
Epoch: 17 , Coefficient 1: 1.000086595352469 , Coefficient 2: 0.9999294449160092 , Coefficient 3: 0.38179780050275036
Epoch: 18 , Train Loss: 1.85521602152221e-05
Epoch: 18 , Test Loss: 1.8449104092724158e-05
Epoch: 18 , D11: 0.5323738825532102 , D22: 0.6043659891984543
Epoch: 18 , D11*: 0.5323869347201703, D22*: 0.6043343635279722, D12*: 1.4886184870037518
Epoch: 18 , Coefficient 1: 1.0000245169182558 , Coefficient 2: 0.9999476713265681 , Coefficient 3: 0.3818041050048029
Epoch: 19 , Train Loss: 1.760775497132272e-05
Epoch: 19 , Test Loss: 1.75137974692916e-05
Epoch: 19 , D11: 0.4843093197686243 , D22: 0.5437105177579785
Epoch: 19 , D11*: 0.4843280473599442, D22*: 0.543645586122175, D12*: 1.5173478899205366
Epoch: 19 , Coefficient 1: 1.0000386686577265 , Coefficient 2: 0.9998805768259343 , Coefficient 3: 0.33874025868120267
Epoch: 20 , Train Loss: 1.6750331870753145e-05
Epoch: 20 , Test Loss: 1.6669450524204876e-05
Epoch: 20 , D11: 0.4647141541362731 , D22: 0.5642057711751647
Epoch: 20 , D11*: 0.4647929989394433, D22*: 0.5642101146258786, D12*: 1.458101200918076
Epoch: 20 , Coefficient 1: 1.00016966301213 , Coefficient 2: 1.0000076983450645 , Coefficient 3: 0.35285723409233266
Epoch: 21 , Train Loss: 1.6023781507101375e-05
Epoch: 21 , Test Loss: 1.59539943888376e-05
Epoch: 21 , D11: 0.5151934771705423 , D22: 0.5712910962893805
Epoch: 21 , D11*: 0.5152151534572951, D22*: 0.5713123290968084, D12*: 1.4596325556587302
Epoch: 21 , Coefficient 1: 1.000042074070642 , Coefficient 2: 1.000037166354536 , Coefficient 3: 0.37219212408692653
Epoch: 22 , Train Loss: 1.540748468323727e-05
Epoch: 22 , Test Loss: 1.5344876901508544e-05
Epoch: 22 , D11: 0.49391180767117565 , D22: 0.5667332310481161
Epoch: 22 , D11*: 0.4939848809991281, D22*: 0.5667002805870159, D12*: 1.4328849439803115
Epoch: 22 , Coefficient 1: 1.000147948129236 , Coefficient 2: 0.9999418589570983 , Coefficient 3: 0.37012223697449853
Epoch: 23 , Train Loss: 1.4867839880025716e-05
Epoch: 23 , Test Loss: 1.4808883031946607e-05
Epoch: 23 , D11: 0.5068327213801292 , D22: 0.5316281388013362
Epoch: 23 , D11*: 0.5068704992799828, D22*: 0.5316384980738439, D12*: 1.4415154193478148
Epoch: 23 , Coefficient 1: 1.0000745372156532 , Coefficient 2: 1.0000194859371647 , Coefficient 3: 0.3602143214755482
Epoch: 24 , Train Loss: 1.4376243756487384e-05
Epoch: 24 , Test Loss: 1.4322020113468169e-05
Epoch: 24 , D11: 0.5072942229797319 , D22: 0.5732361051252087
Epoch: 24 , D11*: 0.5073281484913339, D22*: 0.5732601885259176, D12*: 1.4591081752508321
Epoch: 24 , Coefficient 1: 1.0000668754148287 , Coefficient 2: 1.0000420130562147 , Coefficient 3: 0.3702906869230206
Epoch: 25 , Train Loss: 1.3925616690812602e-05
Epoch: 25 , Test Loss: 1.3878228653993575e-05
Epoch: 25 , D11: 0.5263634728790669 , D22: 0.5724591017574067
Epoch: 25 , D11*: 0.5263712865034119, D22*: 0.5724291123559323, D12*: 1.5082207106067385
Epoch: 25 , Coefficient 1: 1.0000148445413628 , Coefficient 2: 0.9999476130235639 , Coefficient 3: 0.3642704251214368
Epoch: 26 , Train Loss: 1.3521738684630692e-05
Epoch: 26 , Test Loss: 1.3480953672114996e-05
Epoch: 26 , D11: 0.5332960333382367 , D22: 0.5574981599206745
Epoch: 26 , D11*: 0.5333080328610139, D22*: 0.5575058996097509, D12*: 1.518340998252715
Epoch: 26 , Coefficient 1: 1.0000225006788483 , Coefficient 2: 1.000013882896183 , Coefficient 3: 0.3592124344024359
Epoch: 27 , Train Loss: 1.3154675724308618e-05
Epoch: 27 , Test Loss: 1.3117897871779859e-05
Epoch: 27 , D11: 0.4841459626359916 , D22: 0.5223927126925559
Epoch: 27 , D11*: 0.4841589207011451, D22*: 0.5223919276189829, D12*: 1.4191170758229186
Epoch: 27 , Coefficient 1: 1.0000267647902772 , Coefficient 2: 0.9999984971582605 , Coefficient 3: 0.3546398198811217
Epoch: 28 , Train Loss: 1.2837939138080402e-05
Epoch: 28 , Test Loss: 1.2801888477042663e-05
Epoch: 28 , D11: 0.5548027179047542 , D22: 0.545093176665758
Epoch: 28 , D11*: 0.5548265657876683, D22*: 0.5450813739149465, D12*: 1.469953425754102
Epoch: 28 , Coefficient 1: 1.0000429844377912 , Coefficient 2: 0.9999783472783796 , Coefficient 3: 0.3741302004648039
Epoch: 29 , Train Loss: 1.256390667413143e-05
Epoch: 29 , Test Loss: 1.253468005779723e-05
Epoch: 29 , D11: 0.5148246538498621 , D22: 0.5409621302662884
Epoch: 29 , D11*: 0.5148276777570208, D22*: 0.5409524332990182, D12*: 1.5057273345121043
Epoch: 29 , Coefficient 1: 1.000005873664239 , Coefficient 2: 0.9999820745913113 , Coefficient 3: 0.35058808021112925
Epoch: 30 , Train Loss: 1.2329610674441941e-05
Epoch: 30 , Test Loss: 1.2303817309657463e-05
Epoch: 30 , D11: 0.5342080019814085 , D22: 0.5490972999585323
Epoch: 30 , D11*: 0.5341928221112161, D22*: 0.5490687979060518, D12*: 1.4800736928164384
Epoch: 30 , Coefficient 1: 0.9999715843451688 , Coefficient 2: 0.9999480928926756 , Coefficient 3: 0.36594854204722904
Epoch: 31 , Train Loss: 1.2108944564261036e-05
Epoch: 31 , Test Loss: 1.2083587007509776e-05
Epoch: 31 , D11: 0.5036938561874245 , D22: 0.5382730192566272
Epoch: 31 , D11*: 0.5037112854223812, D22*: 0.538274045125656, D12*: 1.4765704366126817
Epoch: 31 , Coefficient 1: 1.0000346028341276 , Coefficient 2: 1.0000019058525917 , Coefficient 3: 0.35283969687839545
Epoch: 32 , Train Loss: 1.1909102305708075e-05
Epoch: 32 , Test Loss: 1.1887917504282085e-05
Epoch: 32 , D11: 0.5202731015345756 , D22: 0.547346421997057
Epoch: 32 , D11*: 0.5202590993033668, D22*: 0.5473496106718644, D12*: 1.490800751535583
Epoch: 32 , Coefficient 1: 0.999973086766993 , Coefficient 2: 1.0000058256977287 , Coefficient 3: 0.35806552581743484
Epoch: 33 , Train Loss: 1.172726105005495e-05
Epoch: 33 , Test Loss: 1.1707917610692676e-05
Epoch: 33 , D11: 0.5427761039561965 , D22: 0.5967454903786044
Epoch: 33 , D11*: 0.542797117562618, D22*: 0.5967283460190443, D12*: 1.491837138851418
Epoch: 33 , Coefficient 1: 1.000038715054455 , Coefficient 2: 0.9999712702318887 , Coefficient 3: 0.38192019554460066
Epoch: 34 , Train Loss: 1.1561168402295154e-05
Epoch: 34 , Test Loss: 1.15414903848432e-05
Epoch: 34 , D11: 0.5552855756622329 , D22: 0.5566233474309361
Epoch: 34 , D11*: 0.5552833533943227, D22*: 0.5566339672828319, D12*: 1.5059972506035442
Epoch: 34 , Coefficient 1: 0.9999959979729213 , Coefficient 2: 1.0000190790629693 , Coefficient 3: 0.3691631310188455
Epoch: 35 , Train Loss: 1.1413839929900861e-05
Epoch: 35 , Test Loss: 1.1394120432669298e-05
Epoch: 35 , D11: 0.5277468943682377 , D22: 0.5365313942383434
Epoch: 35 , D11*: 0.5277557481663524, D22*: 0.5365155007457226, D12*: 1.4352173706932045
Epoch: 35 , Coefficient 1: 1.0000167765991788 , Coefficient 2: 0.9999703773296559 , Coefficient 3: 0.37077005568781407
Epoch: 36 , Train Loss: 1.1276089590865012e-05
Epoch: 36 , Test Loss: 1.126065418793587e-05
Epoch: 36 , D11: 0.5325729615790137 , D22: 0.5808254288889267
Epoch: 36 , D11*: 0.532566091319996, D22*: 0.5808235419987954, D12*: 1.5556717635363242
Epoch: 36 , Coefficient 1: 0.9999870998726685 , Coefficient 2: 0.9999967513644591 , Coefficient 3: 0.35784850616169017
Epoch: 37 , Train Loss: 1.1146328549784812e-05
Epoch: 37 , Test Loss: 1.1131017710795276e-05
Epoch: 37 , D11: 0.570145203451732 , D22: 0.5840669070681207
Epoch: 37 , D11*: 0.5701396625532067, D22*: 0.5840646956014175, D12*: 1.4770652663237849
Epoch: 37 , Coefficient 1: 0.9999902816010873 , Coefficient 2: 0.999996213675734 , Coefficient 3: 0.3907086519701605
Epoch: 38 , Train Loss: 1.1021787533536553e-05
Epoch: 38 , Test Loss: 1.100717077497393e-05
Epoch: 38 , D11: 0.5696486477450539 , D22: 0.5579084389991354
Epoch: 38 , D11*: 0.5696427813923741, D22*: 0.557915414935687, D12*: 1.4762901880647792
Epoch: 38 , Coefficient 1: 0.9999897018053093 , Coefficient 2: 1.0000125037301175 , Coefficient 3: 0.38188907758241636
Epoch: 39 , Train Loss: 1.08934293089078e-05
Epoch: 39 , Test Loss: 1.0879637480684324e-05
Epoch: 39 , D11: 0.504031412821568 , D22: 0.5686684428346557
Epoch: 39 , D11*: 0.5040246943080735, D22*: 0.5686715763580285, D12*: 1.5005126415989858
Epoch: 39 , Coefficient 1: 0.9999866704468737 , Coefficient 2: 1.0000055102818035 , Coefficient 3: 0.3574432633646487
