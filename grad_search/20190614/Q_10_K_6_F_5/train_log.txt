Optimizer: SGD
Learning Rate: 0.05
Momentum: 0.9
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.004379477224545554
Epoch: 0 , Test Loss: 0.004343999105039985
Epoch: 0 , D11: 1.4703395831855672 , D22: 1.7433619939172937
Epoch: 0 , D11*: 1.472433680126015, D22*: 1.7427145761201677, D12*: 1.5948392308413075
Epoch: 0 , Coefficient 1: 1.001424226732651 , Coefficient 2: 0.999628638343967 , Coefficient 3: 1.0079850664791246
Epoch: 1 , Train Loss: 0.003986193669610656
Epoch: 1 , Test Loss: 0.003936173160560429
Epoch: 1 , D11: 1.4721439063191515 , D22: 1.6755115445582205
Epoch: 1 , D11*: 1.4754363087817426, D22*: 1.6733288033915454, D12*: 1.6483856755769601
Epoch: 1 , Coefficient 1: 1.002236467813003 , Coefficient 2: 0.9986972687990338 , Coefficient 3: 0.9551057009371221
Epoch: 2 , Train Loss: 0.0033467827520798897
Epoch: 2 , Test Loss: 0.0032587354555726053
Epoch: 2 , D11: 1.0857366911908166 , D22: 1.241046347747635
Epoch: 2 , D11*: 1.0871284532153445, D22*: 1.2386464639301384, D12*: 1.7194991035065392
Epoch: 2 , Coefficient 1: 1.001281859621969 , Coefficient 2: 0.9980662415856973 , Coefficient 3: 0.6762943093144329
Epoch: 3 , Train Loss: 0.002302402705303393
Epoch: 3 , Test Loss: 0.0021777763944119217
Epoch: 3 , D11: 0.9564902234796728 , D22: 0.9431443900923855
Epoch: 3 , D11*: 0.9574694687095847, D22*: 0.9419771491303622, D12*: 1.425258979838464
Epoch: 3 , Coefficient 1: 1.001023790108747 , Coefficient 2: 0.9987623942057177 , Coefficient 3: 0.6663513946269704
Epoch: 4 , Train Loss: 0.0011469243804458531
Epoch: 4 , Test Loss: 0.0010463328422047197
Epoch: 4 , D11: 0.7115917893649815 , D22: 0.7804375134114534
Epoch: 4 , D11*: 0.7122832625100568, D22*: 0.7790593901742214, D12*: 1.3999316385666627
Epoch: 4 , Coefficient 1: 1.0009717272675285 , Coefficient 2: 0.9982341658191084 , Coefficient 3: 0.5326483849637142
Epoch: 5 , Train Loss: 0.00043572623543877855
Epoch: 5 , Test Loss: 0.00039245451253373174
Epoch: 5 , D11: 0.5557648918007906 , D22: 0.6719297499785172
Epoch: 5 , D11*: 0.5561165018651278, D22*: 0.6709363301310258, D12*: 1.4135732345598824
Epoch: 5 , Coefficient 1: 1.0006326597263062 , Coefficient 2: 0.9985215420994187 , Coefficient 3: 0.43402520718291543
Epoch: 6 , Train Loss: 0.00017135104378758118
Epoch: 6 , Test Loss: 0.0001579708279314218
Epoch: 6 , D11: 0.5232464593245193 , D22: 0.6194679805453803
Epoch: 6 , D11*: 0.5233396911767813, D22*: 0.6191565955153105, D12*: 1.4384543339371096
Epoch: 6 , Coefficient 1: 1.0001781796142153 , Coefficient 2: 0.9994973347455415 , Coefficient 3: 0.3971263667317932
Epoch: 7 , Train Loss: 8.832927943149116e-05
Epoch: 7 , Test Loss: 8.396401524078098e-05
Epoch: 7 , D11: 0.5105767884521927 , D22: 0.5779257845295629
Epoch: 7 , D11*: 0.5110582675508194, D22*: 0.5776736990559985, D12*: 1.4961895949141915
Epoch: 7 , Coefficient 1: 1.0009430101593266 , Coefficient 2: 0.9995638099556856 , Coefficient 3: 0.363834894423677
Epoch: 8 , Train Loss: 5.858274426645948e-05
Epoch: 8 , Test Loss: 5.683226315159118e-05
Epoch: 8 , D11: 0.5036440411309333 , D22: 0.5788886423454149
Epoch: 8 , D11*: 0.5039766265135082, D22*: 0.5785501159418392, D12*: 1.4706366612517527
Epoch: 8 , Coefficient 1: 1.0006603580215663 , Coefficient 2: 0.9994152132572439 , Coefficient 3: 0.36804697277638243
Epoch: 9 , Train Loss: 4.54888009098795e-05
Epoch: 9 , Test Loss: 4.463175237469841e-05
Epoch: 9 , D11: 0.5510473656499157 , D22: 0.5814462701453524
Epoch: 9 , D11*: 0.5513173809208564, D22*: 0.5811766898472234, D12*: 1.494683372480283
Epoch: 9 , Coefficient 1: 1.0004900037415516 , Coefficient 2: 0.9995363624947466 , Coefficient 3: 0.3788407938494743
Epoch: 10 , Train Loss: 3.8574986770981915e-05
Epoch: 10 , Test Loss: 3.807549394696252e-05
Epoch: 10 , D11: 0.5014490523297759 , D22: 0.5948866834401664
Epoch: 10 , D11*: 0.5017128858685683, D22*: 0.5945172373533442, D12*: 1.5066369618327786
Epoch: 10 , Coefficient 1: 1.0005261422622431 , Coefficient 2: 0.9993789639319446 , Coefficient 3: 0.36380035502659563
Epoch: 11 , Train Loss: 3.437676978683157e-05
Epoch: 11 , Test Loss: 3.404986372333951e-05
Epoch: 11 , D11: 0.5333630094064354 , D22: 0.5670704871466155
Epoch: 11 , D11*: 0.5336326704832479, D22*: 0.5666884209742677, D12*: 1.4638824980028484
Epoch: 11 , Coefficient 1: 1.0005055863868635 , Coefficient 2: 0.9993262457119393 , Coefficient 3: 0.3758228863855761
Epoch: 12 , Train Loss: 3.15592968800047e-05
Epoch: 12 , Test Loss: 3.1329032048233775e-05
Epoch: 12 , D11: 0.5372861301066609 , D22: 0.5332085222355608
Epoch: 12 , D11*: 0.5375207942365099, D22*: 0.5330199250235808, D12*: 1.5282151998690139
Epoch: 12 , Coefficient 1: 1.0004367582126164 , Coefficient 2: 0.9996462974537816 , Coefficient 3: 0.350258497413142
Epoch: 13 , Train Loss: 2.951193473109015e-05
Epoch: 13 , Test Loss: 2.9336428298847748e-05
Epoch: 13 , D11: 0.5201884910948167 , D22: 0.5914285394549027
Epoch: 13 , D11*: 0.5203894597609655, D22*: 0.5911407325067415, D12*: 1.5178024966993147
Epoch: 13 , Coefficient 1: 1.0003863381631644 , Coefficient 2: 0.9995133698681054 , Coefficient 3: 0.366164304869999
Epoch: 14 , Train Loss: 2.7947411912464304e-05
Epoch: 14 , Test Loss: 2.781337291526142e-05
Epoch: 14 , D11: 0.5214966919583414 , D22: 0.5841899079043884
Epoch: 14 , D11*: 0.5216632342372308, D22*: 0.5840262388837024, D12*: 1.4847172875406245
Epoch: 14 , Coefficient 1: 1.0003193544301576 , Coefficient 2: 0.9997198359326797 , Coefficient 3: 0.37235690673221167
Epoch: 15 , Train Loss: 2.669396766850696e-05
Epoch: 15 , Test Loss: 2.658022381365299e-05
Epoch: 15 , D11: 0.5120284953665916 , D22: 0.5777353012422657
Epoch: 15 , D11*: 0.5122606693548973, D22*: 0.5775742037613478, D12*: 1.5069286370645179
Epoch: 15 , Coefficient 1: 1.0004534395847238 , Coefficient 2: 0.999721156937145 , Coefficient 3: 0.36160799068734695
Epoch: 16 , Train Loss: 2.5628403542214072e-05
Epoch: 16 , Test Loss: 2.552915639898856e-05
Epoch: 16 , D11: 0.5059885072910412 , D22: 0.5647507508865925
Epoch: 16 , D11*: 0.506195292053807, D22*: 0.56445234692715, D12*: 1.458052413160701
Epoch: 16 , Coefficient 1: 1.0004086748212384 , Coefficient 2: 0.9994716183042269 , Coefficient 3: 0.3671499149540361
Epoch: 17 , Train Loss: 2.472809274058818e-05
Epoch: 17 , Test Loss: 2.464764024625765e-05
Epoch: 17 , D11: 0.5298967019557405 , D22: 0.5695471288173378
Epoch: 17 , D11*: 0.53001768016285, D22*: 0.569278541351728, D12*: 1.481933570591031
Epoch: 17 , Coefficient 1: 1.0002283052652772 , Coefficient 2: 0.9995284192439569 , Coefficient 3: 0.3708992910782607
Epoch: 18 , Train Loss: 2.3963211537193274e-05
Epoch: 18 , Test Loss: 2.389201485857484e-05
Epoch: 18 , D11: 0.527871260493199 , D22: 0.5589017433416767
Epoch: 18 , D11*: 0.528019380647631, D22*: 0.5587212461125027, D12*: 1.4668698903511512
Epoch: 18 , Coefficient 1: 1.0002805990125199 , Coefficient 2: 0.9996770501589514 , Coefficient 3: 0.37042843196542163
Epoch: 19 , Train Loss: 2.3286740993171407e-05
Epoch: 19 , Test Loss: 2.3222568415803835e-05
Epoch: 19 , D11: 0.497168531430083 , D22: 0.5756317580820802
Epoch: 19 , D11*: 0.49730603603237283, D22*: 0.5754196406003532, D12*: 1.4784130006937508
Epoch: 19 , Coefficient 1: 1.000276575433876 , Coefficient 2: 0.9996315049009218 , Coefficient 3: 0.36279634856070175
Epoch: 20 , Train Loss: 2.2684195973852182e-05
Epoch: 20 , Test Loss: 2.2628702165093272e-05
Epoch: 20 , D11: 0.5587703583285423 , D22: 0.5518329139095095
Epoch: 20 , D11*: 0.5589101199934469, D22*: 0.551664710979106, D12*: 1.5205696439672685
Epoch: 20 , Coefficient 1: 1.000250123620234 , Coefficient 2: 0.9996951922834543 , Coefficient 3: 0.3651838096921981
Epoch: 21 , Train Loss: 2.2139494867587927e-05
Epoch: 21 , Test Loss: 2.2091315295256208e-05
Epoch: 21 , D11: 0.5292875593844442 , D22: 0.5587180399912194
Epoch: 21 , D11*: 0.5293714161706551, D22*: 0.558554441928355, D12*: 1.4699760709236773
Epoch: 21 , Coefficient 1: 1.0001584333217814 , Coefficient 2: 0.9997071902978703 , Coefficient 3: 0.3700488326369145
Epoch: 22 , Train Loss: 2.1632346022670395e-05
Epoch: 22 , Test Loss: 2.158434791635955e-05
Epoch: 22 , D11: 0.5329204214627339 , D22: 0.6007347339703178
Epoch: 22 , D11*: 0.5330444147172763, D22*: 0.6005863567023985, D12*: 1.4719503692209204
Epoch: 22 , Coefficient 1: 1.0002326674857047 , Coefficient 2: 0.9997530070103675 , Coefficient 3: 0.3850777835735342
Epoch: 23 , Train Loss: 2.113372514668299e-05
Epoch: 23 , Test Loss: 2.1083302282931977e-05
Epoch: 23 , D11: 0.5357290265443336 , D22: 0.5830026679084895
Epoch: 23 , D11*: 0.5358556086805706, D22*: 0.5828678740238791, D12*: 1.4479363906377212
Epoch: 23 , Coefficient 1: 1.0002362801527733 , Coefficient 2: 0.9997687937087938 , Coefficient 3: 0.38631651567639835
Epoch: 24 , Train Loss: 2.0649661900279173e-05
Epoch: 24 , Test Loss: 2.0603107393981192e-05
Epoch: 24 , D11: 0.5116213587554508 , D22: 0.5421810512111271
Epoch: 24 , D11*: 0.5117788211935509, D22*: 0.5420406248006312, D12*: 1.4345903657841128
Epoch: 24 , Coefficient 1: 1.000307771431754 , Coefficient 2: 0.9997409971997688 , Coefficient 3: 0.36728932213976967
Epoch: 25 , Train Loss: 2.0196876803311167e-05
Epoch: 25 , Test Loss: 2.0154125431872673e-05
Epoch: 25 , D11: 0.5337687093075981 , D22: 0.5740554901324019
Epoch: 25 , D11*: 0.5338517654223849, D22*: 0.5739421247041502, D12*: 1.4078703782061184
Epoch: 25 , Coefficient 1: 1.0001556031916792 , Coefficient 2: 0.9998025183450026 , Coefficient 3: 0.39342893609923985
Epoch: 26 , Train Loss: 1.9767712431530527e-05
Epoch: 26 , Test Loss: 1.9727126753423363e-05
Epoch: 26 , D11: 0.5219336177490911 , D22: 0.5842982732482193
Epoch: 26 , D11*: 0.5220525066449131, D22*: 0.5841859013392615, D12*: 1.4710078670260196
Epoch: 26 , Coefficient 1: 1.0002277854726713 , Coefficient 2: 0.9998076805732575 , Coefficient 3: 0.37601376334604175
Epoch: 27 , Train Loss: 1.93328889690747e-05
Epoch: 27 , Test Loss: 1.9289660787762843e-05
Epoch: 27 , D11: 0.5205978429931822 , D22: 0.5487110014475056
Epoch: 27 , D11*: 0.5207076214963435, D22*: 0.5485199591723736, D12*: 1.5131225809016926
Epoch: 27 , Coefficient 1: 1.0002108700691692 , Coefficient 2: 0.9996518344362916 , Coefficient 3: 0.3533182288613882
Epoch: 28 , Train Loss: 1.8901041471508506e-05
Epoch: 28 , Test Loss: 1.8860932141251396e-05
Epoch: 28 , D11: 0.5423737105912334 , D22: 0.5572208520200703
Epoch: 28 , D11*: 0.5424604878599703, D22*: 0.5571346298695442, D12*: 1.501023561613807
Epoch: 28 , Coefficient 1: 1.0001599953446163 , Coefficient 2: 0.999845263955551 , Coefficient 3: 0.3662817646071119
Epoch: 29 , Train Loss: 1.8497306843528348e-05
Epoch: 29 , Test Loss: 1.8460446470271564e-05
Epoch: 29 , D11: 0.5137318740112009 , D22: 0.5401348498592692
Epoch: 29 , D11*: 0.5138485958760701, D22*: 0.540036048310378, D12*: 1.501251786139348
Epoch: 29 , Coefficient 1: 1.000227203860173 , Coefficient 2: 0.9998170798478992 , Coefficient 3: 0.3510019618017045
Epoch: 30 , Train Loss: 1.8113530120899666e-05
Epoch: 30 , Test Loss: 1.808337996044429e-05
Epoch: 30 , D11: 0.5200827202494203 , D22: 0.6000455015190365
Epoch: 30 , D11*: 0.5201594835088199, D22*: 0.5999664081663049, D12*: 1.487342080415913
Epoch: 30 , Coefficient 1: 1.0001475981731576 , Coefficient 2: 0.999868187741544 , Coefficient 3: 0.3765528812853524
Epoch: 31 , Train Loss: 1.775128695771855e-05
Epoch: 31 , Test Loss: 1.7719107152515787e-05
Epoch: 31 , D11: 0.5330885261757385 , D22: 0.5551049186468433
Epoch: 31 , D11*: 0.5331538771390926, D22*: 0.5550426456542815, D12*: 1.4688139862494072
Epoch: 31 , Coefficient 1: 1.000122589326435 , Coefficient 2: 0.9998878176170487 , Coefficient 3: 0.3704337421146385
Epoch: 32 , Train Loss: 1.7379346556481324e-05
Epoch: 32 , Test Loss: 1.7351026937831194e-05
Epoch: 32 , D11: 0.5032644429655522 , D22: 0.5611424122227654
Epoch: 32 , D11*: 0.5033152886183543, D22*: 0.561084411086213, D12*: 1.4858948535362977
Epoch: 32 , Coefficient 1: 1.0001010316812817 , Coefficient 2: 0.999896637403823 , Coefficient 3: 0.3581679070936246
Epoch: 33 , Train Loss: 1.703284441828146e-05
Epoch: 33 , Test Loss: 1.7005814570438818e-05
Epoch: 33 , D11: 0.5224799655555407 , D22: 0.5698075240639383
Epoch: 33 , D11*: 0.5225331472451197, D22*: 0.569753419033594, D12*: 1.4373829838197854
Epoch: 33 , Coefficient 1: 1.000101787040815 , Coefficient 2: 0.9999050468306238 , Coefficient 3: 0.3799566916313451
Epoch: 34 , Train Loss: 1.6704502926586432e-05
Epoch: 34 , Test Loss: 1.6674309918016658e-05
Epoch: 34 , D11: 0.49530263106956046 , D22: 0.5734644580567507
Epoch: 34 , D11*: 0.49532591731998005, D22*: 0.5734088269889479, D12*: 1.4317117259441459
Epoch: 34 , Coefficient 1: 1.0000470141867999 , Coefficient 2: 0.9999029912542595 , Coefficient 3: 0.373236708529487
Epoch: 35 , Train Loss: 1.636970860272413e-05
Epoch: 35 , Test Loss: 1.634205331720295e-05
Epoch: 35 , D11: 0.46537142492284267 , D22: 0.5488486266206726
Epoch: 35 , D11*: 0.4653958630637987, D22*: 0.5488210246763631, D12*: 1.5136391976815566
Epoch: 35 , Coefficient 1: 1.0000525131962283 , Coefficient 2: 0.999949709367992 , Coefficient 3: 0.3350259722705514
Epoch: 36 , Train Loss: 1.6036157864618872e-05
Epoch: 36 , Test Loss: 1.6004290962882807e-05
Epoch: 36 , D11: 0.5049148906170716 , D22: 0.5476713857141066
Epoch: 36 , D11*: 0.5049468329150147, D22*: 0.5476371506383381, D12*: 1.4398655943720329
Epoch: 36 , Coefficient 1: 1.000063262737021 , Coefficient 2: 0.9999374897490328 , Coefficient 3: 0.3655146659756167
Epoch: 37 , Train Loss: 1.5707286519500485e-05
Epoch: 37 , Test Loss: 1.5676971546781716e-05
Epoch: 37 , D11: 0.5303608172283341 , D22: 0.5480024066363818
Epoch: 37 , D11*: 0.5303704264346394, D22*: 0.5479885054443663, D12*: 1.4437766119087592
Epoch: 37 , Coefficient 1: 1.0000181182432661 , Coefficient 2: 0.9999746329726893 , Coefficient 3: 0.37345075511832493
Epoch: 38 , Train Loss: 1.5404820120238583e-05
Epoch: 38 , Test Loss: 1.537743135122582e-05
Epoch: 38 , D11: 0.5415173060930903 , D22: 0.5388248112004118
Epoch: 38 , D11*: 0.5415321300709072, D22*: 0.5388141878535841, D12*: 1.4641471327645654
Epoch: 38 , Coefficient 1: 1.0000273748920856 , Coefficient 2: 0.9999802842285529 , Coefficient 3: 0.36893365897066943
Epoch: 39 , Train Loss: 1.5120488608772577e-05
Epoch: 39 , Test Loss: 1.5093558526132261e-05
Epoch: 39 , D11: 0.5337096964508828 , D22: 0.5210746777783556
Epoch: 39 , D11*: 0.5337196117211616, D22*: 0.5210645473277403, D12*: 1.4682692929532632
Epoch: 39 , Coefficient 1: 1.0000185780216186 , Coefficient 2: 0.9999805585436267 , Coefficient 3: 0.3591930186482749
