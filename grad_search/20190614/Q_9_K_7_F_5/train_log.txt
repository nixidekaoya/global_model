Optimizer: SGD
Learning Rate: 0.05
Momentum: 0.9
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.004432523460010998
Epoch: 0 , Test Loss: 0.004385643583256752
Epoch: 0 , D11: 1.6830075856212785 , D22: 1.4527375972402636
Epoch: 0 , D11*: 1.680939790554462, D22*: 1.4497056035104907, D12*: 1.5952503276431809
Epoch: 0 , Coefficient 1: 0.9987713691343506 , Coefficient 2: 0.9979129102629871 , Coefficient 3: 0.9812395395931874
Epoch: 1 , Train Loss: 0.0038178466483950618
Epoch: 1 , Test Loss: 0.003729664220940322
Epoch: 1 , D11: 1.2372235098013458 , D22: 1.2023723486756346
Epoch: 1 , D11*: 1.237383849572194, D22*: 1.2012512515169915, D12*: 1.3787966125740008
Epoch: 1 , Coefficient 1: 1.000129596446865 , Coefficient 2: 0.9990675956912367 , Coefficient 3: 0.8843345997698057
Epoch: 2 , Train Loss: 0.0027396662866231054
Epoch: 2 , Test Loss: 0.00260395171190612
Epoch: 2 , D11: 0.9248580378057821 , D22: 1.0766519586698322
Epoch: 2 , D11*: 0.9263200344876955, D22*: 1.076330378167287, D12*: 1.3173449655737006
Epoch: 2 , Coefficient 1: 1.001580779559836 , Coefficient 2: 0.99970131433844 , Coefficient 3: 0.7601085763374187
Epoch: 3 , Train Loss: 0.001411752654850716
Epoch: 3 , Test Loss: 0.001286680540419184
Epoch: 3 , D11: 0.7314537102338345 , D22: 0.773308591810422
Epoch: 3 , D11*: 0.7315258425782815, D22*: 0.7734580377217065, D12*: 1.2902552341475
Epoch: 3 , Coefficient 1: 1.0000986150503275 , Coefficient 2: 1.000193255206094 , Coefficient 3: 0.5832116934965832
Epoch: 4 , Train Loss: 0.0005092136094317538
Epoch: 4 , Test Loss: 0.00045189328535343525
Epoch: 4 , D11: 0.6489703568946263 , D22: 0.6871221040484985
Epoch: 4 , D11*: 0.6492607382722497, D22*: 0.6868509134609669, D12*: 1.3597985795828664
Epoch: 4 , Coefficient 1: 1.000447449370435 , Coefficient 2: 0.999605324023294 , Coefficient 3: 0.4912902807057954
Epoch: 5 , Train Loss: 0.00017260350139622463
Epoch: 5 , Test Loss: 0.00015599797021423
Epoch: 5 , D11: 0.5487678349780035 , D22: 0.5767784194770194
Epoch: 5 , D11*: 0.5488618576484171, D22*: 0.5765842744110798, D12*: 1.3925253415448788
Epoch: 5 , Coefficient 1: 1.0001713341497454 , Coefficient 2: 0.9996633974861342 , Coefficient 3: 0.4041025676455259
Epoch: 6 , Train Loss: 7.759610758330383e-05
Epoch: 6 , Test Loss: 7.288123309263026e-05
Epoch: 6 , D11: 0.5538872471830978 , D22: 0.5878128510485643
Epoch: 6 , D11*: 0.5539911856896732, D22*: 0.5875352433213533, D12*: 1.4169635576796014
Epoch: 6 , Coefficient 1: 1.0001876528248377 , Coefficient 2: 0.9995277276998695 , Coefficient 3: 0.4028072644579418
Epoch: 7 , Train Loss: 4.8276105282639035e-05
Epoch: 7 , Test Loss: 4.663738553790609e-05
Epoch: 7 , D11: 0.5184350676471802 , D22: 0.5818341808691709
Epoch: 7 , D11*: 0.5186068321682792, D22*: 0.5819946126841492, D12*: 1.4715974933403333
Epoch: 7 , Coefficient 1: 1.0003313134697438 , Coefficient 2: 1.0002757345997422 , Coefficient 3: 0.3739478525320832
Epoch: 8 , Train Loss: 3.6960504408853016e-05
Epoch: 8 , Test Loss: 3.6243913047655947e-05
Epoch: 8 , D11: 0.5526198819833997 , D22: 0.5764523841603846
Epoch: 8 , D11*: 0.5526710283760519, D22*: 0.5764074427049527, D12*: 1.4477368313809593
Epoch: 8 , Coefficient 1: 1.000092552574237 , Coefficient 2: 0.9999220378704872 , Coefficient 3: 0.38994603390866467
Epoch: 9 , Train Loss: 3.157810548600537e-05
Epoch: 9 , Test Loss: 3.1193226248433357e-05
Epoch: 9 , D11: 0.524820295971092 , D22: 0.5583303088390976
Epoch: 9 , D11*: 0.5247694022799406, D22*: 0.5583122932051255, D12*: 1.4590288646326088
Epoch: 9 , Coefficient 1: 0.9999030264424945 , Coefficient 2: 0.9999677330180954 , Coefficient 3: 0.37116527360745255
Epoch: 10 , Train Loss: 2.8429473350115586e-05
Epoch: 10 , Test Loss: 2.8178962144011168e-05
Epoch: 10 , D11: 0.5131822800833776 , D22: 0.5477634813429615
Epoch: 10 , D11*: 0.5132539278851602, D22*: 0.547740280659712, D12*: 1.485364056994034
Epoch: 10 , Coefficient 1: 1.0001396147228057 , Coefficient 2: 0.9999576447060827 , Coefficient 3: 0.3571495498187936
Epoch: 11 , Train Loss: 2.6249258695315802e-05
Epoch: 11 , Test Loss: 2.60615017323289e-05
Epoch: 11 , D11: 0.5401402379872331 , D22: 0.5322511467374558
Epoch: 11 , D11*: 0.540597489103695, D22*: 0.5322374593132074, D12*: 1.4413740194834714
Epoch: 11 , Coefficient 1: 1.000846541479979 , Coefficient 2: 0.9999742838989972 , Coefficient 3: 0.3721570299988347
Epoch: 12 , Train Loss: 2.458346734783845e-05
Epoch: 12 , Test Loss: 2.4428597567748516e-05
Epoch: 12 , D11: 0.5376913989314079 , D22: 0.5379433300054344
Epoch: 12 , D11*: 0.5378397940686127, D22*: 0.5378993978889022, D12*: 1.502744678569727
Epoch: 12 , Coefficient 1: 1.0002759857001613 , Coefficient 2: 0.9999183331884945 , Coefficient 3: 0.3579248049580103
Epoch: 13 , Train Loss: 2.320643328857841e-05
Epoch: 13 , Test Loss: 2.307421455407166e-05
Epoch: 13 , D11: 0.5361080977439578 , D22: 0.5580020973087793
Epoch: 13 , D11*: 0.5361144101360209, D22*: 0.557939472966693, D12*: 1.4459834247312076
Epoch: 13 , Coefficient 1: 1.0000117744762476 , Coefficient 2: 0.9998877704180893 , Coefficient 3: 0.3783078921897346
Epoch: 14 , Train Loss: 2.2008300998095362e-05
Epoch: 14 , Test Loss: 2.1890033785894047e-05
Epoch: 14 , D11: 0.5346658790721406 , D22: 0.6138314152165438
Epoch: 14 , D11*: 0.5346348120539319, D22*: 0.6137669995508278, D12*: 1.5372798275094304
Epoch: 14 , Coefficient 1: 0.9999418945187553 , Coefficient 2: 0.9998950596790598 , Coefficient 3: 0.3735174920838265
Epoch: 15 , Train Loss: 2.0958078759576895e-05
Epoch: 15 , Test Loss: 2.0852523994108198e-05
Epoch: 15 , D11: 0.5631035005703701 , D22: 0.5576812191980987
Epoch: 15 , D11*: 0.5631158350295133, D22*: 0.5575710579636441, D12*: 1.4611799368263838
Epoch: 15 , Coefficient 1: 1.000021904426328 , Coefficient 2: 0.9998024655830926 , Coefficient 3: 0.3834869562427877
Epoch: 16 , Train Loss: 2.0025426727443117e-05
Epoch: 16 , Test Loss: 1.9927840996388114e-05
Epoch: 16 , D11: 0.4988059852657317 , D22: 0.5110215492121691
Epoch: 16 , D11*: 0.49888498314824986, D22*: 0.5110114099379187, D12*: 1.55181462607023
Epoch: 16 , Coefficient 1: 1.000158373966736 , Coefficient 2: 0.9999801588127427 , Coefficient 3: 0.32539208489212423
Epoch: 17 , Train Loss: 1.919165696108394e-05
Epoch: 17 , Test Loss: 1.9100921519566326e-05
Epoch: 17 , D11: 0.5330453147317881 , D22: 0.5899769960081286
Epoch: 17 , D11*: 0.5329865496293776, D22*: 0.5899237400339651, D12*: 1.4933857462168585
Epoch: 17 , Coefficient 1: 0.9998897558973199 , Coefficient 2: 0.9999097321174828 , Coefficient 3: 0.37596123188800074
Epoch: 18 , Train Loss: 1.8431492822855943e-05
Epoch: 18 , Test Loss: 1.8346305118029702e-05
Epoch: 18 , D11: 0.5500789414269357 , D22: 0.5139277320831955
Epoch: 18 , D11*: 0.550071012704928, D22*: 0.5139607198171177, D12*: 1.4693292798599453
Epoch: 18 , Coefficient 1: 0.9999855862106134 , Coefficient 2: 1.000064187495367 , Coefficient 3: 0.3620807626672586
Epoch: 19 , Train Loss: 1.7712567458147534e-05
Epoch: 19 , Test Loss: 1.762996738034417e-05
Epoch: 19 , D11: 0.5215541967892928 , D22: 0.5548304671959963
Epoch: 19 , D11*: 0.5216038903355111, D22*: 0.5548660624714523, D12*: 1.4624740090734403
Epoch: 19 , Coefficient 1: 1.0000952797360738 , Coefficient 2: 1.0000641552285978 , Coefficient 3: 0.36803045596993816
Epoch: 20 , Train Loss: 1.7057541432222935e-05
Epoch: 20 , Test Loss: 1.6983567831630352e-05
Epoch: 20 , D11: 0.5442260596167039 , D22: 0.5280045141028207
Epoch: 20 , D11*: 0.5442888903620318, D22*: 0.5279358467536115, D12*: 1.4431390319921995
Epoch: 20 , Coefficient 1: 1.0001154497183984 , Coefficient 2: 0.9998699493141155 , Coefficient 3: 0.37149045010426923
Epoch: 21 , Train Loss: 1.647337054782838e-05
Epoch: 21 , Test Loss: 1.6407340048317562e-05
Epoch: 21 , D11: 0.5742594237806488 , D22: 0.6193809224399803
Epoch: 21 , D11*: 0.5743660051164062, D22*: 0.6194454362074487, D12*: 1.463947202510032
Epoch: 21 , Coefficient 1: 1.0001855978871985 , Coefficient 2: 1.0001041584671582 , Coefficient 3: 0.4077371913676218
Epoch: 22 , Train Loss: 1.592753850309236e-05
Epoch: 22 , Test Loss: 1.5867235419136705e-05
Epoch: 22 , D11: 0.511074724571338 , D22: 0.5713592341912832
Epoch: 22 , D11*: 0.511063266742767, D22*: 0.5713011933164421, D12*: 1.5262799105921265
Epoch: 22 , Coefficient 1: 0.9999775809132793 , Coefficient 2: 0.9998984161428262 , Coefficient 3: 0.35457600291656244
Epoch: 23 , Train Loss: 1.542596120816597e-05
Epoch: 23 , Test Loss: 1.5368096341262566e-05
Epoch: 23 , D11: 0.5256486494565825 , D22: 0.5658482341001407
Epoch: 23 , D11*: 0.5257665162782934, D22*: 0.5657382678441168, D12*: 1.5137788801523633
Epoch: 23 , Coefficient 1: 1.0002242311890894 , Coefficient 2: 0.9998056612190391 , Coefficient 3: 0.3605231908152098
Epoch: 24 , Train Loss: 1.4948788106266875e-05
Epoch: 24 , Test Loss: 1.489770397347456e-05
Epoch: 24 , D11: 0.5380163620598155 , D22: 0.5391404457673171
Epoch: 24 , D11*: 0.5380666792099229, D22*: 0.5390805840128056, D12*: 1.4916627973443823
Epoch: 24 , Coefficient 1: 1.0000935234570092 , Coefficient 2: 0.9998889681622265 , Coefficient 3: 0.36105588513046694
Epoch: 25 , Train Loss: 1.4499842997338418e-05
Epoch: 25 , Test Loss: 1.4453405408858087e-05
Epoch: 25 , D11: 0.5054485619368992 , D22: 0.5365726865239903
Epoch: 25 , D11*: 0.5055347603766679, D22*: 0.5365617552870707, D12*: 1.422320024602827
Epoch: 25 , Coefficient 1: 1.0001705385003734 , Coefficient 2: 0.999979627667986 , Coefficient 3: 0.366336864291402
Epoch: 26 , Train Loss: 1.4107876814705378e-05
Epoch: 26 , Test Loss: 1.4061890258744826e-05
Epoch: 26 , D11: 0.5329263105512202 , D22: 0.5926056154835299
Epoch: 26 , D11*: 0.5329611150180686, D22*: 0.5926311762059743, D12*: 1.4566988574541415
Epoch: 26 , Coefficient 1: 1.0000653082164632 , Coefficient 2: 1.0000431327712336 , Coefficient 3: 0.3863503720979192
Epoch: 27 , Train Loss: 1.3735039314724415e-05
Epoch: 27 , Test Loss: 1.369515242004127e-05
Epoch: 27 , D11: 0.5269473741788897 , D22: 0.5683518540683232
Epoch: 27 , D11*: 0.5269165786360213, D22*: 0.5683806294496972, D12*: 1.4597608378956108
Epoch: 27 , Coefficient 1: 0.9999415585988707 , Coefficient 2: 1.0000506295196683 , Coefficient 3: 0.37516323895381976
Epoch: 28 , Train Loss: 1.3403086940797948e-05
Epoch: 28 , Test Loss: 1.3365211509153597e-05
Epoch: 28 , D11: 0.509236096145006 , D22: 0.5506012038335065
Epoch: 28 , D11*: 0.5092559792775776, D22*: 0.5506116821297711, D12*: 1.4787079255547277
Epoch: 28 , Coefficient 1: 1.0000390450180616 , Coefficient 2: 1.0000190306453955 , Coefficient 3: 0.35837626994855865
Epoch: 29 , Train Loss: 1.30848829403476e-05
Epoch: 29 , Test Loss: 1.3049661032709991e-05
Epoch: 29 , D11: 0.5091194215793069 , D22: 0.5695739957091689
Epoch: 29 , D11*: 0.509175667969743, D22*: 0.5695691654132046, D12*: 1.4588898715547338
Epoch: 29 , Coefficient 1: 1.00011047779372 , Coefficient 2: 0.999991519458401 , Coefficient 3: 0.36971427878697
Epoch: 30 , Train Loss: 1.2791590590495618e-05
Epoch: 30 , Test Loss: 1.2758913782818127e-05
Epoch: 30 , D11: 0.5236208416153496 , D22: 0.5578503577335041
Epoch: 30 , D11*: 0.5236261746477415, D22*: 0.5577827906611432, D12*: 1.4703852795087182
Epoch: 30 , Coefficient 1: 1.0000101849123795 , Coefficient 2: 0.9998788795750971 , Coefficient 3: 0.36772979857027766
Epoch: 31 , Train Loss: 1.2522668047495243e-05
Epoch: 31 , Test Loss: 1.2493419935708516e-05
Epoch: 31 , D11: 0.5546836496462936 , D22: 0.5636211991854054
Epoch: 31 , D11*: 0.5546654946779491, D22*: 0.5635673570817412, D12*: 1.4758850648584108
Epoch: 31 , Coefficient 1: 0.9999672696890272 , Coefficient 2: 0.9999044711168742 , Coefficient 3: 0.3788346661895952
Epoch: 32 , Train Loss: 1.2282595147553363e-05
Epoch: 32 , Test Loss: 1.2255320350959668e-05
Epoch: 32 , D11: 0.5181352998163455 , D22: 0.5769567942397859
Epoch: 32 , D11*: 0.5181261384927123, D22*: 0.5769639567685944, D12*: 1.492946430677278
Epoch: 32 , Coefficient 1: 0.9999823186653437 , Coefficient 2: 1.0000124143244 , Coefficient 3: 0.36675465132547225
Epoch: 33 , Train Loss: 1.2062967840847705e-05
Epoch: 33 , Test Loss: 1.2036632348099374e-05
Epoch: 33 , D11: 0.544529427390047 , D22: 0.5367338257787153
Epoch: 33 , D11*: 0.5445263065178998, D22*: 0.5367697906575245, D12*: 1.4228741396037201
Epoch: 33 , Coefficient 1: 0.9999942686804603 , Coefficient 2: 1.0000670069168027 , Coefficient 3: 0.3799689892025771
Epoch: 34 , Train Loss: 1.1864103676543889e-05
Epoch: 34 , Test Loss: 1.1837918014862225e-05
Epoch: 34 , D11: 0.5311595183557275 , D22: 0.5985461432030944
Epoch: 34 , D11*: 0.5312023722939759, D22*: 0.5985386606999104, D12*: 1.5515126392630165
Epoch: 34 , Coefficient 1: 1.0000806799779869 , Coefficient 2: 0.9999874988699384 , Coefficient 3: 0.3640772896089729
Epoch: 35 , Train Loss: 1.1677499409870507e-05
Epoch: 35 , Test Loss: 1.165405728170299e-05
Epoch: 35 , D11: 0.5450412191851075 , D22: 0.5484376065773797
Epoch: 35 , D11*: 0.5450438215245251, D22*: 0.5484216183201974, D12*: 1.4415480514684036
Epoch: 35 , Coefficient 1: 1.000004774573603 , Coefficient 2: 0.9999708476278969 , Coefficient 3: 0.3792677735337668
Epoch: 36 , Train Loss: 1.1509626179304178e-05
Epoch: 36 , Test Loss: 1.1488692754937801e-05
Epoch: 36 , D11: 0.5048419464852179 , D22: 0.5491501352080552
Epoch: 36 , D11*: 0.5048314035741065, D22*: 0.549151783578192, D12*: 1.4527920163314276
Epoch: 36 , Coefficient 1: 0.9999791164122063 , Coefficient 2: 1.0000030016748265 , Coefficient 3: 0.36274400440807897
Epoch: 37 , Train Loss: 1.1345454400270684e-05
Epoch: 37 , Test Loss: 1.1325297684379618e-05
Epoch: 37 , D11: 0.5419396327180858 , D22: 0.553463527296529
Epoch: 37 , D11*: 0.5419623339954185, D22*: 0.5534431842369961, D12*: 1.5227721110964438
Epoch: 37 , Coefficient 1: 1.0000418889410594 , Coefficient 2: 0.9999632440828896 , Coefficient 3: 0.35967480302869753
Epoch: 38 , Train Loss: 1.119249583916826e-05
Epoch: 38 , Test Loss: 1.1175049463417964e-05
Epoch: 38 , D11: 0.5448338427677726 , D22: 0.5543655481967572
Epoch: 38 , D11*: 0.5448408483970133, D22*: 0.5543461641110125, D12*: 1.4674450829954446
Epoch: 38 , Coefficient 1: 1.0000128582857577 , Coefficient 2: 0.9999650337474834 , Coefficient 3: 0.3745240708648168
Epoch: 39 , Train Loss: 1.1052005836972966e-05
Epoch: 39 , Test Loss: 1.103474696537887e-05
Epoch: 39 , D11: 0.5211798440231739 , D22: 0.5375421699025082
Epoch: 39 , D11*: 0.5212032200618775, D22*: 0.5375312565380085, D12*: 1.4538734627381602
Epoch: 39 , Coefficient 1: 1.0000448521541492 , Coefficient 2: 0.99997969765888 , Coefficient 3: 0.36410819226520336
