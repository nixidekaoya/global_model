Optimizer: SGD
Learning Rate: 0.05
Momentum: 0.9
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.004466139479191044
Epoch: 0 , Test Loss: 0.004421597418840973
Epoch: 0 , D11: 1.412967864649207 , D22: 1.6035731532200495
Epoch: 0 , D11*: 1.4098224924498386, D22*: 1.6075960749741267, D12*: 1.5411655450357609
Epoch: 0 , Coefficient 1: 0.9977739251698061 , Coefficient 2: 1.0025087235627506 , Coefficient 3: 0.9789404445042761
Epoch: 1 , Train Loss: 0.0038822458931244905
Epoch: 1 , Test Loss: 0.003803239816799759
Epoch: 1 , D11: 1.1776046182505517 , D22: 1.541761851466774
Epoch: 1 , D11*: 1.1748807140069237, D22*: 1.543512571353833, D12*: 1.5320844736349204
Epoch: 1 , Coefficient 1: 0.99768691103838 , Coefficient 2: 1.0011355319794646 , Coefficient 3: 0.8871551576106244
Epoch: 2 , Train Loss: 0.0028513826462440196
Epoch: 2 , Test Loss: 0.0027274409201927486
Epoch: 2 , D11: 0.8737505844755707 , D22: 1.078694779486819
Epoch: 2 , D11*: 0.8736741330223966, D22*: 1.07957580680095, D12*: 1.4547399720753527
Epoch: 2 , Coefficient 1: 0.9999125019719214 , Coefficient 2: 1.0008167531083725 , Coefficient 3: 0.6713398879927706
Epoch: 3 , Train Loss: 0.0015357896646601148
Epoch: 3 , Test Loss: 0.0014160490341018884
Epoch: 3 , D11: 0.7618742062392324 , D22: 0.7686497803294984
Epoch: 3 , D11*: 0.7614338992801409, D22*: 0.7685508571347913, D12*: 1.358653180573463
Epoch: 3 , Coefficient 1: 0.999422073938866 , Coefficient 2: 0.9998713026436244 , Coefficient 3: 0.5630519908580177
Epoch: 4 , Train Loss: 0.0005840374016406714
Epoch: 4 , Test Loss: 0.000525417814787943
Epoch: 4 , D11: 0.5127601766638016 , D22: 0.6907901921068285
Epoch: 4 , D11*: 0.5124641234261904, D22*: 0.6906496953470166, D12*: 1.4364683776408627
Epoch: 4 , Coefficient 1: 0.9994226282556937 , Coefficient 2: 0.9997966144258891 , Coefficient 3: 0.4187749056993173
Epoch: 5 , Train Loss: 0.00020638700098061236
Epoch: 5 , Test Loss: 0.00018858305684989315
Epoch: 5 , D11: 0.5636831144105863 , D22: 0.6087459447821892
Epoch: 5 , D11*: 0.563767388159486, D22*: 0.6089295920410809, D12*: 1.435858022781796
Epoch: 5 , Coefficient 1: 1.000149505540871 , Coefficient 2: 1.0003016812850514 , Coefficient 3: 0.4083610501853841
Epoch: 6 , Train Loss: 9.634519787869065e-05
Epoch: 6 , Test Loss: 9.119123370328454e-05
Epoch: 6 , D11: 0.5477060276018924 , D22: 0.5914981622948131
Epoch: 6 , D11*: 0.5475474972589027, D22*: 0.5915716564876304, D12*: 1.5139335005565584
Epoch: 6 , Coefficient 1: 0.9997105557817507 , Coefficient 2: 1.000124250923337 , Coefficient 3: 0.37621175346465535
Epoch: 7 , Train Loss: 6.2069781266473e-05
Epoch: 7 , Test Loss: 6.0228230468055705e-05
Epoch: 7 , D11: 0.5167816639081843 , D22: 0.5794641583648192
Epoch: 7 , D11*: 0.5167288331196233, D22*: 0.5791115580324285, D12*: 1.4965752661241747
Epoch: 7 , Coefficient 1: 0.9998977696148089 , Coefficient 2: 0.9993915062263977 , Coefficient 3: 0.36611603036513335
Epoch: 8 , Train Loss: 4.8733182306023084e-05
Epoch: 8 , Test Loss: 4.7897617172566246e-05
Epoch: 8 , D11: 0.5433274623283801 , D22: 0.5775101341086191
Epoch: 8 , D11*: 0.5433093219451537, D22*: 0.5774219004146077, D12*: 1.468905835250859
Epoch: 8 , Coefficient 1: 0.9999666124308374 , Coefficient 2: 0.999847217063736 , Coefficient 3: 0.38148504671450345
Epoch: 9 , Train Loss: 4.220801675546682e-05
Epoch: 9 , Test Loss: 4.1733743244549255e-05
Epoch: 9 , D11: 0.5288510927615282 , D22: 0.5462404298815688
Epoch: 9 , D11*: 0.5288816544093834, D22*: 0.5461994740961443, D12*: 1.4556239029638463
Epoch: 9 , Coefficient 1: 1.000057788758071 , Coefficient 2: 0.9999250224201943 , Coefficient 3: 0.3692853374819271
Epoch: 10 , Train Loss: 3.8291580500299465e-05
Epoch: 10 , Test Loss: 3.7966213611071006e-05
Epoch: 10 , D11: 0.4928729159423889 , D22: 0.5695580566231201
Epoch: 10 , D11*: 0.49274547228833754, D22*: 0.5695232790053955, D12*: 1.4485616912079737
Epoch: 10 , Coefficient 1: 0.999741426948146 , Coefficient 2: 0.9999389392928074 , Coefficient 3: 0.3666632763178673
Epoch: 11 , Train Loss: 3.549797191772086e-05
Epoch: 11 , Test Loss: 3.524959018250228e-05
Epoch: 11 , D11: 0.5154633346174886 , D22: 0.5334265132622529
Epoch: 11 , D11*: 0.5154572196449789, D22*: 0.533480383401109, D12*: 1.4916300434983236
Epoch: 11 , Coefficient 1: 0.999988136939916 , Coefficient 2: 1.0001009888663515 , Coefficient 3: 0.3516078291725782
Epoch: 12 , Train Loss: 3.32728657831467e-05
Epoch: 12 , Test Loss: 3.305688878026558e-05
Epoch: 12 , D11: 0.5544612588233353 , D22: 0.5847217503251966
Epoch: 12 , D11*: 0.5543245129293866, D22*: 0.5846886351394545, D12*: 1.4890031129195758
Epoch: 12 , Coefficient 1: 0.9997533715985154 , Coefficient 2: 0.9999433659074188 , Coefficient 3: 0.38247507281415655
Epoch: 13 , Train Loss: 3.138445127115119e-05
Epoch: 13 , Test Loss: 3.118887019809335e-05
Epoch: 13 , D11: 0.5501113335071514 , D22: 0.5202442212166271
Epoch: 13 , D11*: 0.5501146216939338, D22*: 0.5203071385057355, D12*: 1.4896631842480637
Epoch: 13 , Coefficient 1: 1.000005977311468 , Coefficient 2: 1.0001209379874731 , Coefficient 3: 0.3592831492106672
Epoch: 14 , Train Loss: 2.9699116044866968e-05
Epoch: 14 , Test Loss: 2.952998867840506e-05
Epoch: 14 , D11: 0.5220703817253216 , D22: 0.5570934002816974
Epoch: 14 , D11*: 0.5221252917156356, D22*: 0.5571007792961776, D12*: 1.4470990384990672
Epoch: 14 , Coefficient 1: 1.0001051773711669 , Coefficient 2: 1.000013245560756 , Coefficient 3: 0.37289295421382757
Epoch: 15 , Train Loss: 2.8211322204697356e-05
Epoch: 15 , Test Loss: 2.8065171161870243e-05
Epoch: 15 , D11: 0.5562281801804824 , D22: 0.5467961805685085
Epoch: 15 , D11*: 0.5562094194030723, D22*: 0.5468828917510434, D12*: 1.4701511280477064
Epoch: 15 , Coefficient 1: 0.9999662714366541 , Coefficient 2: 1.0001585804466386 , Coefficient 3: 0.3751628965584552
Epoch: 16 , Train Loss: 2.687844338470313e-05
Epoch: 16 , Test Loss: 2.6741545145341666e-05
Epoch: 16 , D11: 0.5492944719613762 , D22: 0.5894847119350886
Epoch: 16 , D11*: 0.549293840386759, D22*: 0.5895981424736781, D12*: 1.44070514018919
Epoch: 16 , Coefficient 1: 0.9999988502075855 , Coefficient 2: 1.0001924232067312 , Coefficient 3: 0.3952550563923443
Epoch: 17 , Train Loss: 2.566552770895214e-05
Epoch: 17 , Test Loss: 2.5544267136865527e-05
Epoch: 17 , D11: 0.5077110683115283 , D22: 0.577094675132425
Epoch: 17 , D11*: 0.5076762216998405, D22*: 0.5772257483391303, D12*: 1.4630232775827448
Epoch: 17 , Coefficient 1: 0.9999313652707952 , Coefficient 2: 1.000227126002636 , Coefficient 3: 0.37077399473488953
Epoch: 18 , Train Loss: 2.4588870361185398e-05
Epoch: 18 , Test Loss: 2.4479355157382088e-05
Epoch: 18 , D11: 0.5174313234433852 , D22: 0.5667352566087466
Epoch: 18 , D11*: 0.5175100156633733, D22*: 0.5667561263181177, D12*: 1.4421458720196776
Epoch: 18 , Coefficient 1: 1.0001520824434524 , Coefficient 2: 1.0000368244416202 , Coefficient 3: 0.3759211058389718
Epoch: 19 , Train Loss: 2.3569273974317186e-05
Epoch: 19 , Test Loss: 2.346600871896953e-05
Epoch: 19 , D11: 0.48206843979891917 , D22: 0.6051895789475955
Epoch: 19 , D11*: 0.4820026117399671, D22*: 0.6052514516121119, D12*: 1.4392829968918395
Epoch: 19 , Coefficient 1: 0.99986344665297 , Coefficient 2: 1.000102236830687 , Coefficient 3: 0.37770683934293187
Epoch: 20 , Train Loss: 2.2623268276220192e-05
Epoch: 20 , Test Loss: 2.252689048691536e-05
Epoch: 20 , D11: 0.5095207936811185 , D22: 0.5168949697443452
Epoch: 20 , D11*: 0.5095107039847646, D22*: 0.5169752698615272, D12*: 1.4568642116489021
Epoch: 20 , Coefficient 1: 0.9999801976749939 , Coefficient 2: 1.000155350935649 , Coefficient 3: 0.3522929472900218
Epoch: 21 , Train Loss: 2.1789845719467846e-05
Epoch: 21 , Test Loss: 2.1708087180741128e-05
Epoch: 21 , D11: 0.5272610959785996 , D22: 0.563788109997764
Epoch: 21 , D11*: 0.5272442273113015, D22*: 0.5637915242960025, D12*: 1.444132257450253
Epoch: 21 , Coefficient 1: 0.999968006994207 , Coefficient 2: 1.000006055995467 , Coefficient 3: 0.3777478641511779
Epoch: 22 , Train Loss: 2.1029773217378533e-05
Epoch: 22 , Test Loss: 2.095220114279073e-05
Epoch: 22 , D11: 0.5221010297712092 , D22: 0.5604576656717342
Epoch: 22 , D11*: 0.5219819985817435, D22*: 0.5605021741945725, D12*: 1.4942747691489104
Epoch: 22 , Coefficient 1: 0.9997720150264445 , Coefficient 2: 1.0000794146026801 , Coefficient 3: 0.36221055027010296
Epoch: 23 , Train Loss: 2.027013557017199e-05
Epoch: 23 , Test Loss: 2.018999198480742e-05
Epoch: 23 , D11: 0.5313732051340371 , D22: 0.5491731457259651
Epoch: 23 , D11*: 0.5312640031686329, D22*: 0.5493747427491359, D12*: 1.503528722860409
Epoch: 23 , Coefficient 1: 0.9997944910199665 , Coefficient 2: 1.0003670919176215 , Coefficient 3: 0.35936750974131465
Epoch: 24 , Train Loss: 1.9562671994208356e-05
Epoch: 24 , Test Loss: 1.949158697607345e-05
Epoch: 24 , D11: 0.5176144236395591 , D22: 0.5266756139741728
Epoch: 24 , D11*: 0.5175263718179677, D22*: 0.526792516589326, D12*: 1.5012483578747637
Epoch: 24 , Coefficient 1: 0.9998298891654288 , Coefficient 2: 1.000221963219962 , Coefficient 3: 0.3478168295503348
Epoch: 25 , Train Loss: 1.8936266271339263e-05
Epoch: 25 , Test Loss: 1.8871326072257942e-05
Epoch: 25 , D11: 0.5588149713183498 , D22: 0.5530203002133561
Epoch: 25 , D11*: 0.5587299449607542, D22*: 0.5530513664171401, D12*: 1.491524216000376
Epoch: 25 , Coefficient 1: 0.999847845240447 , Coefficient 2: 1.0000561755215351 , Coefficient 3: 0.37269971866739504
Epoch: 26 , Train Loss: 1.8344148638789197e-05
Epoch: 26 , Test Loss: 1.8282633314811393e-05
Epoch: 26 , D11: 0.5346017622298359 , D22: 0.5620182406898097
Epoch: 26 , D11*: 0.5346167282059804, D22*: 0.5621110797762457, D12*: 1.4986457883788173
Epoch: 26 , Coefficient 1: 1.000027994625536 , Coefficient 2: 1.0001651887424903 , Coefficient 3: 0.3659062790176149
Epoch: 27 , Train Loss: 1.7790791480365443e-05
Epoch: 27 , Test Loss: 1.7737591799232177e-05
Epoch: 27 , D11: 0.5624582833563232 , D22: 0.5464199423449121
Epoch: 27 , D11*: 0.5623840921448456, D22*: 0.5465132532731334, D12*: 1.4441731410102852
Epoch: 27 , Coefficient 1: 0.9998680947304486 , Coefficient 2: 1.0001707677941272 , Coefficient 3: 0.38392119127843605
Epoch: 28 , Train Loss: 1.7270014634959805e-05
Epoch: 28 , Test Loss: 1.7216414351423736e-05
Epoch: 28 , D11: 0.49579036726581166 , D22: 0.5361452886515343
Epoch: 28 , D11*: 0.49576457032431703, D22*: 0.5362920252173855, D12*: 1.4750812336719035
Epoch: 28 , Coefficient 1: 0.9999479680461787 , Coefficient 2: 1.0002736880635847 , Coefficient 3: 0.3498304269564244
Epoch: 29 , Train Loss: 1.6795422962786686e-05
Epoch: 29 , Test Loss: 1.6743265259719916e-05
Epoch: 29 , D11: 0.5327809692779666 , D22: 0.5137769355682559
Epoch: 29 , D11*: 0.5327073337178384, D22*: 0.513859739060206, D12*: 1.5077810098080267
Epoch: 29 , Coefficient 1: 0.9998617901832568 , Coefficient 2: 1.0001611662303573 , Coefficient 3: 0.3470553966292808
Epoch: 30 , Train Loss: 1.634608928543457e-05
Epoch: 30 , Test Loss: 1.629787221099832e-05
Epoch: 30 , D11: 0.5196869174704275 , D22: 0.5397310760914045
Epoch: 30 , D11*: 0.5196133010463152, D22*: 0.5397609886968446, D12*: 1.4857465700556207
Epoch: 30 , Coefficient 1: 0.9998583446655331 , Coefficient 2: 1.0000554213139936 , Coefficient 3: 0.35651244670330984
Epoch: 31 , Train Loss: 1.5940616879561274e-05
Epoch: 31 , Test Loss: 1.5901723938441135e-05
Epoch: 31 , D11: 0.5059560666243977 , D22: 0.5446009439833787
Epoch: 31 , D11*: 0.5059090348091855, D22*: 0.5447247110041464, D12*: 1.4792035724416357
Epoch: 31 , Coefficient 1: 0.9999070436776734 , Coefficient 2: 1.000227261855006 , Coefficient 3: 0.3551349406488762
Epoch: 32 , Train Loss: 1.5579170752062054e-05
Epoch: 32 , Test Loss: 1.5541380413196748e-05
Epoch: 32 , D11: 0.49394961521305747 , D22: 0.5128274208176153
Epoch: 32 , D11*: 0.4937859307962105, D22*: 0.5128900296838371, D12*: 1.4742153588393547
Epoch: 32 , Coefficient 1: 0.9996686212281463 , Coefficient 2: 1.0001220856445663 , Coefficient 3: 0.34142771422236456
Epoch: 33 , Train Loss: 1.5235462946293409e-05
Epoch: 33 , Test Loss: 1.5200438632746227e-05
Epoch: 33 , D11: 0.5385300158563856 , D22: 0.5860972731908746
Epoch: 33 , D11*: 0.5385214847047965, D22*: 0.5861996621813249, D12*: 1.48730584974182
Epoch: 33 , Coefficient 1: 0.99998415844737 , Coefficient 2: 1.000174696240938 , Coefficient 3: 0.3781068793218829
Epoch: 34 , Train Loss: 1.4911858123923594e-05
Epoch: 34 , Test Loss: 1.4877160163450756e-05
Epoch: 34 , D11: 0.5314826417806418 , D22: 0.5854851118010925
Epoch: 34 , D11*: 0.5314271564723191, D22*: 0.5856098911527965, D12*: 1.5492631539333337
Epoch: 34 , Coefficient 1: 0.9998956027836831 , Coefficient 2: 1.000213121306057 , Coefficient 3: 0.3605059104352723
Epoch: 35 , Train Loss: 1.4582996143417404e-05
Epoch: 35 , Test Loss: 1.4548863930031073e-05
Epoch: 35 , D11: 0.5238204682852792 , D22: 0.5444291505473526
Epoch: 35 , D11*: 0.5237626026529606, D22*: 0.5444560943464256, D12*: 1.5137543211457585
Epoch: 35 , Coefficient 1: 0.9998895315555194 , Coefficient 2: 1.0000494900007575 , Coefficient 3: 0.3528375384556633
Epoch: 36 , Train Loss: 1.425939404543897e-05
Epoch: 36 , Test Loss: 1.4222242756659398e-05
Epoch: 36 , D11: 0.5065677166117057 , D22: 0.5531190964796118
Epoch: 36 , D11*: 0.5065217043643576, D22*: 0.5531970592778459, D12*: 1.4744576707801307
Epoch: 36 , Coefficient 1: 0.9999091686148973 , Coefficient 2: 1.0001409511960992 , Coefficient 3: 0.35935882889113724
Epoch: 37 , Train Loss: 1.3934456977494849e-05
Epoch: 37 , Test Loss: 1.3896029277020717e-05
Epoch: 37 , D11: 0.5250529704382371 , D22: 0.5567777161106339
Epoch: 37 , D11*: 0.5250223101734232, D22*: 0.5567961345823513, D12*: 1.49258205450699
Epoch: 37 , Coefficient 1: 0.9999416053873796 , Coefficient 2: 1.0000330804757167 , Coefficient 3: 0.3623983155529451
Epoch: 38 , Train Loss: 1.362958288973459e-05
Epoch: 38 , Test Loss: 1.3592875227914192e-05
Epoch: 38 , D11: 0.5071766221948951 , D22: 0.5453965873304794
Epoch: 38 , D11*: 0.5071384277895757, D22*: 0.5454279399954075, D12*: 1.4648061219052004
Epoch: 38 , Coefficient 1: 0.9999246921020254 , Coefficient 2: 1.0000574859939657 , Coefficient 3: 0.35928521599020985
Epoch: 39 , Train Loss: 1.3343979922410652e-05
Epoch: 39 , Test Loss: 1.3308674166182756e-05
Epoch: 39 , D11: 0.49889630531640194 , D22: 0.5287947324440571
Epoch: 39 , D11*: 0.49886606336962624, D22*: 0.5288180029423942, D12*: 1.3963706875693953
Epoch: 39 , Coefficient 1: 0.9999393822995812 , Coefficient 2: 1.0000440066757654 , Coefficient 3: 0.36798397283061984
