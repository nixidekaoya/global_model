Optimizer: SGD
Learning Rate: 0.05
Momentum: 0.9
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.00416609872400295
Epoch: 0 , Test Loss: 0.004139684804715216
Epoch: 0 , D11: 1.6355368286494212 , D22: 1.4887922522677857
Epoch: 0 , D11*: 1.6308830811253614, D22*: 1.4895623915856873, D12*: 1.6209878519536534
Epoch: 0 , Coefficient 1: 0.9971546054833246 , Coefficient 2: 1.000517291325723 , Coefficient 3: 0.9625135280780214
Epoch: 1 , Train Loss: 0.00388448293809779
Epoch: 1 , Test Loss: 0.0038527252688072633
Epoch: 1 , D11: 1.4860497508413497 , D22: 1.5051367359737573
Epoch: 1 , D11*: 1.4838414003620946, D22*: 1.5062424365217872, D12*: 1.525864890227019
Epoch: 1 , Coefficient 1: 0.998513945796226 , Coefficient 2: 1.0007346180061938 , Coefficient 3: 0.9797996716599905
Epoch: 2 , Train Loss: 0.003486317225266248
Epoch: 2 , Test Loss: 0.0034314425280317653
Epoch: 2 , D11: 1.3124265960507444 , D22: 1.3748636744932365
Epoch: 2 , D11*: 1.308428121946568, D22*: 1.3759930645918148, D12*: 1.5337731533892305
Epoch: 2 , Coefficient 1: 0.9969533731515284 , Coefficient 2: 1.000821456061085 , Coefficient 3: 0.8751037207185842
Epoch: 3 , Train Loss: 0.0027173477357719097
Epoch: 3 , Test Loss: 0.00261498160706833
Epoch: 3 , D11: 1.2248801817569814 , D22: 1.1495276275485444
Epoch: 3 , D11*: 1.2211651902467335, D22*: 1.1524819826012602, D12*: 1.4834810695870309
Epoch: 3 , Coefficient 1: 0.996967057214593 , Coefficient 2: 1.0025700600680787 , Coefficient 3: 0.8000261080206321
Epoch: 4 , Train Loss: 0.0016172848318819892
Epoch: 4 , Test Loss: 0.0015061471762601287
Epoch: 4 , D11: 0.7940516098293732 , D22: 0.7127975536523914
Epoch: 4 , D11*: 0.7940053374609307, D22*: 0.7131676897608497, D12*: 1.4380101249020414
Epoch: 4 , Coefficient 1: 0.9999417262456626 , Coefficient 2: 1.0005192724169178 , Coefficient 3: 0.524048127729438
Epoch: 5 , Train Loss: 0.0007036942285776604
Epoch: 5 , Test Loss: 0.0006370492323767395
Epoch: 5 , D11: 0.5884171928366605 , D22: 0.6444895762047601
Epoch: 5 , D11*: 0.5879756327564306, D22*: 0.6447669460884988, D12*: 1.3937185599632007
Epoch: 5 , Coefficient 1: 0.9992495799143781 , Coefficient 2: 1.0004303714039444 , Coefficient 3: 0.4422494663762956
Epoch: 6 , Train Loss: 0.00026490130067395514
Epoch: 6 , Test Loss: 0.000240400945476722
Epoch: 6 , D11: 0.5674947119744254 , D22: 0.592696373754413
Epoch: 6 , D11*: 0.5670929579201703, D22*: 0.5927247290871146, D12*: 1.4595227775455109
Epoch: 6 , Coefficient 1: 0.9992920567438289 , Coefficient 2: 1.0000478412454628 , Coefficient 3: 0.3973277104170166
Epoch: 7 , Train Loss: 0.0001156003776595753
Epoch: 7 , Test Loss: 0.00010773334228724707
Epoch: 7 , D11: 0.5705248073268548 , D22: 0.5979547975806805
Epoch: 7 , D11*: 0.5700621520406414, D22*: 0.5979426752778271, D12*: 1.4611277459461303
Epoch: 7 , Coefficient 1: 0.9991890706937333 , Coefficient 2: 0.999979727058128 , Coefficient 3: 0.39969291889743197
Epoch: 8 , Train Loss: 6.565020590278438e-05
Epoch: 8 , Test Loss: 6.278198214567965e-05
Epoch: 8 , D11: 0.5346210839600792 , D22: 0.5861224635999062
Epoch: 8 , D11*: 0.5342865869321181, D22*: 0.5863544819748147, D12*: 1.476464496288341
Epoch: 8 , Coefficient 1: 0.9993743287760305 , Coefficient 2: 1.0003958530670936 , Coefficient 3: 0.3795015294049038
Epoch: 9 , Train Loss: 4.595070563664194e-05
Epoch: 9 , Test Loss: 4.467898193979636e-05
Epoch: 9 , D11: 0.5276328181013489 , D22: 0.5713027437838271
Epoch: 9 , D11*: 0.5274242821865108, D22*: 0.5714708535288316, D12*: 1.466294566374679
Epoch: 9 , Coefficient 1: 0.999604770765419 , Coefficient 2: 1.0002942568486388 , Coefficient 3: 0.37471840955951013
Epoch: 10 , Train Loss: 3.6643566169004774e-05
Epoch: 10 , Test Loss: 3.596973150706617e-05
Epoch: 10 , D11: 0.523101007632939 , D22: 0.558148247529659
Epoch: 10 , D11*: 0.5226844169756233, D22*: 0.5585456753572501, D12*: 1.4736012769716962
Epoch: 10 , Coefficient 1: 0.9992036133533736 , Coefficient 2: 1.0007120470759339 , Coefficient 3: 0.3668665700924338
Epoch: 11 , Train Loss: 3.143455148801877e-05
Epoch: 11 , Test Loss: 3.1016163389722354e-05
Epoch: 11 , D11: 0.5338815710022218 , D22: 0.537642972039851
Epoch: 11 , D11*: 0.5334443831163991, D22*: 0.5377770603639711, D12*: 1.4871101308422123
Epoch: 11 , Coefficient 1: 0.9991811144838695 , Coefficient 2: 1.0002494003104168 , Coefficient 3: 0.3601688339227751
Epoch: 12 , Train Loss: 2.800652381756663e-05
Epoch: 12 , Test Loss: 2.7707475954230174e-05
Epoch: 12 , D11: 0.5130582284223343 , D22: 0.5338792776088266
Epoch: 12 , D11*: 0.5126891084701705, D22*: 0.5340365194060317, D12*: 1.5014444257380637
Epoch: 12 , Coefficient 1: 0.999280549591225 , Coefficient 2: 1.0002945268786407 , Coefficient 3: 0.3485728841950524
Epoch: 13 , Train Loss: 2.550059202894772e-05
Epoch: 13 , Test Loss: 2.5269626312365287e-05
Epoch: 13 , D11: 0.5016190975991567 , D22: 0.565307413536383
Epoch: 13 , D11*: 0.5012133615913499, D22*: 0.5655897985690719, D12*: 1.456929825872692
Epoch: 13 , Coefficient 1: 0.9991911472076148 , Coefficient 2: 1.0004995247292483 , Coefficient 3: 0.3661134329244078
Epoch: 14 , Train Loss: 2.3544890058474267e-05
Epoch: 14 , Test Loss: 2.3359106173302285e-05
Epoch: 14 , D11: 0.531646317496009 , D22: 0.5493765592916197
Epoch: 14 , D11*: 0.5313428525875951, D22*: 0.5496063189195878, D12*: 1.4662625213651723
Epoch: 14 , Coefficient 1: 0.9994291977609415 , Coefficient 2: 1.0004182188411248 , Coefficient 3: 0.36860697036051865
Epoch: 15 , Train Loss: 2.196021402960469e-05
Epoch: 15 , Test Loss: 2.1806167806062144e-05
Epoch: 15 , D11: 0.5535785199388443 , D22: 0.5407599192269578
Epoch: 15 , D11*: 0.5532659144957034, D22*: 0.5411192283030656, D12*: 1.4580734687720034
Epoch: 15 , Coefficient 1: 0.9994353006269545 , Coefficient 2: 1.000664452122527 , Coefficient 3: 0.37528463628121067
Epoch: 16 , Train Loss: 2.064651694126951e-05
Epoch: 16 , Test Loss: 2.0511540784355024e-05
Epoch: 16 , D11: 0.5521409544957886 , D22: 0.5651588983168788
Epoch: 16 , D11*: 0.5517682323259862, D22*: 0.5654733369882136, D12*: 1.4682348989625391
Epoch: 16 , Coefficient 1: 0.9993249510532273 , Coefficient 2: 1.0005563721499762 , Coefficient 3: 0.3804709893844804
Epoch: 17 , Train Loss: 1.9492344279569807e-05
Epoch: 17 , Test Loss: 1.9374732568394392e-05
Epoch: 17 , D11: 0.5202508623793295 , D22: 0.5519984047058417
Epoch: 17 , D11*: 0.5199234276730246, D22*: 0.5522607032817387, D12*: 1.4528709825694694
Epoch: 17 , Coefficient 1: 0.9993706215020819 , Coefficient 2: 1.0004751799528058 , Coefficient 3: 0.3689880738957826
Epoch: 18 , Train Loss: 1.848941176376684e-05
Epoch: 18 , Test Loss: 1.8386381590971725e-05
Epoch: 18 , D11: 0.5095762793692706 , D22: 0.5802364068172522
Epoch: 18 , D11*: 0.5093658804814024, D22*: 0.5804297652063692, D12*: 1.4737984948698795
Epoch: 18 , Coefficient 1: 0.9995871101219063 , Coefficient 2: 1.0003332407047287 , Coefficient 3: 0.36972342198788477
Epoch: 19 , Train Loss: 1.7635103007705765e-05
Epoch: 19 , Test Loss: 1.754575443919748e-05
Epoch: 19 , D11: 0.5350908780565883 , D22: 0.5425479715957342
Epoch: 19 , D11*: 0.5346852403383195, D22*: 0.5427120672380586, D12*: 1.4623726032094313
Epoch: 19 , Coefficient 1: 0.9992419274278381 , Coefficient 2: 1.0003024537016363 , Coefficient 3: 0.3683730484323359
Epoch: 20 , Train Loss: 1.68800142555483e-05
Epoch: 20 , Test Loss: 1.6794564835436177e-05
Epoch: 20 , D11: 0.5402685239278537 , D22: 0.5278914208920232
Epoch: 20 , D11*: 0.5400120558274879, D22*: 0.5282164940886916, D12*: 1.4697680367650308
Epoch: 20 , Coefficient 1: 0.9995252951282424 , Coefficient 2: 1.00061579556667 , Coefficient 3: 0.3634003880868704
Epoch: 21 , Train Loss: 1.61923731711795e-05
Epoch: 21 , Test Loss: 1.6116116847115337e-05
Epoch: 21 , D11: 0.5755352793465514 , D22: 0.55851191422101
Epoch: 21 , D11*: 0.5752016721532354, D22*: 0.5586879460492019, D12*: 1.501708714318835
Epoch: 21 , Coefficient 1: 0.999420353182007 , Coefficient 2: 1.0003151800771115 , Coefficient 3: 0.3775331418772388
Epoch: 22 , Train Loss: 1.560575525945751e-05
Epoch: 22 , Test Loss: 1.5541039087111127e-05
Epoch: 22 , D11: 0.5070441556246668 , D22: 0.5952217935883336
Epoch: 22 , D11*: 0.5068288930725635, D22*: 0.5954044377208831, D12*: 1.5657858665772517
Epoch: 22 , Coefficient 1: 0.9995754560037516 , Coefficient 2: 1.000306850546329 , Coefficient 3: 0.3519744794998331
Epoch: 23 , Train Loss: 1.507862710604968e-05
Epoch: 23 , Test Loss: 1.5017370216810378e-05
Epoch: 23 , D11: 0.5313679767152443 , D22: 0.5272201058210778
Epoch: 23 , D11*: 0.5310742880872901, D22*: 0.5274288062462716, D12*: 1.4360192371054457
Epoch: 23 , Coefficient 1: 0.9994472970882256 , Coefficient 2: 1.00039585065685 , Coefficient 3: 0.36855463596266463
Epoch: 24 , Train Loss: 1.4597520118513787e-05
Epoch: 24 , Test Loss: 1.4541964490490502e-05
Epoch: 24 , D11: 0.5144250425175987 , D22: 0.5630195296449795
Epoch: 24 , D11*: 0.5141453569042375, D22*: 0.563263911515502, D12*: 1.4639756742231886
Epoch: 24 , Coefficient 1: 0.9994563141561064 , Coefficient 2: 1.0004340557612215 , Coefficient 3: 0.36797376055836173
Epoch: 25 , Train Loss: 1.4178052643273984e-05
Epoch: 25 , Test Loss: 1.4127047103102086e-05
Epoch: 25 , D11: 0.5430962461261674 , D22: 0.5826083428102329
Epoch: 25 , D11*: 0.5429343543961346, D22*: 0.5827914614395959, D12*: 1.4176358282251416
Epoch: 25 , Coefficient 1: 0.9997019096869338 , Coefficient 2: 1.0003143082855281 , Coefficient 3: 0.3970433708793612
Epoch: 26 , Train Loss: 1.3806527043925597e-05
Epoch: 26 , Test Loss: 1.3760739479039331e-05
Epoch: 26 , D11: 0.4934253550415136 , D22: 0.5433811274555876
Epoch: 26 , D11*: 0.4932651399411336, D22*: 0.5435268504037009, D12*: 1.4580397126890399
Epoch: 26 , Coefficient 1: 0.9996753002277994 , Coefficient 2: 1.0002681781547982 , Coefficient 3: 0.3555431245534098
Epoch: 27 , Train Loss: 1.3483187611200263e-05
Epoch: 27 , Test Loss: 1.3444893031191893e-05
Epoch: 27 , D11: 0.5020001520029124 , D22: 0.5503516229332298
Epoch: 27 , D11*: 0.501916692772478, D22*: 0.5504672146348237, D12*: 1.491678411781638
Epoch: 27 , Coefficient 1: 0.9998337466032602 , Coefficient 2: 1.0002100324533938 , Coefficient 3: 0.3527516048684885
Epoch: 28 , Train Loss: 1.3190526510243218e-05
Epoch: 28 , Test Loss: 1.3154658467101399e-05
Epoch: 28 , D11: 0.5005329947871622 , D22: 0.5519395516839706
Epoch: 28 , D11*: 0.500407757946166, D22*: 0.5520481754711991, D12*: 1.4392148365989363
Epoch: 28 , Coefficient 1: 0.9997497930360226 , Coefficient 2: 1.0001968037747921 , Coefficient 3: 0.36563545158569377
Epoch: 29 , Train Loss: 1.2940856206114403e-05
Epoch: 29 , Test Loss: 1.2914767798065442e-05
Epoch: 29 , D11: 0.5330383561595134 , D22: 0.5431373644897446
Epoch: 29 , D11*: 0.532821954291591, D22*: 0.5432572211284391, D12*: 1.4776299556844443
Epoch: 29 , Coefficient 1: 0.9995940219584166 , Coefficient 2: 1.0002206746332156 , Coefficient 3: 0.3641233623074411
Epoch: 30 , Train Loss: 1.2721428163786185e-05
Epoch: 30 , Test Loss: 1.2695169116341278e-05
Epoch: 30 , D11: 0.5208755581531733 , D22: 0.5529516851308072
Epoch: 30 , D11*: 0.5207305029383289, D22*: 0.553067707367438, D12*: 1.4497164284448738
Epoch: 30 , Coefficient 1: 0.9997215165646115 , Coefficient 2: 1.0002098234615262 , Coefficient 3: 0.3703476725643655
Epoch: 31 , Train Loss: 1.2505025056725573e-05
Epoch: 31 , Test Loss: 1.2481391531764529e-05
Epoch: 31 , D11: 0.5058127840964949 , D22: 0.5818389143864433
Epoch: 31 , D11*: 0.5056463561823699, D22*: 0.5819728084329456, D12*: 1.4859143964395904
Epoch: 31 , Coefficient 1: 0.9996709693401239 , Coefficient 2: 1.0002301221922283 , Coefficient 3: 0.36597638707228597
Epoch: 32 , Train Loss: 1.2297617534386517e-05
Epoch: 32 , Test Loss: 1.227449300859007e-05
Epoch: 32 , D11: 0.519267798560077 , D22: 0.5718015801243159
Epoch: 32 , D11*: 0.5191165816515956, D22*: 0.5719028921409108, D12*: 1.4735388911599077
Epoch: 32 , Coefficient 1: 0.9997087882035036 , Coefficient 2: 1.000177180371857 , Coefficient 3: 0.37020382710554106
Epoch: 33 , Train Loss: 1.2110718733310932e-05
Epoch: 33 , Test Loss: 1.2087314569726002e-05
Epoch: 33 , D11: 0.49531258309619186 , D22: 0.5439051717045056
Epoch: 33 , D11*: 0.49515647752891806, D22*: 0.5439365423580608, D12*: 1.4886957997512031
Epoch: 33 , Coefficient 1: 0.9996848342388195 , Coefficient 2: 1.0000576766965772 , Coefficient 3: 0.3489944084146124
Epoch: 34 , Train Loss: 1.1936538879126603e-05
Epoch: 34 , Test Loss: 1.1913230373465922e-05
Epoch: 34 , D11: 0.5280475585634462 , D22: 0.5648785943865445
Epoch: 34 , D11*: 0.527855233223642, D22*: 0.5649411953924636, D12*: 1.4959851511123496
Epoch: 34 , Coefficient 1: 0.9996357802688693 , Coefficient 2: 1.0001108220536963 , Coefficient 3: 0.3652430733699294
Epoch: 35 , Train Loss: 1.1767255698941881e-05
Epoch: 35 , Test Loss: 1.1747418750019277e-05
Epoch: 35 , D11: 0.5266465145142022 , D22: 0.5723370649966533
Epoch: 35 , D11*: 0.5265533524649696, D22*: 0.5724137142215058, D12*: 1.4694709814508924
Epoch: 35 , Coefficient 1: 0.9998231032644002 , Coefficient 2: 1.0001339232238138 , Coefficient 3: 0.3739328916864363
Epoch: 36 , Train Loss: 1.1611002851623197e-05
Epoch: 36 , Test Loss: 1.159083059610566e-05
Epoch: 36 , D11: 0.5152706895890771 , D22: 0.5435195625202749
Epoch: 36 , D11*: 0.5152335577362267, D22*: 0.5436024963800092, D12*: 1.464660783976519
Epoch: 36 , Coefficient 1: 0.9999279371918477 , Coefficient 2: 1.0001525867060788 , Coefficient 3: 0.36146118804434746
Epoch: 37 , Train Loss: 1.1465623029835115e-05
Epoch: 37 , Test Loss: 1.1446134674770293e-05
Epoch: 37 , D11: 0.5254414673608727 , D22: 0.56749993339496
Epoch: 37 , D11*: 0.5253750886603358, D22*: 0.5675826574708316, D12*: 1.490349399785749
Epoch: 37 , Coefficient 1: 0.9998736706090778 , Coefficient 2: 1.0001457693137985 , Coefficient 3: 0.36667835954719397
Epoch: 38 , Train Loss: 1.1330969108257704e-05
Epoch: 38 , Test Loss: 1.1311258946079759e-05
Epoch: 38 , D11: 0.5365737373521788 , D22: 0.5748956143163196
Epoch: 38 , D11*: 0.5365170781625158, D22*: 0.5749010363121164, D12*: 1.4920347962018463
Epoch: 38 , Coefficient 1: 0.9998944055854417 , Coefficient 2: 1.0000094312700631 , Coefficient 3: 0.3724504674099694
Epoch: 39 , Train Loss: 1.119516824155653e-05
Epoch: 39 , Test Loss: 1.1177681346453026e-05
Epoch: 39 , D11: 0.543047643030192 , D22: 0.5658664752126569
Epoch: 39 , D11*: 0.5429858903113824, D22*: 0.5659235485630848, D12*: 1.479002506515325
Epoch: 39 , Coefficient 1: 0.9998862848967265 , Coefficient 2: 1.0001008601020347 , Coefficient 3: 0.37488423244365104
