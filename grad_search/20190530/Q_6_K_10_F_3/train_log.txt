Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.00330689110676758
Epoch: 0 , Test Loss: 0.002987872699741274
Epoch: 0 , D11: 0.8356558687782732 , D22: 0.8245545747264684
Epoch: 0 , D11*: 0.8528677198419781, D22*: 0.8586806351066019, D12*: 1.1199577443365003
Epoch: 0 , Coefficient 1: 1.0205968170712048 , Coefficient 2: 1.0413872670483384 , Coefficient 3: 0.7641129156897599
Epoch: 1 , Train Loss: 0.0028422792536730414
Epoch: 1 , Test Loss: 0.0028670237673213703
Epoch: 1 , D11: 0.8312717681953254 , D22: 0.8299790350171447
Epoch: 1 , D11*: 0.8249730938042766, D22*: 0.8311009384019269, D12*: 1.1005716800411396
Epoch: 1 , Coefficient 1: 0.9924228457743451 , Coefficient 2: 1.0013517249682808 , Coefficient 3: 0.7523699102198864
Epoch: 2 , Train Loss: 0.0028417065720714165
Epoch: 2 , Test Loss: 0.002862368253991008
Epoch: 2 , D11: 0.8288457124209722 , D22: 0.7938673768467404
Epoch: 2 , D11*: 0.820679361067877, D22*: 0.7902667317744616, D12*: 1.1162849938699775
Epoch: 2 , Coefficient 1: 0.9901473202663471 , Coefficient 2: 0.9954644249438985 , Coefficient 3: 0.7215657747299155
Epoch: 3 , Train Loss: 0.0028294512594584376
Epoch: 3 , Test Loss: 0.002872826164239086
Epoch: 3 , D11: 0.8268757048829019 , D22: 0.827296760460189
Epoch: 3 , D11*: 0.8207038680312428, D22*: 0.860858269277758, D12*: 1.0859369111173154
Epoch: 3 , Coefficient 1: 0.9925359557485934 , Coefficient 2: 1.0405676782765356 , Coefficient 3: 0.7742448571799855
Epoch: 4 , Train Loss: 0.0028442752003320494
Epoch: 4 , Test Loss: 0.002855193022405729
Epoch: 4 , D11: 0.8370181619399347 , D22: 0.822136495799336
Epoch: 4 , D11*: 0.8485921739190799, D22*: 0.8531877260863986, D12*: 1.0821838273284716
Epoch: 4 , Coefficient 1: 1.0138276712566432 , Coefficient 2: 1.0377689476695382 , Coefficient 3: 0.7862711754834527
Epoch: 5 , Train Loss: 0.00283790045461501
Epoch: 5 , Test Loss: 0.0028668520180508495
Epoch: 5 , D11: 0.8277192287298442 , D22: 0.8194776713253186
Epoch: 5 , D11*: 0.8441558213833138, D22*: 0.8071177612305802, D12*: 1.1003626855268074
Epoch: 5 , Coefficient 1: 1.019857690969306 , Coefficient 2: 0.9849173314573062 , Coefficient 3: 0.7503315062993678
Epoch: 6 , Train Loss: 0.002830984193715267
Epoch: 6 , Test Loss: 0.002868722522980533
Epoch: 6 , D11: 0.8352020569581019 , D22: 0.8269755850916362
Epoch: 6 , D11*: 0.8217759986652732, D22*: 0.8326130430472048, D12*: 1.107449001409136
Epoch: 6 , Coefficient 1: 0.9839247782246515 , Coefficient 2: 1.0068169581511213 , Coefficient 3: 0.7469368971426253
Epoch: 7 , Train Loss: 0.002839808795542922
Epoch: 7 , Test Loss: 0.0028552004270022734
Epoch: 7 , D11: 0.8348614028850787 , D22: 0.8021470353833506
Epoch: 7 , D11*: 0.8093760058780414, D22*: 0.8083261305004663, D12*: 1.125311673330621
Epoch: 7 , Coefficient 1: 0.9694734995306216 , Coefficient 2: 1.0077031951058233 , Coefficient 3: 0.7187795944525052
Epoch: 8 , Train Loss: 0.0028414709790376947
Epoch: 8 , Test Loss: 0.0028553671541158105
Epoch: 8 , D11: 0.8532812590892881 , D22: 0.8165988996496981
Epoch: 8 , D11*: 0.8170567871860138, D22*: 0.8356555622048103, D12*: 1.1085846226124758
Epoch: 8 , Coefficient 1: 0.9575468563062819 , Coefficient 2: 1.0233366253166483 , Coefficient 3: 0.7454155125731692
Epoch: 9 , Train Loss: 0.002846687131241197
Epoch: 9 , Test Loss: 0.0028685997298453004
Epoch: 9 , D11: 0.8271811784424634 , D22: 0.829323900713393
Epoch: 9 , D11*: 0.8134649809494578, D22*: 0.8596408652457048, D12*: 1.145614831589725
Epoch: 9 , Coefficient 1: 0.9834181460477227 , Coefficient 2: 1.0365562411818023 , Coefficient 3: 0.7302217988368128
Epoch: 10 , Train Loss: 0.0028377273563819473
Epoch: 10 , Test Loss: 0.0028645428764866665
Epoch: 10 , D11: 0.8425534702962449 , D22: 0.8271449096757036
Epoch: 10 , D11*: 0.8176485615535883, D22*: 0.8325857413329145, D12*: 1.1103742033894406
Epoch: 10 , Coefficient 1: 0.9704411534452526 , Coefficient 2: 1.0065778457844152 , Coefficient 3: 0.743098271667843
Epoch: 11 , Train Loss: 0.0028479333207360466
Epoch: 11 , Test Loss: 0.002868451590766199
Epoch: 11 , D11: 0.8438450978542525 , D22: 0.8045852531527475
Epoch: 11 , D11*: 0.8692803788920912, D22*: 0.8164145789513739, D12*: 1.1238878179637022
Epoch: 11 , Coefficient 1: 1.0301421209917745 , Coefficient 2: 1.0147023895258749 , Coefficient 3: 0.7499391535792532
Epoch: 12 , Train Loss: 0.002836564817698673
Epoch: 12 , Test Loss: 0.002870001515257172
Epoch: 12 , D11: 0.8356092882477081 , D22: 0.8121300984283815
Epoch: 12 , D11*: 0.8367116447657058, D22*: 0.8316770130728213, D12*: 1.0997426166962312
Epoch: 12 , Coefficient 1: 1.0013192248261258 , Coefficient 2: 1.0240686987002041 , Coefficient 3: 0.7585359667385546
Epoch: 13 , Train Loss: 0.0028424918894597796
Epoch: 13 , Test Loss: 0.0028543722542235623
Epoch: 13 , D11: 0.8285249275446136 , D22: 0.8213374181709625
Epoch: 13 , D11*: 0.8497369569107792, D22*: 0.8201564631606572, D12*: 1.1163819426157802
Epoch: 13 , Coefficient 1: 1.0256021619398088 , Coefficient 2: 0.9985621560832633 , Coefficient 3: 0.7479041698572849
Epoch: 14 , Train Loss: 0.0028456049022497604
Epoch: 14 , Test Loss: 0.0028766503010410815
Epoch: 14 , D11: 0.8431049602051333 , D22: 0.825121002455019
Epoch: 14 , D11*: 0.8440482321401345, D22*: 0.8535285026521143, D12*: 1.127108997506339
Epoch: 14 , Coefficient 1: 1.0011188072417125 , Coefficient 2: 1.0344282839881342 , Coefficient 3: 0.7530668012357435
Epoch: 15 , Train Loss: 0.0028406062009162267
Epoch: 15 , Test Loss: 0.0028551593323936685
Epoch: 15 , D11: 0.8284469297011458 , D22: 0.8364058951818977
Epoch: 15 , D11*: 0.8551702761383537, D22*: 0.8345221830605972, D12*: 1.1028283089064423
Epoch: 15 , Coefficient 1: 1.0322571615382148 , Coefficient 2: 0.9977478493012166 , Coefficient 3: 0.7660723095122755
Epoch: 16 , Train Loss: 0.002841299991996493
Epoch: 16 , Test Loss: 0.0028579566755797714
Epoch: 16 , D11: 0.8384971072151448 , D22: 0.7972997944351192
Epoch: 16 , D11*: 0.8369732195393452, D22*: 0.7443234384022229, D12*: 1.1408409585532786
Epoch: 16 , Coefficient 1: 0.998182596382639 , Coefficient 2: 0.9335552869790595 , Coefficient 3: 0.6930399220356006
Epoch: 17 , Train Loss: 0.0028483460214920346
Epoch: 17 , Test Loss: 0.0028596757678315044
Epoch: 17 , D11: 0.8602836039216183 , D22: 0.8313170630119081
Epoch: 17 , D11*: 0.8268117097176024, D22*: 0.8112770030709271, D12*: 1.1212517538959064
Epoch: 17 , Coefficient 1: 0.961092023547312 , Coefficient 2: 0.9758936020531387 , Coefficient 3: 0.7304731997505551
Epoch: 18 , Train Loss: 0.002836228119849693
Epoch: 18 , Test Loss: 0.002852322327089496
Epoch: 18 , D11: 0.8227770016846871 , D22: 0.8159082330652864
Epoch: 18 , D11*: 0.8239139814386954, D22*: 0.8078912329930373, D12*: 1.1099848632505056
Epoch: 18 , Coefficient 1: 1.0013818808154338 , Coefficient 2: 0.990174139998404 , Coefficient 3: 0.7350574176539292
Epoch: 19 , Train Loss: 0.0028370249904401132
Epoch: 19 , Test Loss: 0.002867565939668566
Epoch: 19 , D11: 0.8561897390171717 , D22: 0.8199601066234462
Epoch: 19 , D11*: 0.8267041633049388, D22*: 0.8146227269636619, D12*: 1.0896535992913878
Epoch: 19 , Coefficient 1: 0.9655618674593325 , Coefficient 2: 0.9934906837336717 , Coefficient 3: 0.7531415907477254
Epoch: 20 , Train Loss: 0.0028402664516761432
Epoch: 20 , Test Loss: 0.0028628406766802073
Epoch: 20 , D11: 0.838469972121988 , D22: 0.8426770581004907
Epoch: 20 , D11*: 0.8388437649012287, D22*: 0.7990226271075278, D12*: 1.1240204774022706
Epoch: 20 , Coefficient 1: 1.0004458034177357 , Coefficient 2: 0.948195538761473 , Coefficient 3: 0.7285749792539534
Epoch: 21 , Train Loss: 0.0028452620495227165
Epoch: 21 , Test Loss: 0.0028578705847030505
Epoch: 21 , D11: 0.8467521613756583 , D22: 0.8382258491500008
Epoch: 21 , D11*: 0.8513307355839265, D22*: 0.8352762145134557, D12*: 1.097182890137772
Epoch: 21 , Coefficient 1: 1.00540721880276 , Coefficient 2: 0.9964810979767134 , Coefficient 3: 0.7686079345830834
Epoch: 22 , Train Loss: 0.0028382382504059923
Epoch: 22 , Test Loss: 0.0028797926945844663
Epoch: 22 , D11: 0.8264230433328765 , D22: 0.8128306505999549
Epoch: 22 , D11*: 0.8090971243229179, D22*: 0.8312165877605956, D12*: 1.1053484997800374
Epoch: 22 , Coefficient 1: 0.9790350485145174 , Coefficient 2: 1.0226196405697423 , Coefficient 3: 0.7419893872429977
Epoch: 23 , Train Loss: 0.00284054127681884
Epoch: 23 , Test Loss: 0.002865561950602569
Epoch: 23 , D11: 0.8369785898147214 , D22: 0.8140425286264924
Epoch: 23 , D11*: 0.837021318523266, D22*: 0.8099942745425055, D12*: 1.1076709292722815
Epoch: 23 , Coefficient 1: 1.0000510511368685 , Coefficient 2: 0.9950269747075532 , Coefficient 3: 0.7434588872652951
Epoch: 24 , Train Loss: 0.002836912721541012
Epoch: 24 , Test Loss: 0.0028663513227365914
Epoch: 24 , D11: 0.8253631266031027 , D22: 0.8259403069105261
Epoch: 24 , D11*: 0.8051121355064204, D22*: 0.8394903709813165, D12*: 1.1117361693898853
Epoch: 24 , Coefficient 1: 0.9754641436672509 , Coefficient 2: 1.0164056215169777 , Coefficient 3: 0.739655033167755
Epoch: 25 , Train Loss: 0.002845437352661975
Epoch: 25 , Test Loss: 0.0028563597373431554
Epoch: 25 , D11: 0.8389331414621573 , D22: 0.828409302124703
Epoch: 25 , D11*: 0.841095151840094, D22*: 0.7777573608039614, D12*: 1.1370936715172035
Epoch: 25 , Coefficient 1: 1.0025770949686987 , Coefficient 2: 0.9388563827194727 , Coefficient 3: 0.7118377989405437
Epoch: 26 , Train Loss: 0.0028403604029153943
Epoch: 26 , Test Loss: 0.002856794023537077
Epoch: 26 , D11: 0.8254649506143259 , D22: 0.8104667618227576
Epoch: 26 , D11*: 0.8115413298159365, D22*: 0.7714332839468283, D12*: 1.0888238101427576
Epoch: 26 , Coefficient 1: 0.9831323900693456 , Coefficient 2: 0.9518382742949975 , Coefficient 3: 0.7269195433718602
Epoch: 27 , Train Loss: 0.0028365342212782704
Epoch: 27 , Test Loss: 0.002859804442268796
Epoch: 27 , D11: 0.8356206517714793 , D22: 0.8189070686968367
Epoch: 27 , D11*: 0.8426542160806826, D22*: 0.8358492080500325, D12*: 1.1117011570745812
Epoch: 27 , Coefficient 1: 1.0084171738626762 , Coefficient 2: 1.0206887203698907 , Coefficient 3: 0.7549256441126959
Epoch: 28 , Train Loss: 0.0028320168580103196
Epoch: 28 , Test Loss: 0.002872321323957294
Epoch: 28 , D11: 0.8304001863281661 , D22: 0.8330170842567884
Epoch: 28 , D11*: 0.8250448832257582, D22*: 0.8185744526446954, D12*: 1.122010699305219
Epoch: 28 , Coefficient 1: 0.9935509370173822 , Coefficient 2: 0.9826622624132869 , Coefficient 3: 0.7324436999077769
Epoch: 29 , Train Loss: 0.002850656006776262
Epoch: 29 , Test Loss: 0.002853178885416128
Epoch: 29 , D11: 0.8252608329170437 , D22: 0.8106391798545083
Epoch: 29 , D11*: 0.8128500792332481, D22*: 0.7708267622656739, D12*: 1.1246201889829055
Epoch: 29 , Coefficient 1: 0.9849614168166356 , Coefficient 2: 0.9508876222884023 , Coefficient 3: 0.7040940830571353
Epoch: 30 , Train Loss: 0.0028433818148914727
Epoch: 30 , Test Loss: 0.0028564308024942877
Epoch: 30 , D11: 0.8475305972855616 , D22: 0.8207389575218568
Epoch: 30 , D11*: 0.8625213013387273, D22*: 0.8458457239474014, D12*: 1.1179417148105755
Epoch: 30 , Coefficient 1: 1.0176875078034673 , Coefficient 2: 1.0305904407186326 , Coefficient 3: 0.7640680201183812
Epoch: 31 , Train Loss: 0.002847187943989411
Epoch: 31 , Test Loss: 0.002881683188024908
Epoch: 31 , D11: 0.8376662402417927 , D22: 0.8400807287365912
Epoch: 31 , D11*: 0.8196611461795948, D22*: 0.8251493781915649, D12*: 1.121037757279009
Epoch: 31 , Coefficient 1: 0.9785056467633211 , Coefficient 2: 0.9822262908381653 , Coefficient 3: 0.7336106717598236
Epoch: 32 , Train Loss: 0.0028468519941088747
Epoch: 32 , Test Loss: 0.0028737351240124553
Epoch: 32 , D11: 0.8429276631020011 , D22: 0.8267026809122524
Epoch: 32 , D11*: 0.8595645962349612, D22*: 0.8350983529967713, D12*: 1.0763563538681475
Epoch: 32 , Coefficient 1: 1.0197370828615775 , Coefficient 2: 1.0101556125053983 , Coefficient 3: 0.7872220678316945
Epoch: 33 , Train Loss: 0.0028358477100846355
Epoch: 33 , Test Loss: 0.0028759333572816103
Epoch: 33 , D11: 0.8356066513312966 , D22: 0.8220032312711087
Epoch: 33 , D11*: 0.8385760360626021, D22*: 0.8054705026955767, D12*: 1.1067375807608262
Epoch: 33 , Coefficient 1: 1.0035535676105194 , Coefficient 2: 0.9798872705768242 , Coefficient 3: 0.7427445165582883
Epoch: 34 , Train Loss: 0.002839621586608701
Epoch: 34 , Test Loss: 0.0028608831367455427
Epoch: 34 , D11: 0.8429137567481357 , D22: 0.8359804563749648
Epoch: 34 , D11*: 0.812847624113846, D22*: 0.8360521239825534, D12*: 1.1358798254347446
Epoch: 34 , Coefficient 1: 0.9643307130847154 , Coefficient 2: 1.0000857288074645 , Coefficient 3: 0.7258249117442078
Epoch: 35 , Train Loss: 0.0028340833596303128
Epoch: 35 , Test Loss: 0.0028701999963959674
Epoch: 35 , D11: 0.8272136977729612 , D22: 0.8325484830520338
Epoch: 35 , D11*: 0.8532485156922027, D22*: 0.8038147969835792, D12*: 1.1077324699055315
Epoch: 35 , Coefficient 1: 1.0314729047516173 , Coefficient 2: 0.9654870717401106 , Coefficient 3: 0.7479528485867611
Epoch: 36 , Train Loss: 0.002844889953412348
Epoch: 36 , Test Loss: 0.00287607018079143
Epoch: 36 , D11: 0.8450954460444147 , D22: 0.8382871006599181
Epoch: 36 , D11*: 0.8521642278784826, D22*: 0.8489548121494258, D12*: 1.0735965180863174
Epoch: 36 , Coefficient 1: 1.0083644774884948 , Coefficient 2: 1.0127256061570193 , Coefficient 3: 0.7922524949410921
Epoch: 37 , Train Loss: 0.0028319589195598383
Epoch: 37 , Test Loss: 0.0028752312803408133
Epoch: 37 , D11: 0.856398477595981 , D22: 0.8065695751971951
Epoch: 37 , D11*: 0.8414647026536463, D22*: 0.7914096637870252, D12*: 1.1102322015592299
Epoch: 37 , Coefficient 1: 0.9825621187647884 , Coefficient 2: 0.981204459136134 , Coefficient 3: 0.7353751603256659
Epoch: 38 , Train Loss: 0.0028374705315218304
Epoch: 38 , Test Loss: 0.00285698558378499
Epoch: 38 , D11: 0.8243794071559064 , D22: 0.8109970348994693
Epoch: 38 , D11*: 0.8289448789821813, D22*: 0.7621934892229998, D12*: 1.1662147707993358
Epoch: 38 , Coefficient 1: 1.0055380711680144 , Coefficient 2: 0.9398227816177908 , Coefficient 3: 0.6821806789132837
Epoch: 39 , Train Loss: 0.002840726519934833
Epoch: 39 , Test Loss: 0.002869200457935221
Epoch: 39 , D11: 0.842152626633563 , D22: 0.8313597598733795
Epoch: 39 , D11*: 0.8215555807037399, D22*: 0.8424095016783577, D12*: 1.1244935313854851
Epoch: 39 , Coefficient 1: 0.9755423835556292 , Coefficient 2: 1.0132911674804432 , Coefficient 3: 0.7398731232948629
