Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.0033446946182812097
Epoch: 0 , Test Loss: 0.003033146125380881
Epoch: 0 , D11: 0.8337299956806594 , D22: 0.8257314611013685
Epoch: 0 , D11*: 0.8498969050923685, D22*: 0.8092346863566227, D12*: 1.1182840194338524
Epoch: 0 , Coefficient 1: 1.0193910612494042 , Coefficient 2: 0.9800216226196077 , Coefficient 3: 0.7418203079969571
Epoch: 1 , Train Loss: 0.002840226034604712
Epoch: 1 , Test Loss: 0.002853110762080178
Epoch: 1 , D11: 0.8465348640629722 , D22: 0.8173551254587764
Epoch: 1 , D11*: 0.8724078995903141, D22*: 0.8218779059086945, D12*: 1.0866190255120296
Epoch: 1 , Coefficient 1: 1.030563461265096 , Coefficient 2: 1.005533433765867 , Coefficient 3: 0.7796135378269482
Epoch: 2 , Train Loss: 0.002838937473425176
Epoch: 2 , Test Loss: 0.002873101762961596
Epoch: 2 , D11: 0.8268948948182293 , D22: 0.8228814058374072
Epoch: 2 , D11*: 0.814388267542149, D22*: 0.8269625760912197, D12*: 1.1099105294868794
Epoch: 2 , Coefficient 1: 0.9848751910860091 , Coefficient 2: 1.0049596092764537 , Coefficient 3: 0.7394068260583934
Epoch: 3 , Train Loss: 0.0028406650197575806
Epoch: 3 , Test Loss: 0.002868828900973313
Epoch: 3 , D11: 0.8289822376131026 , D22: 0.8205288801250211
Epoch: 3 , D11*: 0.8570870601198851, D22*: 0.7964976571247593, D12*: 1.110432024319016
Epoch: 3 , Coefficient 1: 1.0339028042237732 , Coefficient 2: 0.9707125202020918 , Coefficient 3: 0.7445681865392537
Epoch: 4 , Train Loss: 0.0028322884338558654
Epoch: 4 , Test Loss: 0.0028575283143436533
Epoch: 4 , D11: 0.8146985268247529 , D22: 0.8269695492593944
Epoch: 4 , D11*: 0.7908473959251853, D22*: 0.7761657177251652, D12*: 1.111074257739748
Epoch: 4 , Coefficient 1: 0.9707239793442045 , Coefficient 2: 0.9385662608983277 , Coefficient 3: 0.7051792905535027
Epoch: 5 , Train Loss: 0.002835332312242826
Epoch: 5 , Test Loss: 0.0028644389181863516
Epoch: 5 , D11: 0.8378703187577689 , D22: 0.8101330072979617
Epoch: 5 , D11*: 0.8076786361401703, D22*: 0.836224754419586, D12*: 1.1080893116908719
Epoch: 5 , Coefficient 1: 0.9639661628515963 , Coefficient 2: 1.0322067449253156 , Coefficient 3: 0.7417738684128571
Epoch: 6 , Train Loss: 0.002839622267929372
Epoch: 6 , Test Loss: 0.0028677437698934227
Epoch: 6 , D11: 0.8420325020808709 , D22: 0.8119553351383235
Epoch: 6 , D11*: 0.8273415228600761, D22*: 0.853680539940102, D12*: 1.0695555418191804
Epoch: 6 , Coefficient 1: 0.9825529546846592 , Coefficient 2: 1.0513885468769908 , Coefficient 3: 0.7858507562594502
Epoch: 7 , Train Loss: 0.0028416519048914774
Epoch: 7 , Test Loss: 0.00286657776334323
Epoch: 7 , D11: 0.8360563541430301 , D22: 0.7963301935981212
Epoch: 7 , D11*: 0.8263454331722311, D22*: 0.8088163538017102, D12*: 1.0917624644377695
Epoch: 7 , Coefficient 1: 0.9883848487931739 , Coefficient 2: 1.0156796267477588 , Coefficient 3: 0.7488633472190349
Epoch: 8 , Train Loss: 0.0028437149904493707
Epoch: 8 , Test Loss: 0.0028684414993040263
Epoch: 8 , D11: 0.8343218211954537 , D22: 0.8184650331090946
Epoch: 8 , D11*: 0.8565948815017447, D22*: 0.8267309561283107, D12*: 1.1153634265163537
Epoch: 8 , Coefficient 1: 1.026696005954126 , Coefficient 2: 1.0100992989130109 , Coefficient 3: 0.7546086762444932
Epoch: 9 , Train Loss: 0.0028371841213083826
Epoch: 9 , Test Loss: 0.0028563911595847454
Epoch: 9 , D11: 0.832954334989719 , D22: 0.7902764708559634
Epoch: 9 , D11*: 0.8416355051294905, D22*: 0.755099785452881, D12*: 1.1311987553985026
Epoch: 9 , Coefficient 1: 1.010422144138164 , Coefficient 2: 0.9554881276359122 , Coefficient 3: 0.705771325756042
Epoch: 10 , Train Loss: 0.0028403996179986284
Epoch: 10 , Test Loss: 0.0028646053466945885
Epoch: 10 , D11: 0.8137628887418874 , D22: 0.8095715373525774
Epoch: 10 , D11*: 0.8251284695776872, D22*: 0.8080444290022559, D12*: 1.1081804557851465
Epoch: 10 , Coefficient 1: 1.0139666983995441 , Coefficient 2: 0.998113683251124 , Coefficient 3: 0.7368713687622469
Epoch: 11 , Train Loss: 0.0028433611305081286
Epoch: 11 , Test Loss: 0.0028776438167551527
Epoch: 11 , D11: 0.8424329711745375 , D22: 0.8035532188306558
Epoch: 11 , D11*: 0.8148896980670977, D22*: 0.8099051181125492, D12*: 1.0803328286043359
Epoch: 11 , Coefficient 1: 0.9673050865174015 , Coefficient 2: 1.0079047649029853 , Coefficient 3: 0.7519880786547477
Epoch: 12 , Train Loss: 0.002845097255340079
Epoch: 12 , Test Loss: 0.0028556473174830904
Epoch: 12 , D11: 0.8336490603266363 , D22: 0.8012072182142814
Epoch: 12 , D11*: 0.8191525106290115, D22*: 0.817016304220845, D12*: 1.1351227409698033
Epoch: 12 , Coefficient 1: 0.9826107286776706 , Coefficient 2: 1.0197315821015676 , Coefficient 3: 0.7207012756400156
Epoch: 13 , Train Loss: 0.0028403599390003365
Epoch: 13 , Test Loss: 0.0028804009209852663
Epoch: 13 , D11: 0.8492425994455586 , D22: 0.8175895379732171
Epoch: 13 , D11*: 0.845421019353211, D22*: 0.8075377556847119, D12*: 1.136432829817307
Epoch: 13 , Coefficient 1: 0.995500013665303 , Coefficient 2: 0.9877055884136882 , Coefficient 3: 0.7272575781287719
Epoch: 14 , Train Loss: 0.002840534739953
Epoch: 14 , Test Loss: 0.002874005162739195
Epoch: 14 , D11: 0.8559161651375216 , D22: 0.8308108072791451
Epoch: 14 , D11*: 0.8589429716199996, D22*: 0.8044680136835238, D12*: 1.107352933300014
Epoch: 14 , Coefficient 1: 1.0035363352227278 , Coefficient 2: 0.9682926686017815 , Coefficient 3: 0.7510753506320722
Epoch: 15 , Train Loss: 0.002841557032952551
Epoch: 15 , Test Loss: 0.0028806837048614394
Epoch: 15 , D11: 0.840341050934192 , D22: 0.8311395621174783
Epoch: 15 , D11*: 0.8403598671810987, D22*: 0.8808668014361621, D12*: 1.113863452383933
Epoch: 15 , Coefficient 1: 1.0000223912028168 , Coefficient 2: 1.0598301916852504 , Coefficient 3: 0.7726380935353547
Epoch: 16 , Train Loss: 0.002840049405494938
Epoch: 16 , Test Loss: 0.0028659732273081315
Epoch: 16 , D11: 0.848477801837817 , D22: 0.8359762006339879
Epoch: 16 , D11*: 0.8452415970399267, D22*: 0.829973544522072, D12*: 1.1168758870596938
Epoch: 16 , Coefficient 1: 0.9961858698119379 , Coefficient 2: 0.9928195849267435 , Coefficient 3: 0.7499558191609804
Epoch: 17 , Train Loss: 0.0028344294987618923
Epoch: 17 , Test Loss: 0.0028658911865204573
Epoch: 17 , D11: 0.8642461561886108 , D22: 0.8198944541652419
Epoch: 17 , D11*: 0.894663345689777, D22*: 0.8315911121513078, D12*: 1.1183561734312382
Epoch: 17 , Coefficient 1: 1.0351950532650422 , Coefficient 2: 1.0142660533031347 , Coefficient 3: 0.7717820578325905
Epoch: 18 , Train Loss: 0.0028419159670011137
Epoch: 18 , Test Loss: 0.0028644266846822577
Epoch: 18 , D11: 0.8263635749441569 , D22: 0.7924195485605668
Epoch: 18 , D11*: 0.8316847665434801, D22*: 0.807499419092442, D12*: 1.1223770997954796
Epoch: 18 , Coefficient 1: 1.0064392862423575 , Coefficient 2: 1.0190301596663887 , Coefficient 3: 0.730228808987022
Epoch: 19 , Train Loss: 0.002837627196422545
Epoch: 19 , Test Loss: 0.002869669866049662
Epoch: 19 , D11: 0.8362627108902577 , D22: 0.8069652123245834
Epoch: 19 , D11*: 0.8407600345859758, D22*: 0.7836597452559669, D12*: 1.1527730299829235
Epoch: 19 , Coefficient 1: 1.0053778838122895 , Coefficient 2: 0.9711196136925387 , Coefficient 3: 0.7045705171754434
Epoch: 20 , Train Loss: 0.0028466771928651728
Epoch: 20 , Test Loss: 0.002875017514452338
Epoch: 20 , D11: 0.8326201876113396 , D22: 0.8119618101183411
Epoch: 20 , D11*: 0.8486141607702876, D22*: 0.8450870810553444, D12*: 1.1215676705139752
Epoch: 20 , Coefficient 1: 1.0192092065469038 , Coefficient 2: 1.0407965873815854 , Coefficient 3: 0.7550597642714986
Epoch: 21 , Train Loss: 0.0028490146086551254
Epoch: 21 , Test Loss: 0.002872363904607482
Epoch: 21 , D11: 0.8428881413945232 , D22: 0.8181635774739563
Epoch: 21 , D11*: 0.8601527906649304, D22*: 0.8153523518285845, D12*: 1.0787506613114979
Epoch: 21 , Coefficient 1: 1.0204827288729483 , Coefficient 2: 0.9965639809412546 , Coefficient 3: 0.7765951867211415
Epoch: 22 , Train Loss: 0.0028305776398337913
Epoch: 22 , Test Loss: 0.0028550401714164766
Epoch: 22 , D11: 0.8508953348606313 , D22: 0.844276532259005
Epoch: 22 , D11*: 0.8504488308478254, D22*: 0.8279428010467875, D12*: 1.0979957251072752
Epoch: 22 , Coefficient 1: 0.9994752538949118 , Coefficient 2: 0.9806535766563192 , Coefficient 3: 0.7642978900171186
Epoch: 23 , Train Loss: 0.002839046480221441
Epoch: 23 , Test Loss: 0.0028528417507186535
Epoch: 23 , D11: 0.8243452354177737 , D22: 0.8230732857444802
Epoch: 23 , D11*: 0.7833335746432488, D22*: 0.8257887408544929, D12*: 1.1488339687935976
Epoch: 23 , Coefficient 1: 0.9502494112751918 , Coefficient 2: 1.003299165647876 , Coefficient 3: 0.7003284892365682
Epoch: 24 , Train Loss: 0.0028324767270532904
Epoch: 24 , Test Loss: 0.0028619695245288316
Epoch: 24 , D11: 0.8168584792744981 , D22: 0.8327566958582646
Epoch: 24 , D11*: 0.7957619672129811, D22*: 0.8216514145812363, D12*: 1.1073389833701919
Epoch: 24 , Coefficient 1: 0.9741736021639219 , Coefficient 2: 0.9866644347235384 , Coefficient 3: 0.7303153804228997
Epoch: 25 , Train Loss: 0.0028384751130943187
Epoch: 25 , Test Loss: 0.002851271830149926
Epoch: 25 , D11: 0.845269186265783 , D22: 0.8095031309197505
Epoch: 25 , D11*: 0.86679778454759, D22*: 0.8185765636799035, D12*: 1.1075298592336607
Epoch: 25 , Coefficient 1: 1.0254695174408472 , Coefficient 2: 1.011208644430867 , Coefficient 3: 0.7608708398135938
Epoch: 26 , Train Loss: 0.0028469298755226186
Epoch: 26 , Test Loss: 0.002865720200934447
Epoch: 26 , D11: 0.8472372480351837 , D22: 0.8120509684885119
Epoch: 26 , D11*: 0.8546022024379352, D22*: 0.7742951729923887, D12*: 1.1212391936721702
Epoch: 26 , Coefficient 1: 1.00869290676234 , Coefficient 2: 0.9535056333146196 , Coefficient 3: 0.726382641912259
Epoch: 27 , Train Loss: 0.0028424923513375687
Epoch: 27 , Test Loss: 0.0028642374969786023
Epoch: 27 , D11: 0.8319748026607637 , D22: 0.8119053981350906
Epoch: 27 , D11*: 0.7981340225890318, D22*: 0.8059247499729362, D12*: 1.1345387121411108
Epoch: 27 , Coefficient 1: 0.9593247536301523 , Coefficient 2: 0.9926338115550264 , Coefficient 3: 0.7069211281185703
Epoch: 28 , Train Loss: 0.0028385559112939517
Epoch: 28 , Test Loss: 0.0028795966511825097
Epoch: 28 , D11: 0.8571633083705326 , D22: 0.8210991532239865
Epoch: 28 , D11*: 0.8505685285071733, D22*: 0.8205947012822707, D12*: 1.1258377724185065
Epoch: 28 , Coefficient 1: 0.9923062737299199 , Coefficient 2: 0.9993856382146601 , Coefficient 3: 0.7421865168902081
Epoch: 29 , Train Loss: 0.002834377651597606
Epoch: 29 , Test Loss: 0.0028715522558195516
Epoch: 29 , D11: 0.8341050852102357 , D22: 0.8431923511858405
Epoch: 29 , D11*: 0.8564944036580694, D22*: 0.8533427647209296, D12*: 1.094655661242053
Epoch: 29 , Coefficient 1: 1.026842323401242 , Coefficient 2: 1.012038075915672 , Coefficient 3: 0.7809931601865234
Epoch: 30 , Train Loss: 0.0028373752775951292
Epoch: 30 , Test Loss: 0.002861546110361815
Epoch: 30 , D11: 0.8405248122575416 , D22: 0.8153544291758853
Epoch: 30 , D11*: 0.8311844189301524, D22*: 0.7959390389875839, D12*: 1.1012794297384807
Epoch: 30 , Coefficient 1: 0.9888874270084875 , Coefficient 2: 0.9761877908630172 , Coefficient 3: 0.7387423273238324
Epoch: 31 , Train Loss: 0.002844839397148462
Epoch: 31 , Test Loss: 0.0028448810713598504
Epoch: 31 , D11: 0.8471330470088366 , D22: 0.8339223226427452
Epoch: 31 , D11*: 0.8408305872304109, D22*: 0.8805485087562511, D12*: 1.1326751147410785
Epoch: 31 , Coefficient 1: 0.9925602480027438 , Coefficient 2: 1.0559119055186639 , Coefficient 3: 0.7598732741560041
Epoch: 32 , Train Loss: 0.0028358199559443166
Epoch: 32 , Test Loss: 0.0028612169175175946
Epoch: 32 , D11: 0.8494173382054498 , D22: 0.8399598000112521
Epoch: 32 , D11*: 0.8882470529479816, D22*: 0.833329680769961, D12*: 1.1171033064435505
Epoch: 32 , Coefficient 1: 1.0457133531375362 , Coefficient 2: 0.9921066231488669 , Coefficient 3: 0.7705539513614077
Epoch: 33 , Train Loss: 0.0028299521430744786
Epoch: 33 , Test Loss: 0.0028578132402617483
Epoch: 33 , D11: 0.8516412014286056 , D22: 0.8403613455453837
Epoch: 33 , D11*: 0.8619318813431792, D22*: 0.8782667332810002, D12*: 1.1179703824538847
Epoch: 33 , Coefficient 1: 1.0120833514129088 , Coefficient 2: 1.0451060581695562 , Coefficient 3: 0.7782847568844075
Epoch: 34 , Train Loss: 0.002846275470947149
Epoch: 34 , Test Loss: 0.002853227209416218
Epoch: 34 , D11: 0.8505105875858924 , D22: 0.799816089708786
Epoch: 34 , D11*: 0.8708682639924599, D22*: 0.8289739876912524, D12*: 1.1083508875200079
Epoch: 34 , Coefficient 1: 1.0239358294931415 , Coefficient 2: 1.0364557532133203 , Coefficient 3: 0.7668339831834289
Epoch: 35 , Train Loss: 0.0028412434310303067
Epoch: 35 , Test Loss: 0.0028710602631326757
Epoch: 35 , D11: 0.8456591678214859 , D22: 0.8075823589333854
Epoch: 35 , D11*: 0.8339817310497176, D22*: 0.8038412791322856, D12*: 1.1112472721855617
Epoch: 35 , Coefficient 1: 0.986191320077744 , Coefficient 2: 0.9953675563121008 , Coefficient 3: 0.7369300475135435
Epoch: 36 , Train Loss: 0.0028313449604320338
Epoch: 36 , Test Loss: 0.0028797587385633963
Epoch: 36 , D11: 0.8439411708314942 , D22: 0.8115643825486532
Epoch: 36 , D11*: 0.8557745279596133, D22*: 0.7798601766883541, D12*: 1.107581806083551
Epoch: 36 , Coefficient 1: 1.0140215426585484 , Coefficient 2: 0.9609344538251734 , Coefficient 3: 0.7383809916631036
Epoch: 37 , Train Loss: 0.002841444422519999
Epoch: 37 , Test Loss: 0.0028822877584025264
Epoch: 37 , D11: 0.8409704248139716 , D22: 0.8073991912426174
Epoch: 37 , D11*: 0.8225692874177841, D22*: 0.812964341919029, D12*: 1.127523673969214
Epoch: 37 , Coefficient 1: 0.9781191622758222 , Coefficient 2: 1.0068926879501163 , Coefficient 3: 0.7252768465513699
Epoch: 38 , Train Loss: 0.0028422830828640144
Epoch: 38 , Test Loss: 0.002881878378684632
Epoch: 38 , D11: 0.8301728073309754 , D22: 0.8384234105780387
Epoch: 38 , D11*: 0.8362406870194513, D22*: 0.7972488565764035, D12*: 1.0978696243212698
Epoch: 38 , Coefficient 1: 1.0073091766375537 , Coefficient 2: 0.9508905005726784 , Coefficient 3: 0.7439360318424506
Epoch: 39 , Train Loss: 0.0028432986373081804
Epoch: 39 , Test Loss: 0.002866973626660183
Epoch: 39 , D11: 0.8305439548487462 , D22: 0.8282170434479742
Epoch: 39 , D11*: 0.8033165337102174, D22*: 0.8243139612873726, D12*: 1.1131035614558553
Epoch: 39 , Coefficient 1: 0.967217362814365 , Coefficient 2: 0.9952873679774173 , Coefficient 3: 0.7311226696951595
