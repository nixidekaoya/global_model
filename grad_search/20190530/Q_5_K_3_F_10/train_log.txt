Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.0032490726375544905
Epoch: 0 , Test Loss: 0.0029746283538406716
Epoch: 0 , D11: 0.8462824748278412 , D22: 0.7999243195277843
Epoch: 0 , D11*: 0.8484676381286884, D22*: 0.8001401817178774, D12*: 1.1155859950541627
Epoch: 0 , Coefficient 1: 1.002582073203503 , Coefficient 2: 1.0002698532658945 , Coefficient 3: 0.7388976856806653
Epoch: 1 , Train Loss: 0.002829510137962643
Epoch: 1 , Test Loss: 0.002867635434959084
Epoch: 1 , D11: 0.8177398502450683 , D22: 0.8171861764388461
Epoch: 1 , D11*: 0.8269369526166412, D22*: 0.8228585890260124, D12*: 1.0901682335830383
Epoch: 1 , Coefficient 1: 1.011246978325462 , Coefficient 2: 1.0069413956705504 , Coefficient 3: 0.7566701591644701
Epoch: 2 , Train Loss: 0.002844158678053645
Epoch: 2 , Test Loss: 0.0028547502664150676
Epoch: 2 , D11: 0.8347425849395749 , D22: 0.8214533505355051
Epoch: 2 , D11*: 0.8545165464365854, D22*: 0.7848468570600998, D12*: 1.106853984406726
Epoch: 2 , Coefficient 1: 1.0236886938006666 , Coefficient 2: 0.9554369174445007 , Coefficient 3: 0.7405508886410995
Epoch: 3 , Train Loss: 0.002841701782017481
Epoch: 3 , Test Loss: 0.002880747656454332
Epoch: 3 , D11: 0.8518896666772435 , D22: 0.8311109998539108
Epoch: 3 , D11*: 0.8487681664003642, D22*: 0.8206892203725151, D12*: 1.1158918258321107
Epoch: 3 , Coefficient 1: 0.9963357927687343 , Coefficient 2: 0.987460424079061 , Coefficient 3: 0.7480372864672523
Epoch: 4 , Train Loss: 0.0028347686346387483
Epoch: 4 , Test Loss: 0.002873564398032613
Epoch: 4 , D11: 0.8302397328254224 , D22: 0.7925871370985366
Epoch: 4 , D11*: 0.8220097140385323, D22*: 0.8152453430240015, D12*: 1.1124360181427098
Epoch: 4 , Coefficient 1: 0.9900871778818845 , Coefficient 2: 1.0285876528458575 , Coefficient 3: 0.7358872916556795
Epoch: 5 , Train Loss: 0.0028408793633570894
Epoch: 5 , Test Loss: 0.002871878841542639
Epoch: 5 , D11: 0.854935292408396 , D22: 0.792326238398282
Epoch: 5 , D11*: 0.8634583791462703, D22*: 0.7844275624237944, D12*: 1.09716045977582
Epoch: 5 , Coefficient 1: 1.0099692769892143 , Coefficient 2: 0.990031030664269 , Coefficient 3: 0.750977638178272
Epoch: 6 , Train Loss: 0.0028375111271452627
Epoch: 6 , Test Loss: 0.0028799885086482394
Epoch: 6 , D11: 0.8298410435676467 , D22: 0.8113559714514922
Epoch: 6 , D11*: 0.8174028369076635, D22*: 0.8148037811807337, D12*: 1.0974436453979464
Epoch: 6 , Coefficient 1: 0.9850113383082272 , Coefficient 2: 1.004249441491228 , Coefficient 3: 0.7436402884708213
Epoch: 7 , Train Loss: 0.0028356242763402408
Epoch: 7 , Test Loss: 0.002845795865287073
Epoch: 7 , D11: 0.8575297879499217 , D22: 0.8410184882505809
Epoch: 7 , D11*: 0.8611533508214549, D22*: 0.8412316273055276, D12*: 1.1302155003747707
Epoch: 7 , Coefficient 1: 1.0042255825073971 , Coefficient 2: 1.0002534296902201 , Coefficient 3: 0.7531240624299015
Epoch: 8 , Train Loss: 0.0028457012253056747
Epoch: 8 , Test Loss: 0.0028557164274388923
Epoch: 8 , D11: 0.8350978220800337 , D22: 0.8120071870356118
Epoch: 8 , D11*: 0.8011854271851206, D22*: 0.7995389775580387, D12*: 1.1244202370463134
Epoch: 8 , Coefficient 1: 0.9593911108396317 , Coefficient 2: 0.9846451981255354 , Coefficient 3: 0.7117998911812664
Epoch: 9 , Train Loss: 0.002831776555976831
Epoch: 9 , Test Loss: 0.0028608823620015758
Epoch: 9 , D11: 0.8469756522088485 , D22: 0.8304762688409952
Epoch: 9 , D11*: 0.8456434477341386, D22*: 0.809857897890991, D12*: 1.0830168431626093
Epoch: 9 , Coefficient 1: 0.9984271041661756 , Coefficient 2: 0.975172835487787 , Coefficient 3: 0.7643008306273242
Epoch: 10 , Train Loss: 0.0028420305189501955
Epoch: 10 , Test Loss: 0.0028430888894945385
Epoch: 10 , D11: 0.8205582304394565 , D22: 0.8215679705396499
Epoch: 10 , D11*: 0.8355486188355632, D22*: 0.8268062012603943, D12*: 1.1148963292898357
Epoch: 10 , Coefficient 1: 1.018268524816427 , Coefficient 2: 1.0063758945194803 , Coefficient 3: 0.7455199090819685
Epoch: 11 , Train Loss: 0.002841590274765622
Epoch: 11 , Test Loss: 0.0028825245756888764
Epoch: 11 , D11: 0.811091337330297 , D22: 0.8388911463583807
Epoch: 11 , D11*: 0.8143135296523849, D22*: 0.8315802588159041, D12*: 1.1241462118833931
Epoch: 11 , Coefficient 1: 1.0039726627246368 , Coefficient 2: 0.9912850581696886 , Coefficient 3: 0.7320639304164716
Epoch: 12 , Train Loss: 0.002833342888043262
Epoch: 12 , Test Loss: 0.0028390922496328128
Epoch: 12 , D11: 0.8320983693377837 , D22: 0.8244048364711366
Epoch: 12 , D11*: 0.834426550479882, D22*: 0.8502139338129093, D12*: 1.1185112307884753
Epoch: 12 , Coefficient 1: 1.0027979638320301 , Coefficient 2: 1.0313063390703148 , Coefficient 3: 0.7530726728176136
Epoch: 13 , Train Loss: 0.002837415046378737
Epoch: 13 , Test Loss: 0.002860068025765941
Epoch: 13 , D11: 0.8208916148467353 , D22: 0.8248876901672776
Epoch: 13 , D11*: 0.801552865068204, D22*: 0.787013572456312, D12*: 1.1031094052735788
Epoch: 13 , Coefficient 1: 0.9764417744940153 , Coefficient 2: 0.9540857280785883 , Coefficient 3: 0.7200402924361525
Epoch: 14 , Train Loss: 0.002836318911577109
Epoch: 14 , Test Loss: 0.002856832433026284
Epoch: 14 , D11: 0.8540782092565243 , D22: 0.8122994568006257
Epoch: 14 , D11*: 0.8609154982383116, D22*: 0.8066511939076046, D12*: 1.1032450700247962
Epoch: 14 , Coefficient 1: 1.0080054600476684 , Coefficient 2: 0.9930465755630717 , Coefficient 3: 0.7557553337212902
Epoch: 15 , Train Loss: 0.002838979456719244
Epoch: 15 , Test Loss: 0.002867407863959671
Epoch: 15 , D11: 0.8529696938748685 , D22: 0.7979728933261389
Epoch: 15 , D11*: 0.8547957536565572, D22*: 0.8265500390501223, D12*: 1.1322575987948749
Epoch: 15 , Coefficient 1: 1.0021408260982794 , Coefficient 2: 1.0358121760312773 , Coefficient 3: 0.7424749432003062
Epoch: 16 , Train Loss: 0.0028326143832236995
Epoch: 16 , Test Loss: 0.0028603768168250095
Epoch: 16 , D11: 0.8153217704250266 , D22: 0.8215470285303161
Epoch: 16 , D11*: 0.8403689549560477, D22*: 0.8423319483718444, D12*: 1.1101729020025843
Epoch: 16 , Coefficient 1: 1.0307206129402922 , Coefficient 2: 1.0252997322365232 , Coefficient 3: 0.7578553305942496
Epoch: 17 , Train Loss: 0.002835653965448728
Epoch: 17 , Test Loss: 0.002869125522556715
Epoch: 17 , D11: 0.8268382148550202 , D22: 0.8131320086559366
Epoch: 17 , D11*: 0.8590064916012282, D22*: 0.7964981026793579, D12*: 1.1079804689806811
Epoch: 17 , Coefficient 1: 1.0389051644786986 , Coefficient 2: 0.9795434126322569 , Coefficient 3: 0.7470820292543675
Epoch: 18 , Train Loss: 0.0028337897684832573
Epoch: 18 , Test Loss: 0.0028613983024843035
Epoch: 18 , D11: 0.8277926026399769 , D22: 0.8092165451231703
Epoch: 18 , D11*: 0.8136770413635672, D22*: 0.8176089768414203, D12*: 1.1208608147900776
Epoch: 18 , Coefficient 1: 0.9829479494846987 , Coefficient 2: 1.0103710579928549 , Coefficient 3: 0.7276933927387343
Epoch: 19 , Train Loss: 0.002843034771212842
Epoch: 19 , Test Loss: 0.002872826463426463
Epoch: 19 , D11: 0.8364343346952963 , D22: 0.791386702899883
Epoch: 19 , D11*: 0.8464048228578915, D22*: 0.7467775688926618, D12*: 1.1046375864218654
Epoch: 19 , Coefficient 1: 1.0119202282223714 , Coefficient 2: 0.9436316861987196 , Coefficient 3: 0.7211335243947199
Epoch: 20 , Train Loss: 0.0028459342193673364
Epoch: 20 , Test Loss: 0.002861846851301379
Epoch: 20 , D11: 0.8456662639053456 , D22: 0.814551216941163
Epoch: 20 , D11*: 0.8731121773037126, D22*: 0.8379668801051768, D12*: 1.1235703758339415
Epoch: 20 , Coefficient 1: 1.0324547810050029 , Coefficient 2: 1.0287467045374328 , Coefficient 3: 0.7614472107004799
Epoch: 21 , Train Loss: 0.0028459371736971662
Epoch: 21 , Test Loss: 0.0028692900715395807
Epoch: 21 , D11: 0.8415354893740737 , D22: 0.8269508838194302
Epoch: 21 , D11*: 0.8567980335557859, D22*: 0.7970238187568917, D12*: 1.1141603374132092
Epoch: 21 , Coefficient 1: 1.018136542515948 , Coefficient 2: 0.9638103475694776 , Coefficient 3: 0.7421830578498343
Epoch: 22 , Train Loss: 0.0028372705601213966
Epoch: 22 , Test Loss: 0.0028705442673526704
Epoch: 22 , D11: 0.8352724236593398 , D22: 0.826788646993308
Epoch: 22 , D11*: 0.8328562908486689, D22*: 0.8325383587702541, D12*: 1.1192920991895128
Epoch: 22 , Coefficient 1: 0.9971073715087039 , Coefficient 2: 1.0069542703541654 , Coefficient 3: 0.7439499710686991
Epoch: 23 , Train Loss: 0.0028362769160594327
Epoch: 23 , Test Loss: 0.002864768862491474
Epoch: 23 , D11: 0.8303226443675996 , D22: 0.832820747651951
Epoch: 23 , D11*: 0.8032136163926417, D22*: 0.8424307793643352, D12*: 1.1188948116887476
Epoch: 23 , Coefficient 1: 0.9673512120151738 , Coefficient 2: 1.011539135809811 , Coefficient 3: 0.735388339710507
Epoch: 24 , Train Loss: 0.0028393392203724943
Epoch: 24 , Test Loss: 0.0028663195372791955
Epoch: 24 , D11: 0.8440769106228646 , D22: 0.8170837906659294
Epoch: 24 , D11*: 0.8456167231094973, D22*: 0.8144364219682456, D12*: 1.1294905149228787
Epoch: 24 , Coefficient 1: 1.0018242561397592 , Coefficient 2: 0.9967599789300359 , Coefficient 3: 0.7348681211329565
Epoch: 25 , Train Loss: 0.002846851244539721
Epoch: 25 , Test Loss: 0.00285660985042341
Epoch: 25 , D11: 0.8478693710215245 , D22: 0.8185784788346334
Epoch: 25 , D11*: 0.8678148243445121, D22*: 0.7842230367101429, D12*: 1.1152326733535
Epoch: 25 , Coefficient 1: 1.0235242055022662 , Coefficient 2: 0.9580303623747836 , Coefficient 3: 0.7406695932280141
Epoch: 26 , Train Loss: 0.0028390924764971712
Epoch: 26 , Test Loss: 0.0028550181654281915
Epoch: 26 , D11: 0.8302849631392022 , D22: 0.812195893026599
Epoch: 26 , D11*: 0.8339083743452297, D22*: 0.8022598264502759, D12*: 1.1107454172625382
Epoch: 26 , Coefficient 1: 1.0043640573620987 , Coefficient 2: 0.9877664161298614 , Coefficient 3: 0.7365180964814989
Epoch: 27 , Train Loss: 0.002844817879522452
Epoch: 27 , Test Loss: 0.002861860126722604
Epoch: 27 , D11: 0.8412890692577384 , D22: 0.8199228285867828
Epoch: 27 , D11*: 0.8489656730432078, D22*: 0.7993363933257647, D12*: 1.1311003146940808
Epoch: 27 , Coefficient 1: 1.0091248110381874 , Coefficient 2: 0.9748922282155494 , Coefficient 3: 0.7286277109801595
Epoch: 28 , Train Loss: 0.002837167852121638
Epoch: 28 , Test Loss: 0.0028623134177178143
Epoch: 28 , D11: 0.8407088084478953 , D22: 0.7961361197804545
Epoch: 28 , D11*: 0.8448811589108328, D22*: 0.767453249389162, D12*: 1.1074359306902752
Epoch: 28 , Coefficient 1: 1.0049628960955463 , Coefficient 2: 0.9639724041170219 , Coefficient 3: 0.7279583240969126
Epoch: 29 , Train Loss: 0.0028440315296757034
Epoch: 29 , Test Loss: 0.0028532441344577817
Epoch: 29 , D11: 0.8391827866382087 , D22: 0.8345481985387172
Epoch: 29 , D11*: 0.8414907839491419, D22*: 0.8013368787305206, D12*: 1.0814196351053018
Epoch: 29 , Coefficient 1: 1.0027502915308584 , Coefficient 2: 0.9602044317316254 , Coefficient 3: 0.7595699251936064
Epoch: 30 , Train Loss: 0.00284136378497351
Epoch: 30 , Test Loss: 0.0028596065670717504
Epoch: 30 , D11: 0.8371851820851839 , D22: 0.8285908047206202
Epoch: 30 , D11*: 0.8214476157592024, D22*: 0.8616612693271097, D12*: 1.1363382439343581
Epoch: 30 , Coefficient 1: 0.9812018097515967 , Coefficient 2: 1.0399116963621629 , Coefficient 3: 0.7405844580478358
Epoch: 31 , Train Loss: 0.0028340255020884797
Epoch: 31 , Test Loss: 0.0028488024126272654
Epoch: 31 , D11: 0.8527478773137808 , D22: 0.8415031827250293
Epoch: 31 , D11*: 0.8701950393971221, D22*: 0.8199208205424696, D12*: 1.0872076357451708
Epoch: 31 , Coefficient 1: 1.0204599302413992 , Coefficient 2: 0.9743526077790107 , Coefficient 3: 0.7772737259986168
Epoch: 32 , Train Loss: 0.0028356867337424774
Epoch: 32 , Test Loss: 0.0028646194067550824
Epoch: 32 , D11: 0.8348146276860097 , D22: 0.8229776358456999
Epoch: 32 , D11*: 0.8713890062872311, D22*: 0.8830909564603411, D12*: 1.1101419710151832
Epoch: 32 , Coefficient 1: 1.0438113772665922 , Coefficient 2: 1.0730436867252997 , Coefficient 3: 0.7902052208435855
Epoch: 33 , Train Loss: 0.0028434354842465834
Epoch: 33 , Test Loss: 0.0028611811605514957
Epoch: 33 , D11: 0.8441956691787667 , D22: 0.8415887645150072
Epoch: 33 , D11*: 0.8728703485050516, D22*: 0.8597372906054402, D12*: 1.1403907224331609
Epoch: 33 , Coefficient 1: 1.0339668638127222 , Coefficient 2: 1.0215646012110104 , Coefficient 3: 0.7596552677198938
Epoch: 34 , Train Loss: 0.002838780423480785
Epoch: 34 , Test Loss: 0.002860298498417251
Epoch: 34 , D11: 0.8300541435036416 , D22: 0.8166207673573154
Epoch: 34 , D11*: 0.8176609526426284, D22*: 0.7955544469201082, D12*: 1.1224805027243532
Epoch: 34 , Coefficient 1: 0.9850694187144204 , Coefficient 2: 0.9742030557153472 , Coefficient 3: 0.7185939513636669
Epoch: 35 , Train Loss: 0.0028386623655387664
Epoch: 35 , Test Loss: 0.0028710109577514227
Epoch: 35 , D11: 0.8383404193672763 , D22: 0.8201471471775534
Epoch: 35 , D11*: 0.8286321233997201, D22*: 0.822299511898339, D12*: 1.1225333431399493
Epoch: 35 , Coefficient 1: 0.9884196255563064 , Coefficient 2: 1.002624364089045 , Coefficient 3: 0.7353597313555402
Epoch: 36 , Train Loss: 0.002840584299119655
Epoch: 36 , Test Loss: 0.0028705959755461665
Epoch: 36 , D11: 0.8302084147263177 , D22: 0.7968632942564183
Epoch: 36 , D11*: 0.8634902717543338, D22*: 0.7674201293909259, D12*: 1.0946697771810965
Epoch: 36 , Coefficient 1: 1.0400885566053768 , Coefficient 2: 0.9630511719165494 , Coefficient 3: 0.7449325975478404
Epoch: 37 , Train Loss: 0.0028383032810234
Epoch: 37 , Test Loss: 0.0028619007463566958
Epoch: 37 , D11: 0.8419734305704306 , D22: 0.8358290157810973
Epoch: 37 , D11*: 0.8452850061110476, D22*: 0.8226770129663081, D12*: 1.1410209447194088
Epoch: 37 , Coefficient 1: 1.0039331116878278 , Coefficient 2: 0.9842647209339839 , Coefficient 3: 0.730907713305617
Epoch: 38 , Train Loss: 0.0028403223060013256
Epoch: 38 , Test Loss: 0.002869656408438459
Epoch: 38 , D11: 0.8271935674452414 , D22: 0.8270353656071695
Epoch: 38 , D11*: 0.831226134077135, D22*: 0.8262245878315161, D12*: 1.1123386447603498
Epoch: 38 , Coefficient 1: 1.00487499757082 , Coefficient 2: 0.9990196576720052 , Coefficient 3: 0.7450297307011858
Epoch: 39 , Train Loss: 0.0028413499744783625
Epoch: 39 , Test Loss: 0.0028668466000817713
Epoch: 39 , D11: 0.8161218056920088 , D22: 0.8359692607758888
Epoch: 39 , D11*: 0.8556848589658992, D22*: 0.8863375837568073, D12*: 1.1043064605755248
Epoch: 39 , Coefficient 1: 1.0484768976860555 , Coefficient 2: 1.0602514055770065 , Coefficient 3: 0.788740492297232
