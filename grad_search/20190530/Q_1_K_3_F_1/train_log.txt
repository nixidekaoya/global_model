Optimizer: Adam
Learning Rate: 0.5
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.027214834599872118
Epoch: 0 , Test Loss: 0.02863753370475024
Epoch: 0 , D11: 771.3747819437195 , D22: 2673.8778100318686
Epoch: 0 , D11*: 479.62912983173254, D22*: 441.75052520084483, D12*: 68692.0008195547
Epoch: 0 , Coefficient 1: 0.6217848198552165 , Coefficient 2: 0.1652096904142302 , Coefficient 3: 0.006706600798053085
Epoch: 1 , Train Loss: 0.03422107269550906
Epoch: 1 , Test Loss: 0.053501718624029304
Epoch: 1 , D11: 222452948529579.2 , D22: 1117121715108.3115
Epoch: 1 , D11*: 303307558771190.7, D22*: 2110295281640.8552, D12*: 66006445941129.42
Epoch: 1 , Coefficient 1: 1.3634683683721118 , Coefficient 2: 1.889046872064652 , Coefficient 3: 2.313545667382479
Epoch: 2 , Train Loss: 0.03993855154520133
Epoch: 2 , Test Loss: 0.033620303502539174
Epoch: 2 , D11: 85626811.281904 , D22: 289879459.9540873
Epoch: 2 , D11*: 692803.1858537372, D22*: 337893688.55214614, D12*: 38808268.2399729
Epoch: 2 , Coefficient 1: 0.008090960944147072 , Coefficient 2: 1.1656351526447013 , Coefficient 3: 4.3622983850288435
Epoch: 3 , Train Loss: 0.050792129463225144
Epoch: 3 , Test Loss: 0.04819141557207331
Epoch: 3 , D11: 146987.20114271063 , D22: 5605.132693540703
Epoch: 3 , D11*: 6149.094589095998, D22*: 560.9724346677001, D12*: 6231399.77217508
Epoch: 3 , Coefficient 1: 0.04183421781822902 , Coefficient 2: 0.10008191872320149 , Coefficient 3: 0.0005384076827911121
Epoch: 4 , Train Loss: 0.023867695062508573
Epoch: 4 , Test Loss: 0.018813500786200164
Epoch: 4 , D11: 610448.6801178916 , D22: 3763518.3652302492
Epoch: 4 , D11*: 697171.8769944931, D22*: 5368.663280101555, D12*: 55015.21338235946
Epoch: 4 , Coefficient 1: 1.1420646807850467 , Coefficient 2: 0.0014265011510773123 , Coefficient 3: 6.384966058314546
Epoch: 5 , Train Loss: 0.04553108872525627
Epoch: 5 , Test Loss: 0.03691911575384439
Epoch: 5 , D11: 44806.66034665094 , D22: 2154237288.6599903
Epoch: 5 , D11*: 7.928620211691286e+16, D22*: 435.1027498022151, D12*: 120612983.79043427
Epoch: 5 , Coefficient 1: 1769518225717.0632 , Coefficient 2: 2.0197531260489135e-07 , Coefficient 3: 328680211.8032065
Epoch: 6 , Train Loss: 0.0713295083286357
Epoch: 6 , Test Loss: 0.03253358176210895
Epoch: 6 , D11: 106680.45238567023 , D22: 659.2748011380886
Epoch: 6 , D11*: 71.69450491156994, D22*: 21.222212347506304, D12*: 162857.90382459247
Epoch: 6 , Coefficient 1: 0.0006720491271669959 , Coefficient 2: 0.03219023738033209 , Coefficient 3: 0.00028526929021250637
Epoch: 7 , Train Loss: 0.02229360363242449
Epoch: 7 , Test Loss: 0.01885705474298447
Epoch: 7 , D11: 776.4276865281793 , D22: 1352.4410785783343
Epoch: 7 , D11*: 15.380371492707678, D22*: 2573.024388266679, D12*: 215968.2990518583
Epoch: 7 , Coefficient 1: 0.019809148694170723 , Coefficient 2: 1.9025038717186877 , Coefficient 3: 0.00599255717418476
Epoch: 8 , Train Loss: 0.02725052663416136
Epoch: 8 , Test Loss: 0.02251655936124735
Epoch: 8 , D11: 8555.466104353316 , D22: 182.87088732598062
Epoch: 8 , D11*: 1945.1309001141037, D22*: 27.579416570574157, D12*: 3021.5822723720803
Epoch: 8 , Coefficient 1: 0.22735533942731118 , Coefficient 2: 0.15081359845655393 , Coefficient 3: 0.3264366379698161
Epoch: 9 , Train Loss: 0.04148702642618446
Epoch: 9 , Test Loss: 0.04210798682877794
Epoch: 9 , D11: 175813.04358716408 , D22: 461514.2551553273
Epoch: 9 , D11*: 131408.33112438404, D22*: 267.213469465094, D12*: 1754873.820103494
Epoch: 9 , Coefficient 1: 0.7474322066396331 , Coefficient 2: 0.000578992883708783 , Coefficient 3: 0.037517097550091534
