Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.003315287292934954
Epoch: 0 , Test Loss: 0.003040475173620507
Epoch: 0 , D11: 0.8558970443722161 , D22: 0.8406323631370181
Epoch: 0 , D11*: 0.888106941641471, D22*: 0.7877659677230041, D12*: 1.1084395571152557
Epoch: 0 , Coefficient 1: 1.0376329109687255 , Coefficient 2: 0.9371111585369727 , Coefficient 3: 0.7559604394334231
Epoch: 1 , Train Loss: 0.0028331269127374985
Epoch: 1 , Test Loss: 0.0028806223260471595
Epoch: 1 , D11: 0.8415761219413838 , D22: 0.8255054021053108
Epoch: 1 , D11*: 0.8118887696690822, D22*: 0.8474441414470544, D12*: 1.0804860462723058
Epoch: 1 , Coefficient 1: 0.9647241033837587 , Coefficient 2: 1.0265761305568597 , Coefficient 3: 0.7678641093241609
Epoch: 2 , Train Loss: 0.0028358557609317356
Epoch: 2 , Test Loss: 0.002860963137354702
Epoch: 2 , D11: 0.8380255982905521 , D22: 0.8257514633482572
Epoch: 2 , D11*: 0.8012188372090715, D22*: 0.8172555613828878, D12*: 1.1201656150537933
Epoch: 2 , Coefficient 1: 0.9560791923819977 , Coefficient 2: 0.9897113086170987 , Coefficient 3: 0.7224263880454124
Epoch: 3 , Train Loss: 0.0028394149336963895
Epoch: 3 , Test Loss: 0.0028755897167138753
Epoch: 3 , D11: 0.8264336612149008 , D22: 0.8211098306270626
Epoch: 3 , D11*: 0.822584675831209, D22*: 0.7662083143591019, D12*: 1.1094646266301862
Epoch: 3 , Coefficient 1: 0.9953426565684248 , Coefficient 2: 0.9331374266630889 , Coefficient 3: 0.7160178666606094
Epoch: 4 , Train Loss: 0.0028380613976332824
Epoch: 4 , Test Loss: 0.0028587599820457396
Epoch: 4 , D11: 0.8261714423020496 , D22: 0.8372798861611404
Epoch: 4 , D11*: 0.828075551540144, D22*: 0.8482251785786251, D12*: 1.1336622651461472
Epoch: 4 , Coefficient 1: 1.002304738630022 , Coefficient 2: 1.0130724416033305 , Coefficient 3: 0.739329861130496
Epoch: 5 , Train Loss: 0.002834450852678856
Epoch: 5 , Test Loss: 0.0028798657748848196
Epoch: 5 , D11: 0.8160860233055036 , D22: 0.8089994192155852
Epoch: 5 , D11*: 0.8135095217597246, D22*: 0.8265404143585653, D12*: 1.0931465216562566
Epoch: 5 , Coefficient 1: 0.9968428554439113 , Coefficient 2: 1.0216823334187162 , Coefficient 3: 0.7501510106958968
Epoch: 6 , Train Loss: 0.0028406753805757037
Epoch: 6 , Test Loss: 0.0028784209757577624
Epoch: 6 , D11: 0.8321704771799264 , D22: 0.8240411805454795
Epoch: 6 , D11*: 0.8601217606253944, D22*: 0.823552471859564, D12*: 1.1274826090009653
Epoch: 6 , Coefficient 1: 1.033588410322113 , Coefficient 2: 0.9994069365737378 , Coefficient 3: 0.7466519745155186
Epoch: 7 , Train Loss: 0.0028458976304682436
Epoch: 7 , Test Loss: 0.0028757975884946066
Epoch: 7 , D11: 0.8506419384277074 , D22: 0.820108540478286
Epoch: 7 , D11*: 0.8534583275896631, D22*: 0.8328681495049708, D12*: 1.101407019361331
Epoch: 7 , Coefficient 1: 1.0033108985517 , Coefficient 2: 1.015558439397843 , Coefficient 3: 0.7655328354782404
Epoch: 8 , Train Loss: 0.002840642553783255
Epoch: 8 , Test Loss: 0.0028623361361678687
Epoch: 8 , D11: 0.8088186178801494 , D22: 0.796652999417247
Epoch: 8 , D11*: 0.805530820553353, D22*: 0.8255596821656147, D12*: 1.1390723620162584
Epoch: 8 , Coefficient 1: 0.9959350622573285 , Coefficient 2: 1.0362851615063433 , Coefficient 3: 0.7159731712881673
Epoch: 9 , Train Loss: 0.0028457291274389717
Epoch: 9 , Test Loss: 0.0028493592911399902
Epoch: 9 , D11: 0.8328350871955993 , D22: 0.8058332128655243
Epoch: 9 , D11*: 0.8065448629937071, D22*: 0.8448619998769861, D12*: 1.1326173938505637
Epoch: 9 , Coefficient 1: 0.9684328571092998 , Coefficient 2: 1.0484328349692567 , Coefficient 3: 0.7290223829498146
Epoch: 10 , Train Loss: 0.0028388723472016863
Epoch: 10 , Test Loss: 0.0028631682059494777
Epoch: 10 , D11: 0.836127222795166 , D22: 0.8135721381193263
Epoch: 10 , D11*: 0.852553348244782, D22*: 0.8480073778134299, D12*: 1.1170178732433331
Epoch: 10 , Coefficient 1: 1.0196454857607717 , Coefficient 2: 1.04232598202503 , Coefficient 3: 0.761205691866203
Epoch: 11 , Train Loss: 0.0028413129906402898
Epoch: 11 , Test Loss: 0.002881087457062677
Epoch: 11 , D11: 0.8407816478638989 , D22: 0.823357828527307
Epoch: 11 , D11*: 0.8336390827678241, D22*: 0.8207094517647648, D12*: 1.1197407307194085
Epoch: 11 , Coefficient 1: 0.9915048513318276 , Coefficient 2: 0.9967834437582513 , Coefficient 3: 0.7387194594009753
Epoch: 12 , Train Loss: 0.0028409076259413267
Epoch: 12 , Test Loss: 0.0028726646321592855
Epoch: 12 , D11: 0.8369354170834981 , D22: 0.8293904333214304
Epoch: 12 , D11*: 0.8149888878961622, D22*: 0.8217913477704061, D12*: 1.106680440123731
Epoch: 12 , Coefficient 1: 0.973777511694016 , Coefficient 2: 0.9908377463185915 , Coefficient 3: 0.7394999388818919
Epoch: 13 , Train Loss: 0.002839531860081479
Epoch: 13 , Test Loss: 0.0028748512209858753
Epoch: 13 , D11: 0.8307523881777105 , D22: 0.8417630554676426
Epoch: 13 , D11*: 0.8403228441157623, D22*: 0.8488553091700981, D12*: 1.1189489119089933
Epoch: 13 , Coefficient 1: 1.011520226813967 , Coefficient 2: 1.0084254751457526 , Coefficient 3: 0.7548057535549243
Epoch: 14 , Train Loss: 0.002831437441491289
Epoch: 14 , Test Loss: 0.0028608291811542583
Epoch: 14 , D11: 0.8166892594094245 , D22: 0.8265265118413411
Epoch: 14 , D11*: 0.8321832495960421, D22*: 0.8620167306445325, D12*: 1.1416644905764644
Epoch: 14 , Coefficient 1: 1.0189717080371814 , Coefficient 2: 1.0429389962629585 , Coefficient 3: 0.7419868070807374
Epoch: 15 , Train Loss: 0.0028463641612324862
Epoch: 15 , Test Loss: 0.0028578511427622285
Epoch: 15 , D11: 0.8402466063219098 , D22: 0.8213622335412372
Epoch: 15 , D11*: 0.8349449350459125, D22*: 0.8303879526293144, D12*: 1.1005924959158113
Epoch: 15 , Coefficient 1: 0.993690338959886 , Coefficient 2: 1.0109887193731364 , Coefficient 3: 0.7565619854101816
Epoch: 16 , Train Loss: 0.0028417315336992034
Epoch: 16 , Test Loss: 0.002871312181232497
Epoch: 16 , D11: 0.8468670454352818 , D22: 0.8490055465457335
Epoch: 16 , D11*: 0.8713168378913057, D22*: 0.8351571164859657, D12*: 1.1509438725307541
Epoch: 16 , Coefficient 1: 1.028870874817731 , Coefficient 2: 0.9836886459504163 , Coefficient 3: 0.7413367389606017
Epoch: 17 , Train Loss: 0.0028465228174172808
Epoch: 17 , Test Loss: 0.0028637701465049764
Epoch: 17 , D11: 0.8264199582008566 , D22: 0.8233644765345315
Epoch: 17 , D11*: 0.8258056256818774, D22*: 0.8332365456530008, D12*: 1.121209566826625
Epoch: 17 , Coefficient 1: 0.9992566339753984 , Coefficient 2: 1.0119899138228794 , Coefficient 3: 0.7398448160010301
Epoch: 18 , Train Loss: 0.0028437233639124317
Epoch: 18 , Test Loss: 0.0028555892559234053
Epoch: 18 , D11: 0.8285526550918395 , D22: 0.8277464013020842
Epoch: 18 , D11*: 0.8216857996231577, D22*: 0.836974244232781, D12*: 1.1290245732076227
Epoch: 18 , Coefficient 1: 0.9917122280322418 , Coefficient 2: 1.011148152279709 , Coefficient 3: 0.7345544478024918
Epoch: 19 , Train Loss: 0.0028363110635837075
Epoch: 19 , Test Loss: 0.0028545270091854032
Epoch: 19 , D11: 0.8426539257772271 , D22: 0.8061827336619001
Epoch: 19 , D11*: 0.8600909136490599, D22*: 0.7705693675913835, D12*: 1.1186029071011276
Epoch: 19 , Coefficient 1: 1.0206929408840641 , Coefficient 2: 0.9558246975735253 , Coefficient 3: 0.7288825511218804
Epoch: 20 , Train Loss: 0.0028332398903148713
Epoch: 20 , Test Loss: 0.0028632103686686604
Epoch: 20 , D11: 0.8578865048985743 , D22: 0.8415741893261667
Epoch: 20 , D11*: 0.8456468257350721, D22*: 0.8280319035030753, D12*: 1.1002444771437168
Epoch: 20 , Coefficient 1: 0.9857327524170003 , Coefficient 2: 0.9839083874067782 , Coefficient 3: 0.7605940152424538
Epoch: 21 , Train Loss: 0.0028371116994821933
Epoch: 21 , Test Loss: 0.0028759769099997354
Epoch: 21 , D11: 0.8320648798426888 , D22: 0.8160579390599595
Epoch: 21 , D11*: 0.840518861281358, D22*: 0.7998660964134554, D12*: 1.1430580185633887
Epoch: 21 , Coefficient 1: 1.0101602430813659 , Coefficient 2: 0.9801584644036967 , Coefficient 3: 0.7175422992773682
Epoch: 22 , Train Loss: 0.002838367287768051
Epoch: 22 , Test Loss: 0.0028544549818616356
Epoch: 22 , D11: 0.8419685726070937 , D22: 0.8251481646344387
Epoch: 22 , D11*: 0.8222442765316624, D22*: 0.8072564752115235, D12*: 1.1192866424244547
Epoch: 22 , Coefficient 1: 0.9765735958358203 , Coefficient 2: 0.9783169978559648 , Coefficient 3: 0.7279193237817845
Epoch: 23 , Train Loss: 0.0028364968158712143
Epoch: 23 , Test Loss: 0.0028688233805587516
Epoch: 23 , D11: 0.848815935755749 , D22: 0.8137607816893868
Epoch: 23 , D11*: 0.8279306349884687, D22*: 0.8058862706843545, D12*: 1.1261880369297268
Epoch: 23 , Coefficient 1: 0.9753947824404535 , Coefficient 2: 0.9903233097708584 , Coefficient 3: 0.7253748273365703
Epoch: 24 , Train Loss: 0.0028447551789577115
Epoch: 24 , Test Loss: 0.002869719044538214
Epoch: 24 , D11: 0.8262228806265436 , D22: 0.8285178194119408
Epoch: 24 , D11*: 0.8549856725448247, D22*: 0.8126606548381957, D12*: 1.1422092057846671
Epoch: 24 , Coefficient 1: 1.0348123885124916 , Coefficient 2: 0.9808608044362883 , Coefficient 3: 0.7300091432188169
Epoch: 25 , Train Loss: 0.002836005109566031
Epoch: 25 , Test Loss: 0.0028702684340532873
Epoch: 25 , D11: 0.8396691345047499 , D22: 0.8271960630958176
Epoch: 25 , D11*: 0.7838035326480658, D22*: 0.8126632996055929, D12*: 1.1230312225964694
Epoch: 25 , Coefficient 1: 0.933467124655434 , Coefficient 2: 0.9824312951444242 , Coefficient 3: 0.7107847048822905
Epoch: 26 , Train Loss: 0.0028349186849663966
Epoch: 26 , Test Loss: 0.002848309784312732
Epoch: 26 , D11: 0.8341394377588115 , D22: 0.8214255712534659
Epoch: 26 , D11*: 0.8368581928629321, D22*: 0.827025013730139, D12*: 1.1383794571066945
Epoch: 26 , Coefficient 1: 1.0032593532700305 , Coefficient 2: 1.0068167374776615 , Coefficient 3: 0.7308122068637803
Epoch: 27 , Train Loss: 0.002835561113170115
Epoch: 27 , Test Loss: 0.0028613250679336484
Epoch: 27 , D11: 0.8596486885790732 , D22: 0.8215387805591458
Epoch: 27 , D11*: 0.885396020536798, D22*: 0.8546317026537386, D12*: 1.1201378266339597
Epoch: 27 , Coefficient 1: 1.0299509931205537 , Coefficient 2: 1.040281631102149 , Coefficient 3: 0.7767025100917092
Epoch: 28 , Train Loss: 0.0028420117865607607
Epoch: 28 , Test Loss: 0.00288056508929003
Epoch: 28 , D11: 0.8547803499511556 , D22: 0.8124833989584271
Epoch: 28 , D11*: 0.8542513765995777, D22*: 0.8151398294524123, D12*: 1.115547547153084
Epoch: 28 , Coefficient 1: 0.999381158736735 , Coefficient 2: 1.003269519718668 , Coefficient 3: 0.7482384817717247
Epoch: 29 , Train Loss: 0.002843790932674892
Epoch: 29 , Test Loss: 0.0028709820949006826
Epoch: 29 , D11: 0.8317514835844495 , D22: 0.8266770813372573
Epoch: 29 , D11*: 0.8291632775620467, D22*: 0.8684618977953421, D12*: 1.1155713805115528
Epoch: 29 , Coefficient 1: 0.9968882459803391 , Coefficient 2: 1.0505455121490637 , Coefficient 3: 0.7608769842136552
Epoch: 30 , Train Loss: 0.0028397186977963426
Epoch: 30 , Test Loss: 0.002856456699664705
Epoch: 30 , D11: 0.84008001874041 , D22: 0.8086624647285029
Epoch: 30 , D11*: 0.8461155702392111, D22*: 0.7927478606182654, D12*: 1.1218319885076238
Epoch: 30 , Coefficient 1: 1.0071844959577192 , Coefficient 2: 0.9803198431924491 , Coefficient 3: 0.7304406754516161
Epoch: 31 , Train Loss: 0.0028369345553801396
Epoch: 31 , Test Loss: 0.002848092095809989
Epoch: 31 , D11: 0.8507736318359185 , D22: 0.838672693775236
Epoch: 31 , D11*: 0.8427230037136886, D22*: 0.8407405610756088, D12*: 1.0941992455294154
Epoch: 31 , Coefficient 1: 0.9905372853353986 , Coefficient 2: 1.002465642813604 , Coefficient 3: 0.7692673759680639
Epoch: 32 , Train Loss: 0.0028420234902296216
Epoch: 32 , Test Loss: 0.002875769438687712
Epoch: 32 , D11: 0.8298264461455315 , D22: 0.8080181611369509
Epoch: 32 , D11*: 0.8282677579745549, D22*: 0.7874825785852942, D12*: 1.1101404434639515
Epoch: 32 , Coefficient 1: 0.9981216696838037 , Coefficient 2: 0.9745852462984727 , Coefficient 3: 0.7277233912487019
Epoch: 33 , Train Loss: 0.002843147349631181
Epoch: 33 , Test Loss: 0.0028587362379767006
Epoch: 33 , D11: 0.8474145426465957 , D22: 0.8091827331776235
Epoch: 33 , D11*: 0.8366258573839988, D22*: 0.8307725430627664, D12*: 1.1029681833273746
Epoch: 33 , Coefficient 1: 0.9872687041351659 , Coefficient 2: 1.0266810066502046 , Coefficient 3: 0.7558687665026964
Epoch: 34 , Train Loss: 0.002838457737234421
Epoch: 34 , Test Loss: 0.0028645554766990244
Epoch: 34 , D11: 0.8375760933369049 , D22: 0.8404743297890387
Epoch: 34 , D11*: 0.8395639230190599, D22*: 0.831940942128594, D12*: 1.0858505684590125
Epoch: 34 , Coefficient 1: 1.0023733123449543 , Coefficient 2: 0.9898469383799187 , Coefficient 3: 0.7696753649628669
Epoch: 35 , Train Loss: 0.0028420062726945616
Epoch: 35 , Test Loss: 0.0028744299290701754
Epoch: 35 , D11: 0.8217438495540869 , D22: 0.837077252912631
Epoch: 35 , D11*: 0.8015365685653639, D22*: 0.8604538039845119, D12*: 1.1009010606747915
Epoch: 35 , Coefficient 1: 0.9754092701762377 , Coefficient 2: 1.027926396268136 , Coefficient 3: 0.7548318517974574
Epoch: 36 , Train Loss: 0.0028425830043852336
Epoch: 36 , Test Loss: 0.0028707483393372963
Epoch: 36 , D11: 0.8234613913021942 , D22: 0.8243753144004826
Epoch: 36 , D11*: 0.8406737699267102, D22*: 0.8826264129124909, D12*: 1.1247867308241333
Epoch: 36 , Coefficient 1: 1.0209024719389659 , Coefficient 2: 1.0706608961894628 , Coefficient 3: 0.7660564156800356
Epoch: 37 , Train Loss: 0.0028495720034698024
Epoch: 37 , Test Loss: 0.0028707636817125607
Epoch: 37 , D11: 0.8512446378663959 , D22: 0.8224161534190534
Epoch: 37 , D11*: 0.8314019891900697, D22*: 0.8373898400079328, D12*: 1.1088419185862994
Epoch: 37 , Coefficient 1: 0.9766898400369829 , Coefficient 2: 1.0182069461143595 , Coefficient 3: 0.7524931197251283
Epoch: 38 , Train Loss: 0.0028354841363034213
Epoch: 38 , Test Loss: 0.0028674234141362826
Epoch: 38 , D11: 0.8253386900206184 , D22: 0.8243232849818831
Epoch: 38 , D11*: 0.846936924976624, D22*: 0.803037094656554, D12*: 1.0724848170870902
Epoch: 38 , Coefficient 1: 1.026168935513572 , Coefficient 2: 0.9741773758995576 , Coefficient 3: 0.7692295468175347
Epoch: 39 , Train Loss: 0.002838736950943712
Epoch: 39 , Test Loss: 0.002871714245993644
Epoch: 39 , D11: 0.8437304113128771 , D22: 0.8276011866724413
Epoch: 39 , D11*: 0.8579034525807947, D22*: 0.7749085441302251, D12*: 1.1099908254718465
Epoch: 39 , Coefficient 1: 1.0167980685274385 , Coefficient 2: 0.9363308760417818 , Coefficient 3: 0.7355069786351284
