Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.003274543187435484
Epoch: 0 , Test Loss: 0.00299973983084783
Epoch: 0 , D11: 0.8477031253706111 , D22: 0.8226970060974967
Epoch: 0 , D11*: 0.851178812137059, D22*: 0.8075672946433009, D12*: 1.085907299293118
Epoch: 0 , Coefficient 1: 1.0041001226283417 , Coefficient 2: 0.981609618921595 , Coefficient 3: 0.7637604553630577
Epoch: 1 , Train Loss: 0.0028306527272798122
Epoch: 1 , Test Loss: 0.0028687111858744173
Epoch: 1 , D11: 0.8428096316001017 , D22: 0.8292227365741929
Epoch: 1 , D11*: 0.8217887196765541, D22*: 0.822225822047405, D12*: 1.0937625912912916
Epoch: 1 , Coefficient 1: 0.9750585290730023 , Coefficient 2: 0.991562080707417 , Coefficient 3: 0.7515408530214231
Epoch: 2 , Train Loss: 0.0028354149709048215
Epoch: 2 , Test Loss: 0.0028535063244635233
Epoch: 2 , D11: 0.8243572604459228 , D22: 0.8128845918234897
Epoch: 2 , D11*: 0.8117789104105998, D22*: 0.7939881914946809, D12*: 1.110463491252577
Epoch: 2 , Coefficient 1: 0.9847416276427056 , Coefficient 2: 0.9767538953021366 , Coefficient 3: 0.7230166117816322
Epoch: 3 , Train Loss: 0.00284386023748084
Epoch: 3 , Test Loss: 0.002860542787821032
Epoch: 3 , D11: 0.8229199936528826 , D22: 0.8314175405292666
Epoch: 3 , D11*: 0.821512579552273, D22*: 0.8279776277944073, D12*: 1.1162856652827913
Epoch: 3 , Coefficient 1: 0.9982897315517123 , Coefficient 2: 0.9958625930207468 , Coefficient 3: 0.7388297900111488
Epoch: 4 , Train Loss: 0.002830521913565462
Epoch: 4 , Test Loss: 0.002859644982381724
Epoch: 4 , D11: 0.852529275066013 , D22: 0.8103503734041293
Epoch: 4 , D11*: 0.8362099337832624, D22*: 0.7980193406392921, D12*: 1.1184448456971683
Epoch: 4 , Coefficient 1: 0.9808577350244225 , Coefficient 2: 0.9847830849845397 , Coefficient 3: 0.730581074565138
Epoch: 5 , Train Loss: 0.0028365597969968797
Epoch: 5 , Test Loss: 0.0028667764307465397
Epoch: 5 , D11: 0.8621124967702439 , D22: 0.8342340103677606
Epoch: 5 , D11*: 0.8770018918566352, D22*: 0.8276179933365253, D12*: 1.0924694910067734
Epoch: 5 , Coefficient 1: 1.0172708261881969 , Coefficient 2: 0.9920693511065094 , Coefficient 3: 0.7801681874073461
Epoch: 6 , Train Loss: 0.0028398511673731267
Epoch: 6 , Test Loss: 0.0028662928967969495
Epoch: 6 , D11: 0.8271640222434133 , D22: 0.8085145853147914
Epoch: 6 , D11*: 0.8097794706892333, D22*: 0.8247192370051946, D12*: 1.1091274065222156
Epoch: 6 , Coefficient 1: 0.9789829452361454 , Coefficient 2: 1.0200424976676135 , Coefficient 3: 0.7368399239270303
Epoch: 7 , Train Loss: 0.0028386104799574237
Epoch: 7 , Test Loss: 0.0028603465668857095
Epoch: 7 , D11: 0.828915332291036 , D22: 0.7963812445519439
Epoch: 7 , D11*: 0.795380160137111, D22*: 0.793013639668965, D12*: 1.1044270484909346
Epoch: 7 , Coefficient 1: 0.9595433081672681 , Coefficient 2: 0.9957713659054419 , Coefficient 3: 0.7191030869700371
Epoch: 8 , Train Loss: 0.0028316306760825683
Epoch: 8 , Test Loss: 0.002866238088463433
Epoch: 8 , D11: 0.8171670201022975 , D22: 0.8458498886732321
Epoch: 8 , D11*: 0.7902410504288724, D22*: 0.799248023648581, D12*: 1.1568839987363622
Epoch: 8 , Coefficient 1: 0.9670496128563114 , Coefficient 2: 0.9449052773444837 , Coefficient 3: 0.6869699450479114
Epoch: 9 , Train Loss: 0.002836197229626123
Epoch: 9 , Test Loss: 0.002865311676287092
Epoch: 9 , D11: 0.8580037038845627 , D22: 0.8026252825145834
Epoch: 9 , D11*: 0.8291629275528103, D22*: 0.7846933848527492, D12*: 1.1039052607968325
Epoch: 9 , Coefficient 1: 0.9663861866782423 , Coefficient 2: 0.9776584440429604 , Coefficient 3: 0.7309759132955977
Epoch: 10 , Train Loss: 0.0028463378285232465
Epoch: 10 , Test Loss: 0.0028535828011808915
Epoch: 10 , D11: 0.8173533105006024 , D22: 0.8409916284920946
Epoch: 10 , D11*: 0.8330710577299278, D22*: 0.8516178884038549, D12*: 1.0891744175225617
Epoch: 10 , Coefficient 1: 1.0192300526925115 , Coefficient 2: 1.0126353932093393 , Coefficient 3: 0.7733788633990227
Epoch: 11 , Train Loss: 0.002841107771237148
Epoch: 11 , Test Loss: 0.002869088730658405
Epoch: 11 , D11: 0.8466320364235573 , D22: 0.8389079032505907
Epoch: 11 , D11*: 0.8751695196825613, D22*: 0.8264972970534337, D12*: 1.1079292189486962
Epoch: 11 , Coefficient 1: 1.0337070675704114 , Coefficient 2: 0.9852062352147731 , Coefficient 3: 0.7679492460496217
Epoch: 12 , Train Loss: 0.002843766676232917
Epoch: 12 , Test Loss: 0.0028769766312325374
Epoch: 12 , D11: 0.8472487365194485 , D22: 0.8130774506772178
Epoch: 12 , D11*: 0.8675955573698058, D22*: 0.8279645151792346, D12*: 1.1122450632432395
Epoch: 12 , Coefficient 1: 1.0240151681239953 , Coefficient 2: 1.0183095281877725 , Coefficient 3: 0.7622241395277088
Epoch: 13 , Train Loss: 0.0028411758416041267
Epoch: 13 , Test Loss: 0.0028526134131243454
Epoch: 13 , D11: 0.8420613269206902 , D22: 0.8041340285769217
Epoch: 13 , D11*: 0.8031787244446859, D22*: 0.7986421830177164, D12*: 1.1121215381257876
Epoch: 13 , Coefficient 1: 0.9538245003862212 , Coefficient 2: 0.9931704848146716 , Coefficient 3: 0.7201645020569805
Epoch: 14 , Train Loss: 0.0028389594139298425
Epoch: 14 , Test Loss: 0.002862734884256497
Epoch: 14 , D11: 0.8517148175639879 , D22: 0.8331501769260025
Epoch: 14 , D11*: 0.8691705314881282, D22*: 0.8365593692094869, D12*: 1.1092132073063223
Epoch: 14 , Coefficient 1: 1.0204947871801335 , Coefficient 2: 1.0040919300960398 , Coefficient 3: 0.7688918097359787
Epoch: 15 , Train Loss: 0.0028458387598220723
Epoch: 15 , Test Loss: 0.0028580507903825493
Epoch: 15 , D11: 0.8376039320168637 , D22: 0.8264706937884069
Epoch: 15 , D11*: 0.8590844618569073, D22*: 0.7900119056234682, D12*: 1.0928869754011856
Epoch: 15 , Coefficient 1: 1.0256452113212038 , Coefficient 2: 0.9558861694202156 , Coefficient 3: 0.7544679388621189
Epoch: 16 , Train Loss: 0.0028383649437455456
Epoch: 16 , Test Loss: 0.002852496717823669
Epoch: 16 , D11: 0.8310272508920175 , D22: 0.8203744425129377
Epoch: 16 , D11*: 0.840424809071719, D22*: 0.773457860299639, D12*: 1.1089876821378604
Epoch: 16 , Coefficient 1: 1.0113083634376783 , Coefficient 2: 0.9428107705676622 , Coefficient 3: 0.7276377796461103
Epoch: 17 , Train Loss: 0.0028344192172517066
Epoch: 17 , Test Loss: 0.0028590774786425755
Epoch: 17 , D11: 0.8324562447872111 , D22: 0.8241996391273795
Epoch: 17 , D11*: 0.8499029629162166, D22*: 0.8152094634498964, D12*: 1.0917258419198579
Epoch: 17 , Coefficient 1: 1.0209581203075304 , Coefficient 2: 0.9890922353630227 , Coefficient 3: 0.7626055747832827
Epoch: 18 , Train Loss: 0.0028415930405026302
Epoch: 18 , Test Loss: 0.0028643251879839223
Epoch: 18 , D11: 0.8392337381323739 , D22: 0.8004854967328289
Epoch: 18 , D11*: 0.8296668021281627, D22*: 0.862118251728765, D12*: 1.1245109748328552
Epoch: 18 , Coefficient 1: 0.9886003915601613 , Coefficient 2: 1.0769942181931957 , Coefficient 3: 0.7522314551480437
Epoch: 19 , Train Loss: 0.002836192600079812
Epoch: 19 , Test Loss: 0.002845916763180867
Epoch: 19 , D11: 0.8416887335689753 , D22: 0.8216298380158064
Epoch: 19 , D11*: 0.8340754488049229, D22*: 0.821571660499961, D12*: 1.0916172989560369
Epoch: 19 , Coefficient 1: 0.9909547503008979 , Coefficient 2: 0.999929192547357 , Coefficient 3: 0.758345947287687
Epoch: 20 , Train Loss: 0.002839777168846922
Epoch: 20 , Test Loss: 0.0028708157187793404
Epoch: 20 , D11: 0.8120527571119271 , D22: 0.8257328273632717
Epoch: 20 , D11*: 0.8100989125976995, D22*: 0.8487791342110321, D12*: 1.1020997598330842
Epoch: 20 , Coefficient 1: 0.9975939438698829 , Coefficient 2: 1.0279101255079708 , Coefficient 3: 0.7525988604969721
Epoch: 21 , Train Loss: 0.002840012361994013
Epoch: 21 , Test Loss: 0.0028885271830949933
Epoch: 21 , D11: 0.8305122877146425 , D22: 0.8454609344786479
Epoch: 21 , D11*: 0.8606226006571961, D22*: 0.8409695145146687, D12*: 1.1030750273741987
Epoch: 21 , Coefficient 1: 1.0362551083084026 , Coefficient 2: 0.9946876079298107 , Coefficient 3: 0.7712948226297891
Epoch: 22 , Train Loss: 0.002836747650144389
Epoch: 22 , Test Loss: 0.002846499943989329
Epoch: 22 , D11: 0.8485422944155027 , D22: 0.8051391977582423
Epoch: 22 , D11*: 0.8519129651492012, D22*: 0.8060757532274805, D12*: 1.1013158632403726
Epoch: 22 , Coefficient 1: 1.0039723072802405 , Coefficient 2: 1.0011632218029451 , Coefficient 3: 0.7527307894659873
Epoch: 23 , Train Loss: 0.0028307424014201383
Epoch: 23 , Test Loss: 0.00286561364249792
Epoch: 23 , D11: 0.8421371499207342 , D22: 0.8149441801676576
Epoch: 23 , D11*: 0.847836706145969, D22*: 0.8430328661443753, D12*: 1.125411173200162
Epoch: 23 , Coefficient 1: 1.0067679667448126 , Coefficient 2: 1.0344670060358478 , Coefficient 3: 0.7512230252176516
Epoch: 24 , Train Loss: 0.0028403580073791093
Epoch: 24 , Test Loss: 0.0028634292678907515
Epoch: 24 , D11: 0.8290149878422822 , D22: 0.8236371386661893
Epoch: 24 , D11*: 0.8447918493235811, D22*: 0.8564437823363037, D12*: 1.134404287281607
Epoch: 24 , Coefficient 1: 1.0190308519299054 , Coefficient 2: 1.0398314283438481 , Coefficient 3: 0.7498365665280523
Epoch: 25 , Train Loss: 0.0028393975229118952
Epoch: 25 , Test Loss: 0.002870441421400755
Epoch: 25 , D11: 0.8228878832796778 , D22: 0.8193340152464632
Epoch: 25 , D11*: 0.8181934298352925, D22*: 0.81256432984292, D12*: 1.1221652838998015
Epoch: 25 , Coefficient 1: 0.9942951481729502 , Coefficient 2: 0.9917375755460284 , Coefficient 3: 0.7266121056654535
Epoch: 26 , Train Loss: 0.0028372656917781567
Epoch: 26 , Test Loss: 0.0028719053167151286
Epoch: 26 , D11: 0.8146628875924791 , D22: 0.8340035205944981
Epoch: 26 , D11*: 0.7882075924049761, D22*: 0.875541306823554, D12*: 1.1227166838113525
Epoch: 26 , Coefficient 1: 0.9675260827632831 , Coefficient 2: 1.0498052888307314 , Coefficient 3: 0.7409477935165726
Epoch: 27 , Train Loss: 0.0028403408206941093
Epoch: 27 , Test Loss: 0.002868946128874086
Epoch: 27 , D11: 0.8269448486887071 , D22: 0.8288438693258126
Epoch: 27 , D11*: 0.8337799962431655, D22*: 0.8240848944574917, D12*: 1.101251105464401
Epoch: 27 , Coefficient 1: 1.0082655422127569 , Coefficient 2: 0.9942582975582701 , Coefficient 3: 0.7527188315518333
Epoch: 28 , Train Loss: 0.002838413728168234
Epoch: 28 , Test Loss: 0.0028465153987053786
Epoch: 28 , D11: 0.8460421621336265 , D22: 0.8162653378226657
Epoch: 28 , D11*: 0.8580937518674403, D22*: 0.7969263908751417, D12*: 1.1240581496659727
Epoch: 28 , Coefficient 1: 1.0142446680238972 , Coefficient 2: 0.9763080140103592 , Coefficient 3: 0.7361808387023354
Epoch: 29 , Train Loss: 0.002842385925760027
Epoch: 29 , Test Loss: 0.0028644561918918046
Epoch: 29 , D11: 0.8256161945032651 , D22: 0.7984405939279652
Epoch: 29 , D11*: 0.8420856337557453, D22*: 0.8197442529022588, D12*: 1.1004883621412846
Epoch: 29 , Coefficient 1: 1.0199480574171502 , Coefficient 2: 1.0266815829960365 , Coefficient 3: 0.7550420085426821
Epoch: 30 , Train Loss: 0.0028438563378585966
Epoch: 30 , Test Loss: 0.002868047743104398
Epoch: 30 , D11: 0.8367639754119672 , D22: 0.8093245722965516
Epoch: 30 , D11*: 0.8505530000810021, D22*: 0.8023677618881401, D12*: 1.1001591074808432
Epoch: 30 , Coefficient 1: 1.0164789893855626 , Coefficient 2: 0.9914041774504995 , Coefficient 3: 0.7512189603892926
Epoch: 31 , Train Loss: 0.002840511077811243
Epoch: 31 , Test Loss: 0.0028675135562662036
Epoch: 31 , D11: 0.8503859812305025 , D22: 0.8290330591502327
Epoch: 31 , D11*: 0.856991555733348, D22*: 0.8273890119133995, D12*: 1.1327385821824139
Epoch: 31 , Coefficient 1: 1.0077677368261495 , Coefficient 2: 0.9980169099185039 , Coefficient 3: 0.7434992478147523
Epoch: 32 , Train Loss: 0.00284179119989858
Epoch: 32 , Test Loss: 0.0028631862433394417
Epoch: 32 , D11: 0.8526318443078053 , D22: 0.8481425277983659
Epoch: 32 , D11*: 0.847344063161399, D22*: 0.8304207651180237, D12*: 1.1022003007751497
Epoch: 32 , Coefficient 1: 0.9937982833016293 , Coefficient 2: 0.9791052068496732 , Coefficient 3: 0.7610979724372661
Epoch: 33 , Train Loss: 0.002839288071700139
Epoch: 33 , Test Loss: 0.0028630132629768926
Epoch: 33 , D11: 0.8388942799497848 , D22: 0.8303027467553165
Epoch: 33 , D11*: 0.8442615792587221, D22*: 0.8230460583512402, D12*: 1.1005004373069602
Epoch: 33 , Coefficient 1: 1.0063980640197696 , Coefficient 2: 0.9912601898133733 , Coefficient 3: 0.7575224784508212
Epoch: 34 , Train Loss: 0.002841918706108118
Epoch: 34 , Test Loss: 0.0028635392419528215
Epoch: 34 , D11: 0.8294623175065052 , D22: 0.814951163931682
Epoch: 34 , D11*: 0.8315776980907743, D22*: 0.7937839782079753, D12*: 1.1379174391765692
Epoch: 34 , Coefficient 1: 1.0025503034190006 , Coefficient 2: 0.9740264366007076 , Coefficient 3: 0.7141826025071334
Epoch: 35 , Train Loss: 0.002837191989819985
Epoch: 35 , Test Loss: 0.0028597130533307797
Epoch: 35 , D11: 0.8402425621089512 , D22: 0.8053267644182455
Epoch: 35 , D11*: 0.8237515227106281, D22*: 0.7975009642001127, D12*: 1.1234440707995013
Epoch: 35 , Coefficient 1: 0.9803734776813356 , Coefficient 2: 0.990282453577976 , Coefficient 3: 0.7215546056320246
Epoch: 36 , Train Loss: 0.002850934523739852
Epoch: 36 , Test Loss: 0.002861217769095674
Epoch: 36 , D11: 0.8319364274422257 , D22: 0.8386654695393962
Epoch: 36 , D11*: 0.8285568951780191, D22*: 0.8677106559970846, D12*: 1.1040162612680313
Epoch: 36 , Coefficient 1: 0.9959377517888032 , Coefficient 2: 1.03463262470272 , Coefficient 3: 0.7682258000560767
Epoch: 37 , Train Loss: 0.00283844558551209
Epoch: 37 , Test Loss: 0.0028650239395210516
Epoch: 37 , D11: 0.8423729068851721 , D22: 0.8314173928356337
Epoch: 37 , D11*: 0.8529144541937419, D22*: 0.822299511486882, D12*: 1.1110740658329246
Epoch: 37 , Coefficient 1: 1.0125141101077777 , Coefficient 2: 0.9890333285936511 , Coefficient 3: 0.7538714191950776
Epoch: 38 , Train Loss: 0.0028498730370483823
Epoch: 38 , Test Loss: 0.002867676524328999
Epoch: 38 , D11: 0.8454549316303037 , D22: 0.8031525726017904
Epoch: 38 , D11*: 0.865554343479906, D22*: 0.7740817419038002, D12*: 1.1072935668507546
Epoch: 38 , Coefficient 1: 1.0237734870276813 , Coefficient 2: 0.9638040993832392 , Coefficient 3: 0.7403800285984605
Epoch: 39 , Train Loss: 0.002838880911731394
Epoch: 39 , Test Loss: 0.002852384942234494
Epoch: 39 , D11: 0.8338824705584222 , D22: 0.8167421345427265
Epoch: 39 , D11*: 0.8273650984765194, D22*: 0.8112001637497479, D12*: 1.1322631973875348
Epoch: 39 , Coefficient 1: 0.9921843037694048 , Coefficient 2: 0.9932145403566311 , Coefficient 3: 0.723579670348255
