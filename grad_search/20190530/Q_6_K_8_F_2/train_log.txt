Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.0034104666787607126
Epoch: 0 , Test Loss: 0.003041429475997575
Epoch: 0 , D11: 0.8341516086962659 , D22: 0.8120476366456071
Epoch: 0 , D11*: 0.8311701437258103, D22*: 0.813530487222133, D12*: 1.1124302782712319
Epoch: 0 , Coefficient 1: 0.9964257516986444 , Coefficient 2: 1.0018260635332321 , Coefficient 3: 0.7392376237294997
Epoch: 1 , Train Loss: 0.002838440662599169
Epoch: 1 , Test Loss: 0.002862754930974915
Epoch: 1 , D11: 0.8456293726098739 , D22: 0.7972177142838647
Epoch: 1 , D11*: 0.8022198276653454, D22*: 0.809145479970794, D12*: 1.1005885009966223
Epoch: 1 , Coefficient 1: 0.9486659920402797 , Coefficient 2: 1.0149617419096664 , Coefficient 3: 0.7320471303202742
Epoch: 2 , Train Loss: 0.002843913820543093
Epoch: 2 , Test Loss: 0.002873048168839887
Epoch: 2 , D11: 0.8418615212134793 , D22: 0.8132502556155677
Epoch: 2 , D11*: 0.8268641173376768, D22*: 0.8409147536275028, D12*: 1.0903004478644946
Epoch: 2 , Coefficient 1: 0.982185426583953 , Coefficient 2: 1.0340172017419105 , Coefficient 3: 0.7648253626932636
Epoch: 3 , Train Loss: 0.0028340947424294427
Epoch: 3 , Test Loss: 0.002877790546626783
Epoch: 3 , D11: 0.8342940769701302 , D22: 0.8151238682129571
Epoch: 3 , D11*: 0.8237074068120509, D22*: 0.8138815619480266, D12*: 1.1186317557831202
Epoch: 3 , Coefficient 1: 0.9873106252935098 , Coefficient 2: 0.9984759294711194 , Coefficient 3: 0.7319607012289987
Epoch: 4 , Train Loss: 0.002847345882473746
Epoch: 4 , Test Loss: 0.0028533211856847625
Epoch: 4 , D11: 0.8566925190297547 , D22: 0.8173772678059028
Epoch: 4 , D11*: 0.8769398140585773, D22*: 0.7985720347738333, D12*: 1.1108963706890513
Epoch: 4 , Coefficient 1: 1.0236342615104819 , Coefficient 2: 0.9769932028051763 , Coefficient 3: 0.7541260791918636
Epoch: 5 , Train Loss: 0.0028362883630325087
Epoch: 5 , Test Loss: 0.002873950952780433
Epoch: 5 , D11: 0.8319675749829537 , D22: 0.8034695823205275
Epoch: 5 , D11*: 0.7896294942027491, D22*: 0.8426769675413649, D12*: 1.1314836029029323
Epoch: 5 , Coefficient 1: 0.949110900408502 , Coefficient 2: 1.048797597424412 , Coefficient 3: 0.7213124686722244
Epoch: 6 , Train Loss: 0.0028347056951315607
Epoch: 6 , Test Loss: 0.0028748206555610526
Epoch: 6 , D11: 0.8189667747700251 , D22: 0.8146048410244918
Epoch: 6 , D11*: 0.8027121496008174, D22*: 0.7819024825529444, D12*: 1.106470507324544
Epoch: 6 , Coefficient 1: 0.9801522776381592 , Coefficient 2: 0.9598549421454221 , Coefficient 3: 0.7160672705074511
Epoch: 7 , Train Loss: 0.0028304441882937683
Epoch: 7 , Test Loss: 0.0028660985827445988
Epoch: 7 , D11: 0.8419863736353321 , D22: 0.8129789451115325
Epoch: 7 , D11*: 0.8571842817813539, D22*: 0.8332070175057247, D12*: 1.1097091599731654
Epoch: 7 , Coefficient 1: 1.0180500642550827 , Coefficient 2: 1.0248814222260296 , Coefficient 3: 0.7616370848592234
Epoch: 8 , Train Loss: 0.0028396699826407717
Epoch: 8 , Test Loss: 0.002862562433001585
Epoch: 8 , D11: 0.8414757275315682 , D22: 0.8555245720458525
Epoch: 8 , D11*: 0.8502048481666962, D22*: 0.8475181557638007, D12*: 1.1147861666078682
Epoch: 8 , Coefficient 1: 1.0103735857726217 , Coefficient 2: 0.9906415121860197 , Coefficient 3: 0.7614567953854418
Epoch: 9 , Train Loss: 0.0028387573853251523
Epoch: 9 , Test Loss: 0.0028788199578411882
Epoch: 9 , D11: 0.8354930027898954 , D22: 0.8017523582214895
Epoch: 9 , D11*: 0.8373539936467048, D22*: 0.7573730022675101, D12*: 1.130899509843333
Epoch: 9 , Coefficient 1: 1.002227416448247 , Coefficient 2: 0.9446470527976679 , Coefficient 3: 0.7050701596533265
Epoch: 10 , Train Loss: 0.002841789843951119
Epoch: 10 , Test Loss: 0.002861060299910605
Epoch: 10 , D11: 0.8397596057746057 , D22: 0.8303440678552644
Epoch: 10 , D11*: 0.8201042744560328, D22*: 0.8250896520033421, D12*: 1.106337345026695
Epoch: 10 , Coefficient 1: 0.9765940976638874 , Coefficient 2: 0.9936720016974478 , Coefficient 3: 0.7435317689739913
Epoch: 11 , Train Loss: 0.0028399992152117193
Epoch: 11 , Test Loss: 0.00287160474807024
Epoch: 11 , D11: 0.8469974270465092 , D22: 0.8082167047651897
Epoch: 11 , D11*: 0.8660108559063637, D22*: 0.8114437151180449, D12*: 1.1423829092670341
Epoch: 11 , Coefficient 1: 1.022448036148297 , Coefficient 2: 1.0039927538416726 , Coefficient 3: 0.7341910306154189
Epoch: 12 , Train Loss: 0.002846402739960467
Epoch: 12 , Test Loss: 0.0028734335303306578
Epoch: 12 , D11: 0.8480741300265442 , D22: 0.8155107391652711
Epoch: 12 , D11*: 0.8328347323125206, D22*: 0.8027472223369512, D12*: 1.105097938789931
Epoch: 12 , Coefficient 1: 0.9820305829709172 , Coefficient 2: 0.9843490511953477 , Coefficient 3: 0.7400167429686886
Epoch: 13 , Train Loss: 0.0028366813994944095
Epoch: 13 , Test Loss: 0.002866155485971831
Epoch: 13 , D11: 0.8198102396763615 , D22: 0.8056108108793562
Epoch: 13 , D11*: 0.8312179499524912, D22*: 0.8220376511757126, D12*: 1.1195011990756731
Epoch: 13 , Coefficient 1: 1.0139150619546216 , Coefficient 2: 1.0203905410336114 , Coefficient 3: 0.7383893838136262
Epoch: 14 , Train Loss: 0.002849405620945618
Epoch: 14 , Test Loss: 0.0028650024073431264
Epoch: 14 , D11: 0.8205398250428033 , D22: 0.8234027690061626
Epoch: 14 , D11*: 0.8053453637215456, D22*: 0.8572622614550273, D12*: 1.111750240737773
Epoch: 14 , Coefficient 1: 0.9814823597130522 , Coefficient 2: 1.0411214216460951 , Coefficient 3: 0.7477433169131779
Epoch: 15 , Train Loss: 0.0028465282381512223
Epoch: 15 , Test Loss: 0.002860834138118662
Epoch: 15 , D11: 0.8316436960929252 , D22: 0.8068744515029622
Epoch: 15 , D11*: 0.7943450698986464, D22*: 0.8257204173271433, D12*: 1.0844247951496115
Epoch: 15 , Coefficient 1: 0.9551507137377361 , Coefficient 2: 1.0233567512133726 , Coefficient 3: 0.7469699579316051
Epoch: 16 , Train Loss: 0.0028510745918902103
Epoch: 16 , Test Loss: 0.002858381086261943
Epoch: 16 , D11: 0.8269253717898658 , D22: 0.8223989791184656
Epoch: 16 , D11*: 0.8504636395376995, D22*: 0.814175023947817, D12*: 1.0778801734763521
Epoch: 16 , Coefficient 1: 1.0284648029324406 , Coefficient 2: 0.9900000420970076 , Coefficient 3: 0.7721816879313986
Epoch: 17 , Train Loss: 0.002833657539158594
Epoch: 17 , Test Loss: 0.002872370593249798
Epoch: 17 , D11: 0.8560861062050862 , D22: 0.8353453780959706
Epoch: 17 , D11*: 0.8633607772623285, D22*: 0.7907283956201998, D12*: 1.0997279967644062
Epoch: 17 , Coefficient 1: 1.0084975927123616 , Coefficient 2: 0.9465885804294892 , Coefficient 3: 0.7520446772970909
Epoch: 18 , Train Loss: 0.002834939679451054
Epoch: 18 , Test Loss: 0.002861410399782471
Epoch: 18 , D11: 0.8517353203342453 , D22: 0.7881089525628276
Epoch: 18 , D11*: 0.84527497300847, D22*: 0.7951046419072832, D12*: 1.1161788927060479
Epoch: 18 , Coefficient 1: 0.9924150764074924 , Coefficient 2: 1.008876551042475 , Coefficient 3: 0.7348193132996991
Epoch: 19 , Train Loss: 0.0028414800425525756
Epoch: 19 , Test Loss: 0.0028691199736203994
Epoch: 19 , D11: 0.8300886667052313 , D22: 0.8184536637733089
Epoch: 19 , D11*: 0.8079529906695287, D22*: 0.7899510025975807, D12*: 1.0975046233015706
Epoch: 19 , Coefficient 1: 0.9733333595270455 , Coefficient 2: 0.9651749849291129 , Coefficient 3: 0.7279714177696179
Epoch: 20 , Train Loss: 0.0028482285284553654
Epoch: 20 , Test Loss: 0.002872208245098591
Epoch: 20 , D11: 0.8343169228399155 , D22: 0.8287748555616957
Epoch: 20 , D11*: 0.8512235796557727, D22*: 0.8510543467037979, D12*: 1.1308786782475762
Epoch: 20 , Coefficient 1: 1.020264070346684 , Coefficient 2: 1.0268824409821198 , Coefficient 3: 0.752635078856311
Epoch: 21 , Train Loss: 0.0028449335787445306
Epoch: 21 , Test Loss: 0.0028425898303976282
Epoch: 21 , D11: 0.8449511337558568 , D22: 0.8305007985925621
Epoch: 21 , D11*: 0.8465867222531942, D22*: 0.8404864781612996, D12*: 1.0946847535661108
Epoch: 21 , Coefficient 1: 1.0019357196315803 , Coefficient 2: 1.0120236844873118 , Coefficient 3: 0.7705749052037962
Epoch: 22 , Train Loss: 0.0028406110673677176
Epoch: 22 , Test Loss: 0.002878375715226866
Epoch: 22 , D11: 0.8405377671207307 , D22: 0.8222127703937491
Epoch: 22 , D11*: 0.8385391806818865, D22*: 0.8817253517107719, D12*: 1.1027620555870998
Epoch: 22 , Coefficient 1: 0.9976222526613047 , Coefficient 2: 1.0723809985200339 , Coefficient 3: 0.7799799257133517
Epoch: 23 , Train Loss: 0.0028442496397474313
Epoch: 23 , Test Loss: 0.0028592686651973055
Epoch: 23 , D11: 0.8441787797368813 , D22: 0.8344139658150023
Epoch: 23 , D11*: 0.852306696422683, D22*: 0.8161337811826179, D12*: 1.1212667717329678
Epoch: 23 , Coefficient 1: 1.0096281935543736 , Coefficient 2: 0.9780921875935652 , Coefficient 3: 0.7439980028243643
Epoch: 24 , Train Loss: 0.0028390067259897477
Epoch: 24 , Test Loss: 0.002850539263454266
Epoch: 24 , D11: 0.8511470362642674 , D22: 0.8449766297602053
Epoch: 24 , D11*: 0.8188213129764883, D22*: 0.8388402505428462, D12*: 1.1238415224617844
Epoch: 24 , Coefficient 1: 0.9620209882540877 , Coefficient 2: 0.9927378119095429 , Coefficient 3: 0.7374979169163516
Epoch: 25 , Train Loss: 0.0028306617905036547
Epoch: 25 , Test Loss: 0.0028700591123197233
Epoch: 25 , D11: 0.8201889745695251 , D22: 0.8354367526058739
Epoch: 25 , D11*: 0.7676684566476949, D22*: 0.8337927241116838, D12*: 1.1206597166408347
Epoch: 25 , Coefficient 1: 0.9359653451213539 , Coefficient 2: 0.9980321329064563 , Coefficient 3: 0.7145171531460687
Epoch: 26 , Train Loss: 0.002846472467062995
Epoch: 26 , Test Loss: 0.0028586806257953875
Epoch: 26 , D11: 0.8494553229151685 , D22: 0.8141062261574585
Epoch: 26 , D11*: 0.8555159932555522, D22*: 0.8050904512990124, D12*: 1.1323711412683353
Epoch: 26 , Coefficient 1: 1.0071347723380961 , Coefficient 2: 0.9889255547141554 , Coefficient 3: 0.7332430084250331
Epoch: 27 , Train Loss: 0.0028419024292088576
Epoch: 27 , Test Loss: 0.0028543994191568343
Epoch: 27 , D11: 0.8446856323172575 , D22: 0.8093785787039631
Epoch: 27 , D11*: 0.864390943851466, D22*: 0.7993910445446816, D12*: 1.1288942988272477
Epoch: 27 , Coefficient 1: 1.0233285743006546 , Coefficient 2: 0.9876602440167439 , Coefficient 3: 0.7369077822983818
Epoch: 28 , Train Loss: 0.0028349977622565354
Epoch: 28 , Test Loss: 0.00286724747158587
Epoch: 28 , D11: 0.8379798823376347 , D22: 0.819038612747243
Epoch: 28 , D11*: 0.8536683884647308, D22*: 0.8240331969114902, D12*: 1.1231124882070824
Epoch: 28 , Coefficient 1: 1.0187218171435468 , Coefficient 2: 1.0060981058603504 , Coefficient 3: 0.7468982862324304
Epoch: 29 , Train Loss: 0.0028462443624448497
Epoch: 29 , Test Loss: 0.0028730243066092957
Epoch: 29 , D11: 0.8314129456340502 , D22: 0.8255649837993928
Epoch: 29 , D11*: 0.8295202294051577, D22*: 0.8200463462427918, D12*: 1.0927484660265812
Epoch: 29 , Coefficient 1: 0.9977234943973008 , Coefficient 2: 0.9933153202171884 , Coefficient 3: 0.7547787194092587
Epoch: 30 , Train Loss: 0.002839872439071769
Epoch: 30 , Test Loss: 0.002864136747666635
Epoch: 30 , D11: 0.8320619093008291 , D22: 0.820395186461168
Epoch: 30 , D11*: 0.8561746950377923, D22*: 0.8015619163422402, D12*: 1.1120573927971273
Epoch: 30 , Coefficient 1: 1.028979557251004 , Coefficient 2: 0.9770436608725528 , Coefficient 3: 0.7453466979839832
Epoch: 31 , Train Loss: 0.0028353633749065923
Epoch: 31 , Test Loss: 0.0028617284097708765
Epoch: 31 , D11: 0.8375222948350276 , D22: 0.8397036525630948
Epoch: 31 , D11*: 0.833777211651062, D22*: 0.8167116636475805, D12*: 1.1137382553283424
Epoch: 31 , Coefficient 1: 0.9955283779225205 , Coefficient 2: 0.9726189247297735 , Coefficient 3: 0.7409680270038225
Epoch: 32 , Train Loss: 0.0028415984271850906
Epoch: 32 , Test Loss: 0.0028669360809726644
Epoch: 32 , D11: 0.8367029459460652 , D22: 0.8224663181323045
Epoch: 32 , D11*: 0.8502984986864647, D22*: 0.8523641025741235, D12*: 1.125479976831836
Epoch: 32 , Coefficient 1: 1.016248960047615 , Coefficient 2: 1.0363513785095932 , Coefficient 3: 0.7564162118874337
Epoch: 33 , Train Loss: 0.0028358267819567117
Epoch: 33 , Test Loss: 0.0028624870796920736
Epoch: 33 , D11: 0.8394919467909356 , D22: 0.8526131470627148
Epoch: 33 , D11*: 0.8267036855442272, D22*: 0.8826698370050311, D12*: 1.0780316857733776
Epoch: 33 , Coefficient 1: 0.9847666659631541 , Coefficient 2: 1.0352524354636832 , Coefficient 3: 0.7928215585439669
Epoch: 34 , Train Loss: 0.0028426213582861235
Epoch: 34 , Test Loss: 0.002877627903362736
Epoch: 34 , D11: 0.8117844868224784 , D22: 0.836584415554792
Epoch: 34 , D11*: 0.791897494142532, D22*: 0.8075589033381442, D12*: 1.1052908493963531
Epoch: 34 , Coefficient 1: 0.9755021277164473 , Coefficient 2: 0.9653047419041398 , Coefficient 3: 0.7235454805195429
Epoch: 35 , Train Loss: 0.002843100850586779
Epoch: 35 , Test Loss: 0.0028684962377883492
Epoch: 35 , D11: 0.8320867628395476 , D22: 0.8145915038357021
Epoch: 35 , D11*: 0.8700285180398567, D22*: 0.8026579669522536, D12*: 1.1271143020784342
Epoch: 35 , Coefficient 1: 1.0455983160588092 , Coefficient 2: 0.9853502806900678 , Coefficient 3: 0.7420216751342893
Epoch: 36 , Train Loss: 0.0028317539433191995
Epoch: 36 , Test Loss: 0.00287608630314935
Epoch: 36 , D11: 0.8217253779336685 , D22: 0.8243338639659007
Epoch: 36 , D11*: 0.8041296483735713, D22*: 0.7959351469449303, D12*: 1.1316237042577015
Epoch: 36 , Coefficient 1: 0.9785868490464005 , Coefficient 2: 0.9655494960690525 , Coefficient 3: 0.7069774118809564
Epoch: 37 , Train Loss: 0.002846863298182143
Epoch: 37 , Test Loss: 0.002852734292391688
Epoch: 37 , D11: 0.8231849917775087 , D22: 0.8356665591610171
Epoch: 37 , D11*: 0.8284347059578473, D22*: 0.8556605033863319, D12*: 1.1046173085021789
Epoch: 37 , Coefficient 1: 1.0063773200833057 , Coefficient 2: 1.023925744073555 , Coefficient 3: 0.7622980358816537
Epoch: 38 , Train Loss: 0.0028410070066456684
Epoch: 38 , Test Loss: 0.0028656348481308673
Epoch: 38 , D11: 0.846938867382616 , D22: 0.8357401083910772
Epoch: 38 , D11*: 0.8159055383015332, D22*: 0.8359529324255787, D12*: 1.1186818953227446
Epoch: 38 , Coefficient 1: 0.9633582419272027 , Coefficient 2: 1.0002546533693486 , Coefficient 3: 0.7383057139092
Epoch: 39 , Train Loss: 0.0028378560021519667
Epoch: 39 , Test Loss: 0.0028815576387569305
Epoch: 39 , D11: 0.8241669610842127 , D22: 0.7959615006776025
Epoch: 39 , D11*: 0.8356779343391998, D22*: 0.7917218150144444, D12*: 1.0969221518676417
Epoch: 39 , Coefficient 1: 1.013966797746714 , Coefficient 2: 0.9946735041084915 , Coefficient 3: 0.7418027553654561
