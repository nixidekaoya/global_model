Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.003286184982134728
Epoch: 0 , Test Loss: 0.002986498547252268
Epoch: 0 , D11: 0.8368512145689103 , D22: 0.8229042250036891
Epoch: 0 , D11*: 0.855230855485398, D22*: 0.8227684089173605, D12*: 1.101239623633805
Epoch: 0 , Coefficient 1: 1.0219628538460754 , Coefficient 2: 0.9998349551719363 , Coefficient 3: 0.7618683656086568
Epoch: 1 , Train Loss: 0.0028437899018172175
Epoch: 1 , Test Loss: 0.00286154656088911
Epoch: 1 , D11: 0.8399317212733697 , D22: 0.7966469934958776
Epoch: 1 , D11*: 0.8434967310363883, D22*: 0.8222467463441365, D12*: 1.123801067586605
Epoch: 1 , Coefficient 1: 1.0042444042446854 , Coefficient 2: 1.0321343745187828 , Coefficient 3: 0.7411202593701733
Epoch: 2 , Train Loss: 0.0028439893103495706
Epoch: 2 , Test Loss: 0.002868292378261685
Epoch: 2 , D11: 0.8429817040918414 , D22: 0.8416886238606505
Epoch: 2 , D11*: 0.8611405146065118, D22*: 0.8417185197067087, D12*: 1.1273213726785858
Epoch: 2 , Coefficient 1: 1.021541168007001 , Coefficient 2: 1.0000355188904908 , Coefficient 3: 0.7552677859141095
Epoch: 3 , Train Loss: 0.0028339439563569617
Epoch: 3 , Test Loss: 0.0028609389916528015
Epoch: 3 , D11: 0.8218077192604104 , D22: 0.8130347507647498
Epoch: 3 , D11*: 0.7982927079394971, D22*: 0.8023799659553722, D12*: 1.144578302540501
Epoch: 3 , Coefficient 1: 0.9713862369873141 , Coefficient 2: 0.9868950437858214 , Coefficient 3: 0.6992412272458876
Epoch: 4 , Train Loss: 0.0028396915880148296
Epoch: 4 , Test Loss: 0.002869321748730727
Epoch: 4 , D11: 0.8294981837546797 , D22: 0.8697297528382213
Epoch: 4 , D11*: 0.8582356058435374, D22*: 0.8444406626488309, D12*: 1.1295694540073145
Epoch: 4 , Coefficient 1: 1.0346443460054118 , Coefficient 2: 0.9709230480998683 , Coefficient 3: 0.7536837431518145
Epoch: 5 , Train Loss: 0.0028387101078988053
Epoch: 5 , Test Loss: 0.002856175366905518
Epoch: 5 , D11: 0.8321517995037774 , D22: 0.8391188213114568
Epoch: 5 , D11*: 0.8159480391815729, D22*: 0.8565147944919029, D12*: 1.1188683221642017
Epoch: 5 , Coefficient 1: 0.9805278792500756 , Coefficient 2: 1.0207312394128618 , Coefficient 3: 0.7473903767507104
Epoch: 6 , Train Loss: 0.0028331982539384626
Epoch: 6 , Test Loss: 0.0028691915108356625
Epoch: 6 , D11: 0.8331259953122402 , D22: 0.8417468578982875
Epoch: 6 , D11*: 0.8445126018330581, D22*: 0.818895979878356, D12*: 1.1075592752464491
Epoch: 6 , Coefficient 1: 1.0136673283331539 , Coefficient 2: 0.9728530284306773 , Coefficient 3: 0.7509343377316215
Epoch: 7 , Train Loss: 0.002832331266545225
Epoch: 7 , Test Loss: 0.002852301095263101
Epoch: 7 , D11: 0.8434420634110483 , D22: 0.8309665876438482
Epoch: 7 , D11*: 0.8661718472432463, D22*: 0.8159191514043935, D12*: 1.1140783162307293
Epoch: 7 , Coefficient 1: 1.0269488383591805 , Coefficient 2: 0.9818916470731744 , Coefficient 3: 0.7549249339753208
Epoch: 8 , Train Loss: 0.0028420491583528926
Epoch: 8 , Test Loss: 0.002855055119725876
Epoch: 8 , D11: 0.8245743952241754 , D22: 0.8282391948320951
Epoch: 8 , D11*: 0.7981475068339141, D22*: 0.831779662742663, D12*: 1.0812178646711483
Epoch: 8 , Coefficient 1: 0.9679508743621894 , Coefficient 2: 1.0042746925437231 , Coefficient 3: 0.753745948358113
Epoch: 9 , Train Loss: 0.002848324966616929
Epoch: 9 , Test Loss: 0.002853653639322147
Epoch: 9 , D11: 0.8358166704421289 , D22: 0.8233743930487777
Epoch: 9 , D11*: 0.8293595002442107, D22*: 0.8015055624797144, D12*: 1.105945080750509
Epoch: 9 , Coefficient 1: 0.9922744180317646 , Coefficient 2: 0.9734399918752783 , Coefficient 3: 0.7373173818076023
Epoch: 10 , Train Loss: 0.0028352458056178876
Epoch: 10 , Test Loss: 0.002859256137744523
Epoch: 10 , D11: 0.8486104288880718 , D22: 0.8248054234928147
Epoch: 10 , D11*: 0.8546005051909089, D22*: 0.8288311939599856, D12*: 1.1231147709298364
Epoch: 10 , Coefficient 1: 1.0070586880610057 , Coefficient 2: 1.004880872933792 , Coefficient 3: 0.7494477602485662
Epoch: 11 , Train Loss: 0.002839802546950523
Epoch: 11 , Test Loss: 0.002863432227750309
Epoch: 11 , D11: 0.8553800134374371 , D22: 0.834685456082378
Epoch: 11 , D11*: 0.8710447256891916, D22*: 0.8728958967469439, D12*: 1.1269544512723295
Epoch: 11 , Coefficient 1: 1.0183131614085816 , Coefficient 2: 1.0457782514192926 , Coefficient 3: 0.7737405094177628
Epoch: 12 , Train Loss: 0.0028379362235136795
Epoch: 12 , Test Loss: 0.0028657307062530894
Epoch: 12 , D11: 0.8383544520312198 , D22: 0.8309782884728627
Epoch: 12 , D11*: 0.8783531351975469, D22*: 0.8721100546168633, D12*: 1.1183266014513036
Epoch: 12 , Coefficient 1: 1.047710945017845 , Coefficient 2: 1.0494980033949994 , Coefficient 3: 0.7826261074102834
Epoch: 13 , Train Loss: 0.0028380314902460664
Epoch: 13 , Test Loss: 0.0028721273492556066
Epoch: 13 , D11: 0.8410753723598572 , D22: 0.8359279477501836
Epoch: 13 , D11*: 0.8283076147269455, D22*: 0.8355818564441864, D12*: 1.1212199838702797
Epoch: 13 , Coefficient 1: 0.9848197224024187 , Coefficient 2: 0.9995859795010698 , Coefficient 3: 0.7419995607943234
Epoch: 14 , Train Loss: 0.002840538874006598
Epoch: 14 , Test Loss: 0.0028634594986215235
Epoch: 14 , D11: 0.8378449076520122 , D22: 0.8335098076934986
Epoch: 14 , D11*: 0.8687486536652184, D22*: 0.8169590077163739, D12*: 1.1283018454564118
Epoch: 14 , Coefficient 1: 1.036884804969229 , Coefficient 2: 0.9801432450771943 , Coefficient 3: 0.7470109475446719
Epoch: 15 , Train Loss: 0.002843659295322141
Epoch: 15 , Test Loss: 0.00286300920881331
Epoch: 15 , D11: 0.8463631975366771 , D22: 0.8075584812084677
Epoch: 15 , D11*: 0.8180951205045061, D22*: 0.8285662833683455, D12*: 1.1527092463482416
Epoch: 15 , Coefficient 1: 0.9666005361357338 , Coefficient 2: 1.0260139700699331 , Coefficient 3: 0.7142570466444335
Epoch: 16 , Train Loss: 0.002844659857219085
Epoch: 16 , Test Loss: 0.0028607956325868147
Epoch: 16 , D11: 0.8255062517475714 , D22: 0.8287641382990365
Epoch: 16 , D11*: 0.8225209152122233, D22*: 0.8234645218768647, D12*: 1.1106484664547793
Epoch: 16 , Coefficient 1: 0.9963836294043463 , Coefficient 2: 0.9936053984755556 , Coefficient 3: 0.7410019852380111
Epoch: 17 , Train Loss: 0.0028475095026078636
Epoch: 17 , Test Loss: 0.002854559289989993
Epoch: 17 , D11: 0.8266413202090575 , D22: 0.7948951280790643
Epoch: 17 , D11*: 0.8678378981664471, D22*: 0.7932065158605696, D12*: 1.1157178091229778
Epoch: 17 , Coefficient 1: 1.0498360981362158 , Coefficient 2: 0.9978756792451661 , Coefficient 3: 0.7443837502839086
Epoch: 18 , Train Loss: 0.002837416466063587
Epoch: 18 , Test Loss: 0.0028591211955063048
Epoch: 18 , D11: 0.8421661701495565 , D22: 0.798077603897313
Epoch: 18 , D11*: 0.8642658595783346, D22*: 0.8490381452905268, D12*: 1.1175987020130707
Epoch: 18 , Coefficient 1: 1.0262414832275362 , Coefficient 2: 1.0638541178756982 , Coefficient 3: 0.7665112717931662
Epoch: 19 , Train Loss: 0.0028395386348711326
Epoch: 19 , Test Loss: 0.002865872801630758
Epoch: 19 , D11: 0.828816988293864 , D22: 0.8130907099394289
Epoch: 19 , D11*: 0.8143270340778382, D22*: 0.8048504343112144, D12*: 1.0962052782335971
Epoch: 19 , Coefficient 1: 0.9825173054839844 , Coefficient 2: 0.9898654903721279 , Coefficient 3: 0.738537526018011
Epoch: 20 , Train Loss: 0.002841727319464553
Epoch: 20 , Test Loss: 0.0028749942692229526
Epoch: 20 , D11: 0.831072577232153 , D22: 0.8074259889264279
Epoch: 20 , D11*: 0.8290168221089245, D22*: 0.7935754696351041, D12*: 1.1230682014542572
Epoch: 20 , Coefficient 1: 0.9975263831588871 , Coefficient 2: 0.9828460818932273 , Coefficient 3: 0.7223925891779943
Epoch: 21 , Train Loss: 0.0028461025175056426
Epoch: 21 , Test Loss: 0.00286483827396296
Epoch: 21 , D11: 0.8292988372668428 , D22: 0.8273820163711589
Epoch: 21 , D11*: 0.8442612220441499, D22*: 0.8430631249880314, D12*: 1.1313340219930106
Epoch: 21 , Coefficient 1: 1.0180422112089524 , Coefficient 2: 1.0189526824448623 , Coefficient 3: 0.7457233293752239
Epoch: 22 , Train Loss: 0.002849403529398842
Epoch: 22 , Test Loss: 0.0028812681732233608
Epoch: 22 , D11: 0.8407432865768235 , D22: 0.8292941696836393
Epoch: 22 , D11*: 0.84662638038101, D22*: 0.8384813773238349, D12*: 1.1183744799361526
Epoch: 22 , Coefficient 1: 1.0069974912653066 , Coefficient 2: 1.0110783458705617 , Coefficient 3: 0.7533736632657457
Epoch: 23 , Train Loss: 0.0028447292622877287
Epoch: 23 , Test Loss: 0.0028640590078430257
Epoch: 23 , D11: 0.8498600027969346 , D22: 0.8352636760388783
Epoch: 23 , D11*: 0.8517309303196785, D22*: 0.8450574913154242, D12*: 1.0956394454115097
Epoch: 23 , Coefficient 1: 1.0022014537883728 , Coefficient 2: 1.0117254174430184 , Coefficient 3: 0.7743370452484066
Epoch: 24 , Train Loss: 0.002840811725036474
Epoch: 24 , Test Loss: 0.002866164157167077
Epoch: 24 , D11: 0.8440425485494968 , D22: 0.8229885686274833
Epoch: 24 , D11*: 0.864957275878131, D22*: 0.8119963230749568, D12*: 1.1177456322791426
Epoch: 24 , Coefficient 1: 1.0247792334220314 , Coefficient 2: 0.9866435015362869 , Coefficient 3: 0.7501499225426139
Epoch: 25 , Train Loss: 0.0028406904923031105
Epoch: 25 , Test Loss: 0.00288122478465084
Epoch: 25 , D11: 0.8322061044834494 , D22: 0.825221442262965
Epoch: 25 , D11*: 0.8552114443841174, D22*: 0.7936364908447899, D12*: 1.156849335535347
Epoch: 25 , Coefficient 1: 1.0276438009487414 , Coefficient 2: 0.9617254838512664 , Coefficient 3: 0.7126459274257532
Epoch: 26 , Train Loss: 0.0028393181978026405
Epoch: 26 , Test Loss: 0.0028664748999290167
Epoch: 26 , D11: 0.8341444495040687 , D22: 0.8427206333479323
Epoch: 26 , D11*: 0.8429476101296173, D22*: 0.8310224387928579, D12*: 1.1563266461093316
Epoch: 26 , Coefficient 1: 1.0105535205932046 , Coefficient 2: 0.9861185378734584 , Coefficient 3: 0.7238309583865631
Epoch: 27 , Train Loss: 0.002841874946752796
Epoch: 27 , Test Loss: 0.002858349962043576
Epoch: 27 , D11: 0.8446790707043922 , D22: 0.8008054404555541
Epoch: 27 , D11*: 0.8601578109852832, D22*: 0.791734112098321, D12*: 1.1215878065427234
Epoch: 27 , Coefficient 1: 1.0183249956317528 , Coefficient 2: 0.9886722443443032 , Coefficient 3: 0.7364077575769724
Epoch: 28 , Train Loss: 0.002837487061333377
Epoch: 28 , Test Loss: 0.002874081488116644
Epoch: 28 , D11: 0.8325883036163411 , D22: 0.8204857985796099
Epoch: 28 , D11*: 0.8281048069875969, D22*: 0.8120815978849263, D12*: 1.1420961203363837
Epoch: 28 , Coefficient 1: 0.9946149896542263 , Coefficient 2: 0.9897570430722474 , Coefficient 3: 0.7180597042871646
Epoch: 29 , Train Loss: 0.00284066750886268
Epoch: 29 , Test Loss: 0.002875292699900455
Epoch: 29 , D11: 0.8390084785494146 , D22: 0.8334654406851272
Epoch: 29 , D11*: 0.8401421373198197, D22*: 0.8166119331317202, D12*: 1.1017125695331227
Epoch: 29 , Coefficient 1: 1.0013511886940225 , Coefficient 2: 0.9797789965477717 , Coefficient 3: 0.751899413816087
Epoch: 30 , Train Loss: 0.0028361380801652557
Epoch: 30 , Test Loss: 0.002861842814018018
Epoch: 30 , D11: 0.8598046452065863 , D22: 0.8185689938414831
Epoch: 30 , D11*: 0.8576999341682163, D22*: 0.8352639108329823, D12*: 1.0803263624922195
Epoch: 30 , Coefficient 1: 0.997552105527571 , Coefficient 2: 1.0203952472144728 , Coefficient 3: 0.7835427810424238
Epoch: 31 , Train Loss: 0.002838411382108461
Epoch: 31 , Test Loss: 0.0028735240723472086
Epoch: 31 , D11: 0.8323536142061395 , D22: 0.8280347366366587
Epoch: 31 , D11*: 0.8368724002591775, D22*: 0.8076292351506325, D12*: 1.0863031492517337
Epoch: 31 , Coefficient 1: 1.0054289258506408 , Coefficient 2: 0.975356708380484 , Coefficient 3: 0.7569257423871846
Epoch: 32 , Train Loss: 0.002841626074368833
Epoch: 32 , Test Loss: 0.0028660150844370944
Epoch: 32 , D11: 0.8386579649346794 , D22: 0.7997949918228922
Epoch: 32 , D11*: 0.8445769344257887, D22*: 0.7846285879022579, D12*: 1.1085684012987094
Epoch: 32 , Coefficient 1: 1.0070576680107848 , Coefficient 2: 0.9810371356713962 , Coefficient 3: 0.7348240850178486
Epoch: 33 , Train Loss: 0.0028372481153928677
Epoch: 33 , Test Loss: 0.0028532522602472458
Epoch: 33 , D11: 0.8290675510582851 , D22: 0.8301931333475656
Epoch: 33 , D11*: 0.8312100203410656, D22*: 0.8475618981278575, D12*: 1.1182916751353749
Epoch: 33 , Coefficient 1: 1.0025841914570721 , Coefficient 2: 1.0209213544205749 , Coefficient 3: 0.750596626888821
Epoch: 34 , Train Loss: 0.0028376095622661525
Epoch: 34 , Test Loss: 0.0028669649019138887
Epoch: 34 , D11: 0.8538722131821193 , D22: 0.8425285703487393
Epoch: 34 , D11*: 0.8483713306962727, D22*: 0.8295142051643059, D12*: 1.1033086772294687
Epoch: 34 , Coefficient 1: 0.9935577216345447 , Coefficient 2: 0.9845532060959706 , Coefficient 3: 0.7603880810916562
Epoch: 35 , Train Loss: 0.002842347062105546
Epoch: 35 , Test Loss: 0.0028764560318086303
Epoch: 35 , D11: 0.8378474947808289 , D22: 0.8150889654577645
Epoch: 35 , D11*: 0.8293484853469736, D22*: 0.8236082890445722, D12*: 1.076523378141062
Epoch: 35 , Coefficient 1: 0.9898561379167475 , Coefficient 2: 1.0104520168323259 , Coefficient 3: 0.7677291584906719
Epoch: 36 , Train Loss: 0.002832117500947788
Epoch: 36 , Test Loss: 0.002864333276520483
Epoch: 36 , D11: 0.8310575063905113 , D22: 0.8124301277644022
Epoch: 36 , D11*: 0.8523125327997518, D22*: 0.7968235992810655, D12*: 1.1374294847202693
Epoch: 36 , Coefficient 1: 1.0255758792211098 , Coefficient 2: 0.9807903129758595 , Coefficient 3: 0.7249399431941019
Epoch: 37 , Train Loss: 0.0028360277636966203
Epoch: 37 , Test Loss: 0.0028687091433675952
Epoch: 37 , D11: 0.8526848989870278 , D22: 0.8295589280081191
Epoch: 37 , D11*: 0.8617047733354819, D22*: 0.8533481523457163, D12*: 1.092453023258454
Epoch: 37 , Coefficient 1: 1.0105782034596478 , Coefficient 2: 1.0286769553486914 , Coefficient 3: 0.7849549999714032
Epoch: 38 , Train Loss: 0.0028317808829888234
Epoch: 38 , Test Loss: 0.002861977193970233
Epoch: 38 , D11: 0.8485604682268797 , D22: 0.8283441003099659
Epoch: 38 , D11*: 0.8292197630526218, D22*: 0.8210732510364394, D12*: 1.0821292701453467
Epoch: 38 , Coefficient 1: 0.9772076288037888 , Coefficient 2: 0.9912224288543786 , Coefficient 3: 0.7625211976141266
Epoch: 39 , Train Loss: 0.002836512001958909
Epoch: 39 , Test Loss: 0.0028551222768146544
Epoch: 39 , D11: 0.8352366559469827 , D22: 0.8413108296153712
Epoch: 39 , D11*: 0.8306033850210418, D22*: 0.8750202797911463, D12*: 1.1310288608582002
Epoch: 39 , Coefficient 1: 0.9944527447485075 , Coefficient 2: 1.0400677716120525 , Coefficient 3: 0.7540142094685355
