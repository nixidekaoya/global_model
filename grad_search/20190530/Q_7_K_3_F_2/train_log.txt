Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.0032581174821825695
Epoch: 0 , Test Loss: 0.0030144087149528787
Epoch: 0 , D11: 0.8562071437984794 , D22: 0.8325158798911527
Epoch: 0 , D11*: 0.8468978689607838, D22*: 0.8549793067210271, D12*: 1.08973894378049
Epoch: 0 , Coefficient 1: 0.9891273100147285 , Coefficient 2: 1.0269825805999175 , Coefficient 3: 0.7808646214742537
Epoch: 1 , Train Loss: 0.002838181578699732
Epoch: 1 , Test Loss: 0.0028656217252137134
Epoch: 1 , D11: 0.8560098407692569 , D22: 0.8151659405808978
Epoch: 1 , D11*: 0.8602119063396679, D22*: 0.8195233511481137, D12*: 1.1138580147989454
Epoch: 1 , Coefficient 1: 1.0049088986718129 , Coefficient 2: 1.005345427661159 , Coefficient 3: 0.7540167755541889
Epoch: 2 , Train Loss: 0.0028360962682927493
Epoch: 2 , Test Loss: 0.002855089530348778
Epoch: 2 , D11: 0.8424144684257658 , D22: 0.831959968006916
Epoch: 2 , D11*: 0.8432640381965447, D22*: 0.8323149696009876, D12*: 1.1209872156188683
Epoch: 2 , Coefficient 1: 1.0010084938027792 , Coefficient 2: 1.0004267051393376 , Coefficient 3: 0.7473675812049686
Epoch: 3 , Train Loss: 0.0028395232716866303
Epoch: 3 , Test Loss: 0.0028666448668809605
Epoch: 3 , D11: 0.8488830178448886 , D22: 0.8328128399315193
Epoch: 3 , D11*: 0.8317909067574206, D22*: 0.8698621872633844, D12*: 1.0973378202239636
Epoch: 3 , Coefficient 1: 0.9798651749084806 , Coefficient 2: 1.0444870030280893 , Coefficient 3: 0.7753551653188725
Epoch: 4 , Train Loss: 0.0028405628431937653
Epoch: 4 , Test Loss: 0.002857922238181345
Epoch: 4 , D11: 0.8527939135003916 , D22: 0.8331274232543362
Epoch: 4 , D11*: 0.8283425322130605, D22*: 0.8050186946371748, D12*: 1.1070746313647348
Epoch: 4 , Coefficient 1: 0.9713279129925219 , Coefficient 2: 0.9662611890659367 , Coefficient 3: 0.7376924647061627
Epoch: 5 , Train Loss: 0.0028336068216594868
Epoch: 5 , Test Loss: 0.0028753585397498687
Epoch: 5 , D11: 0.845529653225208 , D22: 0.8254787590808508
Epoch: 5 , D11*: 0.861363333033711, D22*: 0.825802977820629, D12*: 1.126520688176923
Epoch: 5 , Coefficient 1: 1.018726344780584 , Coefficient 2: 1.0003927644851083 , Coefficient 3: 0.7488394703095618
Epoch: 6 , Train Loss: 0.0028397910561761817
Epoch: 6 , Test Loss: 0.002874179545324296
Epoch: 6 , D11: 0.8490551112083332 , D22: 0.8327001734259738
Epoch: 6 , D11*: 0.8840111032316182, D22*: 0.8224983412106471, D12*: 1.0997892618045897
Epoch: 6 , Coefficient 1: 1.0411704629791785 , Coefficient 2: 0.9877484927457703 , Coefficient 3: 0.7758347456685195
Epoch: 7 , Train Loss: 0.0028375460622191897
Epoch: 7 , Test Loss: 0.0028642950335051867
Epoch: 7 , D11: 0.8419279616958847 , D22: 0.8189823853842538
Epoch: 7 , D11*: 0.8593347383186953, D22*: 0.8450914233219214, D12*: 1.1009336962428173
Epoch: 7 , Coefficient 1: 1.020674900246511 , Coefficient 2: 1.0318798528559532 , Coefficient 3: 0.7740821120551367
Epoch: 8 , Train Loss: 0.0028389548780978656
Epoch: 8 , Test Loss: 0.002866452887537889
Epoch: 8 , D11: 0.8485956763929958 , D22: 0.8160860082368927
Epoch: 8 , D11*: 0.8604542522877023, D22*: 0.8156753232491458, D12*: 1.0803186783428942
Epoch: 8 , Coefficient 1: 1.0139743534224828 , Coefficient 2: 0.9994967626161927 , Coefficient 3: 0.7757570100092461
Epoch: 9 , Train Loss: 0.002839777850313112
Epoch: 9 , Test Loss: 0.002872664757305756
Epoch: 9 , D11: 0.8305171455492235 , D22: 0.8273090430551892
Epoch: 9 , D11*: 0.8456485581402441, D22*: 0.827436410405802, D12*: 1.1200431140802232
Epoch: 9 , Coefficient 1: 1.0182192657576192 , Coefficient 2: 1.0001539537754143 , Coefficient 3: 0.7468841812933155
Epoch: 10 , Train Loss: 0.002838730025687255
Epoch: 10 , Test Loss: 0.002882862190017477
Epoch: 10 , D11: 0.8384711568732279 , D22: 0.8177702141268409
Epoch: 10 , D11*: 0.8180531771196502, D22*: 0.8221256454124356, D12*: 1.1474487809361338
Epoch: 10 , Coefficient 1: 0.9756485603753872 , Coefficient 2: 1.0053259842561582 , Coefficient 3: 0.7147067693923398
Epoch: 11 , Train Loss: 0.002836128284980077
Epoch: 11 , Test Loss: 0.0028643334523076195
Epoch: 11 , D11: 0.8410657401440885 , D22: 0.8308025488838603
Epoch: 11 , D11*: 0.8347379405074753, D22*: 0.8527601558308671, D12*: 1.0697179084113304
Epoch: 11 , Coefficient 1: 0.9924764506095217 , Coefficient 2: 1.026429392852135 , Coefficient 3: 0.7887584582203058
Epoch: 12 , Train Loss: 0.0028354592103278266
Epoch: 12 , Test Loss: 0.0028576299623819072
Epoch: 12 , D11: 0.8319938139078845 , D22: 0.8252955022137285
Epoch: 12 , D11*: 0.8244135017907382, D22*: 0.8164770154689894, D12*: 1.1020725562407214
Epoch: 12 , Coefficient 1: 0.9908889801938052 , Coefficient 2: 0.9893147524479597 , Coefficient 3: 0.7444566639318956
Epoch: 13 , Train Loss: 0.0028432115464238445
Epoch: 13 , Test Loss: 0.0028539449529489504
Epoch: 13 , D11: 0.8294183480741687 , D22: 0.8214174200160972
Epoch: 13 , D11*: 0.8400525562491488, D22*: 0.8021096442670338, D12*: 1.1079429334733364
Epoch: 13 , Coefficient 1: 1.0128212839752964 , Coefficient 2: 0.9764945625956106 , Coefficient 3: 0.7410860933821294
Epoch: 14 , Train Loss: 0.002843248824792681
Epoch: 14 , Test Loss: 0.0028663102886639534
Epoch: 14 , D11: 0.8298062941893537 , D22: 0.8218561622278635
Epoch: 14 , D11*: 0.8389517243542962, D22*: 0.8538993649836393, D12*: 1.1278503102583355
Epoch: 14 , Coefficient 1: 1.0110211626845718 , Coefficient 2: 1.0389888209500238 , Coefficient 3: 0.7504768469453121
Epoch: 15 , Train Loss: 0.0028426955424947662
Epoch: 15 , Test Loss: 0.0028673777054063977
Epoch: 15 , D11: 0.8415471719072354 , D22: 0.8209266916291191
Epoch: 15 , D11*: 0.8613721180565688, D22*: 0.7874859245577616, D12*: 1.1097208891662207
Epoch: 15 , Coefficient 1: 1.0235577360499035 , Coefficient 2: 0.9592646122822553 , Coefficient 3: 0.7429156550586273
Epoch: 16 , Train Loss: 0.0028413384589657652
Epoch: 16 , Test Loss: 0.002857013535685837
Epoch: 16 , D11: 0.8401569218265993 , D22: 0.8170455351768877
Epoch: 16 , D11*: 0.8233556840617475, D22*: 0.7932660175210953, D12*: 1.1093784324972966
Epoch: 16 , Coefficient 1: 0.9800022622817606 , Coefficient 2: 0.9708957253518994 , Coefficient 3: 0.728615977301678
Epoch: 17 , Train Loss: 0.002840826983592706
Epoch: 17 , Test Loss: 0.0028610991820460186
Epoch: 17 , D11: 0.8468636951169308 , D22: 0.8233913174497247
Epoch: 17 , D11*: 0.8538263845485425, D22*: 0.8174884402045879, D12*: 1.085388812226568
Epoch: 17 , Coefficient 1: 1.0082217356485572 , Coefficient 2: 0.9928310183505217 , Coefficient 3: 0.7699152625889855
Epoch: 18 , Train Loss: 0.002843202694493812
Epoch: 18 , Test Loss: 0.0028558191325282673
Epoch: 18 , D11: 0.8206129869977833 , D22: 0.825189021471697
Epoch: 18 , D11*: 0.8318182310982359, D22*: 0.8483720695934996, D12*: 1.1504099555965934
Epoch: 18 , Coefficient 1: 1.0136547243073097 , Coefficient 2: 1.0280942275267506 , Coefficient 3: 0.7302571976702003
Epoch: 19 , Train Loss: 0.0028418939223047346
Epoch: 19 , Test Loss: 0.002864493898814544
Epoch: 19 , D11: 0.8419965334492918 , D22: 0.8308106070019392
Epoch: 19 , D11*: 0.8449375174085743, D22*: 0.8679466399284584, D12*: 1.120673182439843
Epoch: 19 , Coefficient 1: 1.0034928694388259 , Coefficient 2: 1.044698554175335 , Coefficient 3: 0.7642210879035553
Epoch: 20 , Train Loss: 0.002844692197832046
Epoch: 20 , Test Loss: 0.0028536879713647067
Epoch: 20 , D11: 0.8610488500750069 , D22: 0.805880080138495
Epoch: 20 , D11*: 0.8647081089224139, D22*: 0.7665440677975767, D12*: 1.1175799476375265
Epoch: 20 , Coefficient 1: 1.0042497691589602 , Coefficient 2: 0.951188752135233 , Coefficient 3: 0.7298145337021864
Epoch: 21 , Train Loss: 0.0028386300514102914
Epoch: 21 , Test Loss: 0.002850164537667296
Epoch: 21 , D11: 0.8288582393329953 , D22: 0.8334998475319527
Epoch: 21 , D11*: 0.8107180201116554, D22*: 0.8318991389337976, D12*: 1.1191461600056916
Epoch: 21 , Coefficient 1: 0.9781142077613443 , Coefficient 2: 0.9980795334241573 , Coefficient 3: 0.7338707032855741
Epoch: 22 , Train Loss: 0.0028407494752900673
Epoch: 22 , Test Loss: 0.002865434642881155
Epoch: 22 , D11: 0.8230949456332947 , D22: 0.8301885851519336
Epoch: 22 , D11*: 0.8095045203411828, D22*: 0.8562734815685996, D12*: 1.10761334069605
Epoch: 22 , Coefficient 1: 0.9834886298789561 , Coefficient 2: 1.0314204469721686 , Coefficient 3: 0.7519672889019957
Epoch: 23 , Train Loss: 0.002841484238306293
Epoch: 23 , Test Loss: 0.0028629252430982886
Epoch: 23 , D11: 0.8519710315477378 , D22: 0.8239189888456907
Epoch: 23 , D11*: 0.8249403994856023, D22*: 0.8456183236062713, D12*: 1.1129602040588003
Epoch: 23 , Coefficient 1: 0.9682728272896437 , Coefficient 2: 1.0263367334098967 , Coefficient 3: 0.7505024514801134
Epoch: 24 , Train Loss: 0.0028341494123742448
Epoch: 24 , Test Loss: 0.0028588152752490716
Epoch: 24 , D11: 0.8585389565628186 , D22: 0.847556252919005
Epoch: 24 , D11*: 0.8961803847830971, D22*: 0.8542023025291665, D12*: 1.0994777109629452
Epoch: 24 , Coefficient 1: 1.0438435879147254 , Coefficient 2: 1.0078414259670343 , Coefficient 3: 0.7960064446323529
Epoch: 25 , Train Loss: 0.0028389049769612026
Epoch: 25 , Test Loss: 0.002867278211051598
Epoch: 25 , D11: 0.8486549742759916 , D22: 0.8245394736736716
Epoch: 25 , D11*: 0.8636334688978625, D22*: 0.8214793560363799, D12*: 1.1041595031619293
Epoch: 25 , Coefficient 1: 1.017649686946865 , Coefficient 2: 0.996288694798737 , Coefficient 3: 0.7630749090637107
Epoch: 26 , Train Loss: 0.0028331789419462432
Epoch: 26 , Test Loss: 0.0028584030404454103
Epoch: 26 , D11: 0.8427565395267338 , D22: 0.8481058255329471
Epoch: 26 , D11*: 0.842062712853176, D22*: 0.861121814210445, D12*: 1.1169941684592828
Epoch: 26 , Coefficient 1: 0.9991767175441351 , Coefficient 2: 1.0153471280182738 , Coefficient 3: 0.762396337938315
Epoch: 27 , Train Loss: 0.0028388447311590423
Epoch: 27 , Test Loss: 0.002871348202461376
Epoch: 27 , D11: 0.8275720415525412 , D22: 0.8227554319442344
Epoch: 27 , D11*: 0.8268644885559456, D22*: 0.8340785566977961, D12*: 1.1025553836486366
Epoch: 27 , Coefficient 1: 0.9991450254949791 , Coefficient 2: 1.0137624430224719 , Coefficient 3: 0.7532243141189235
Epoch: 28 , Train Loss: 0.002838776786957169
Epoch: 28 , Test Loss: 0.002872895141481422
Epoch: 28 , D11: 0.840054219193849 , D22: 0.8212524657326433
Epoch: 28 , D11*: 0.8268450545487945, D22*: 0.7865670059340701, D12*: 1.130097489521506
Epoch: 28 , Coefficient 1: 0.9842758189373413 , Coefficient 2: 0.9577651681476169 , Coefficient 3: 0.7138375562474698
Epoch: 29 , Train Loss: 0.0028442182501021303
Epoch: 29 , Test Loss: 0.0028601587947923697
Epoch: 29 , D11: 0.8250809042194286 , D22: 0.7882601568754768
Epoch: 29 , D11*: 0.8243767430649401, D22*: 0.7693355018067548, D12*: 1.093588564531162
Epoch: 29 , Coefficient 1: 0.9991465550215896 , Coefficient 2: 0.9759918665130356 , Coefficient 3: 0.7286617182006395
Epoch: 30 , Train Loss: 0.0028388307824207004
Epoch: 30 , Test Loss: 0.0028423699853010473
Epoch: 30 , D11: 0.8260685947744669 , D22: 0.8204915876661897
Epoch: 30 , D11*: 0.8382229126048173, D22*: 0.8184888596756219, D12*: 1.1246142698340698
Epoch: 30 , Coefficient 1: 1.0147134486254967 , Coefficient 2: 0.9975591120973412 , Coefficient 3: 0.7365688915386417
Epoch: 31 , Train Loss: 0.002836152481177123
Epoch: 31 , Test Loss: 0.002859194855554961
Epoch: 31 , D11: 0.8257770128606575 , D22: 0.8106074260237798
Epoch: 31 , D11*: 0.8470141749014245, D22*: 0.8105785302542213, D12*: 1.0949420015288007
Epoch: 31 , Coefficient 1: 1.025717792709193 , Coefficient 2: 0.9999643529424592 , Coefficient 3: 0.7569317383209568
Epoch: 32 , Train Loss: 0.002838098206266295
Epoch: 32 , Test Loss: 0.00287182294356171
Epoch: 32 , D11: 0.8380837921346626 , D22: 0.8220897296795184
Epoch: 32 , D11*: 0.8662013940570668, D22*: 0.8250794739879936, D12*: 1.0895525730782833
Epoch: 32 , Coefficient 1: 1.0335498695790148 , Coefficient 2: 1.0036367615365305 , Coefficient 3: 0.7761355026984749
Epoch: 33 , Train Loss: 0.002840738404629519
Epoch: 33 , Test Loss: 0.002861563462065533
Epoch: 33 , D11: 0.8383327525325239 , D22: 0.8047034044735596
Epoch: 33 , D11*: 0.8339990512422716, D22*: 0.8514685224885119, D12*: 1.1222670368786973
Epoch: 33 , Coefficient 1: 0.9948305714202855 , Coefficient 2: 1.0581147261897645 , Coefficient 3: 0.7509209120221896
Epoch: 34 , Train Loss: 0.0028525664035987577
Epoch: 34 , Test Loss: 0.002868804839090444
Epoch: 34 , D11: 0.8315648783081142 , D22: 0.8293005301912504
Epoch: 34 , D11*: 0.8381335016384732, D22*: 0.8343568062108943, D12*: 1.1156873600173702
Epoch: 34 , Coefficient 1: 1.007899111063617 , Coefficient 2: 1.0060970370035551 , Coefficient 3: 0.7495335914818146
Epoch: 35 , Train Loss: 0.0028362343976914423
Epoch: 35 , Test Loss: 0.0028604910481953992
Epoch: 35 , D11: 0.8421069293645526 , D22: 0.8139653647803083
Epoch: 35 , D11*: 0.8541165788863663, D22*: 0.8338002369420189, D12*: 1.1148745041315042
Epoch: 35 , Coefficient 1: 1.0142614305891962 , Coefficient 2: 1.0243682016704285 , Coefficient 3: 0.7569985722936975
Epoch: 36 , Train Loss: 0.0028395259950775653
Epoch: 36 , Test Loss: 0.002858968112268485
Epoch: 36 , D11: 0.8160172661939743 , D22: 0.8507970461112507
Epoch: 36 , D11*: 0.7914959868742473, D22*: 0.9118466294016082, D12*: 1.1318964214248852
Epoch: 36 , Coefficient 1: 0.9699500484418695 , Coefficient 2: 1.071755753701071 , Coefficient 3: 0.7524286604473961
Epoch: 37 , Train Loss: 0.002843794439395424
Epoch: 37 , Test Loss: 0.0028774770256131885
Epoch: 37 , D11: 0.8361575931355375 , D22: 0.8340021732911218
Epoch: 37 , D11*: 0.8402816180016156, D22*: 0.8261862093356377, D12*: 1.112775941955596
Epoch: 37 , Coefficient 1: 1.004932114352527 , Coefficient 2: 0.9906283650021667 , Coefficient 3: 0.7487885766152517
Epoch: 38 , Train Loss: 0.002839781005459372
Epoch: 38 , Test Loss: 0.0028705285827163606
Epoch: 38 , D11: 0.8339076155759061 , D22: 0.8178249508562031
Epoch: 38 , D11*: 0.8160042532374537, D22*: 0.8095853999014441, D12*: 1.101615172464196
Epoch: 38 , Coefficient 1: 0.9785307604774803 , Coefficient 2: 0.9899250433162587 , Coefficient 3: 0.7378210167088687
Epoch: 39 , Train Loss: 0.0028477307215507607
Epoch: 39 , Test Loss: 0.002871784621966072
Epoch: 39 , D11: 0.8467302269237094 , D22: 0.8127596187858351
Epoch: 39 , D11*: 0.8400201554317873, D22*: 0.8175201122320228, D12*: 1.1180635181277758
Epoch: 39 , Coefficient 1: 0.9920753136258041 , Coefficient 2: 1.0058571973018287 , Coefficient 3: 0.7412549648518186
