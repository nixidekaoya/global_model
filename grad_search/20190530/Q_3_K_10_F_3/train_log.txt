Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.003241990431706654
Epoch: 0 , Test Loss: 0.002962286544498056
Epoch: 0 , D11: 0.852053825818606 , D22: 0.8122887438044146
Epoch: 0 , D11*: 0.8658654327304727, D22*: 0.8093234544127251, D12*: 1.133955704959661
Epoch: 0 , Coefficient 1: 1.016209782167925 , Coefficient 2: 0.9963494638891568 , Coefficient 3: 0.7386482910294943
Epoch: 1 , Train Loss: 0.0028460704917961264
Epoch: 1 , Test Loss: 0.0028610195906367156
Epoch: 1 , D11: 0.8385229247565594 , D22: 0.8266294065540177
Epoch: 1 , D11*: 0.8323552974941432, D22*: 0.7957768315929638, D12*: 1.1149264176466263
Epoch: 1 , Coefficient 1: 0.9926446527813096 , Coefficient 2: 0.9626766544760734 , Coefficient 3: 0.7301522788040798
Epoch: 2 , Train Loss: 0.002843257431377424
Epoch: 2 , Test Loss: 0.002853340124129318
Epoch: 2 , D11: 0.8408132747349061 , D22: 0.8104743226086663
Epoch: 2 , D11*: 0.874341175834349, D22*: 0.8102225643921143, D12*: 1.1136946691728995
Epoch: 2 , Coefficient 1: 1.039875561086989 , Coefficient 2: 0.9996893692871828 , Coefficient 3: 0.7562951439273421
Epoch: 3 , Train Loss: 0.0028384655575791834
Epoch: 3 , Test Loss: 0.002864271406433545
Epoch: 3 , D11: 0.8400547648054978 , D22: 0.8026889205889015
Epoch: 3 , D11*: 0.8075100537526523, D22*: 0.7634348825659939, D12*: 1.13287276524771
Epoch: 3 , Coefficient 1: 0.9612588221431245 , Coefficient 2: 0.9510968234193286 , Coefficient 3: 0.6933457068213431
Epoch: 4 , Train Loss: 0.002839374332397711
Epoch: 4 , Test Loss: 0.002868864091578871
Epoch: 4 , D11: 0.8433171901693122 , D22: 0.8253986158236446
Epoch: 4 , D11*: 0.819912954283599, D22*: 0.8361523371287772, D12*: 1.1276442851417954
Epoch: 4 , Coefficient 1: 0.9722474103948785 , Coefficient 2: 1.0130285187047494 , Coefficient 3: 0.7343030569272715
Epoch: 5 , Train Loss: 0.0028434812693740245
Epoch: 5 , Test Loss: 0.002869190573692322
Epoch: 5 , D11: 0.8390764665283013 , D22: 0.815235157314536
Epoch: 5 , D11*: 0.8138154930444539, D22*: 0.8278942921529665, D12*: 1.1313044290966905
Epoch: 5 , Coefficient 1: 0.9698943129839342 , Coefficient 2: 1.0155282003294988 , Coefficient 3: 0.7255826738468053
Epoch: 6 , Train Loss: 0.002838148856681073
Epoch: 6 , Test Loss: 0.002874384978204035
Epoch: 6 , D11: 0.8472885450417638 , D22: 0.8154788376004843
Epoch: 6 , D11*: 0.8395903112660814, D22*: 0.7932637079611844, D12*: 1.099426125540822
Epoch: 6 , Coefficient 1: 0.9909142713887358 , Coefficient 2: 0.9727581776313569 , Coefficient 3: 0.7425937865648061
Epoch: 7 , Train Loss: 0.0028425318004156
Epoch: 7 , Test Loss: 0.0028789581154705954
Epoch: 7 , D11: 0.8571188772787013 , D22: 0.8015082233187781
Epoch: 7 , D11*: 0.8368621810971341, D22*: 0.8296735265277185, D12*: 1.1216138308308667
Epoch: 7 , Coefficient 1: 0.9763665266061098 , Coefficient 2: 1.0351403795862721 , Coefficient 3: 0.7429186685359969
Epoch: 8 , Train Loss: 0.0028324868057097775
Epoch: 8 , Test Loss: 0.0028679901355644693
Epoch: 8 , D11: 0.8247370349755807 , D22: 0.8205470858532992
Epoch: 8 , D11*: 0.8382553315093979, D22*: 0.7687723776914731, D12*: 1.131230488278607
Epoch: 8 , Coefficient 1: 1.0163910385499026 , Coefficient 2: 0.936902209447268 , Coefficient 3: 0.7103007414723609
Epoch: 9 , Train Loss: 0.002839493392384611
Epoch: 9 , Test Loss: 0.0028584250027779484
Epoch: 9 , D11: 0.8514164570487709 , D22: 0.8273189444005874
Epoch: 9 , D11*: 0.845773535476857, D22*: 0.8207657616953173, D12*: 1.0884592820514079
Epoch: 9 , Coefficient 1: 0.9933723132490606 , Coefficient 2: 0.9920790128769287 , Coefficient 3: 0.7655496740453465
Epoch: 10 , Train Loss: 0.002834582228533691
Epoch: 10 , Test Loss: 0.0028627935197437183
Epoch: 10 , D11: 0.8324122046483271 , D22: 0.8239980639429504
Epoch: 10 , D11*: 0.8519826880778624, D22*: 0.8600638359736875, D12*: 1.108185905250224
Epoch: 10 , Coefficient 1: 1.0235105676253309 , Coefficient 2: 1.043769243653507 , Coefficient 3: 0.7724545655834597
Epoch: 11 , Train Loss: 0.0028411338930891365
Epoch: 11 , Test Loss: 0.0028579226217698302
Epoch: 11 , D11: 0.8399373899441147 , D22: 0.8282222714508157
Epoch: 11 , D11*: 0.8254661869434532, D22*: 0.7980877038501075, D12*: 1.1004132883653002
Epoch: 11 , Coefficient 1: 0.9827710932101447 , Coefficient 2: 0.9636153619149593 , Coefficient 3: 0.7377018743591341
Epoch: 12 , Train Loss: 0.002839001346728765
Epoch: 12 , Test Loss: 0.0028625086572719735
Epoch: 12 , D11: 0.8305293737374804 , D22: 0.8082845847517073
Epoch: 12 , D11*: 0.8451544874839253, D22*: 0.8412779652170868, D12*: 1.0912747253055028
Epoch: 12 , Coefficient 1: 1.0176093877097088 , Coefficient 2: 1.0408190148467504 , Coefficient 3: 0.7726892292080231
Epoch: 13 , Train Loss: 0.0028451326325011905
Epoch: 13 , Test Loss: 0.0028744436654960736
Epoch: 13 , D11: 0.8424004435944118 , D22: 0.8126831511645364
Epoch: 13 , D11*: 0.8568358108640853, D22*: 0.7760477877292744, D12*: 1.0984255261628004
Epoch: 13 , Coefficient 1: 1.0171359920088359 , Coefficient 2: 0.9549204836069688 , Coefficient 3: 0.7432837091366657
Epoch: 14 , Train Loss: 0.0028328846342628826
Epoch: 14 , Test Loss: 0.0028625016065780074
Epoch: 14 , D11: 0.8603050421666741 , D22: 0.8294572428641193
Epoch: 14 , D11*: 0.8920476978303153, D22*: 0.8355432033530251, D12*: 1.0955435218952088
Epoch: 14 , Coefficient 1: 1.0368969773601437 , Coefficient 2: 1.007337280542504 , Coefficient 3: 0.7884629257789489
Epoch: 15 , Train Loss: 0.0028420337167335678
Epoch: 15 , Test Loss: 0.002862635441706516
Epoch: 15 , D11: 0.8557556324643691 , D22: 0.8237501813387339
Epoch: 15 , D11*: 0.8541615591789102, D22*: 0.7788956704818014, D12*: 1.1393469121064095
Epoch: 15 , Coefficient 1: 0.9981372330780127 , Coefficient 2: 0.9455484054837642 , Coefficient 3: 0.7166637361756382
Epoch: 16 , Train Loss: 0.0028418504052388016
Epoch: 16 , Test Loss: 0.0028671752940863373
Epoch: 16 , D11: 0.8236396650001894 , D22: 0.8291135389288098
Epoch: 16 , D11*: 0.8182005600577035, D22*: 0.8338005688071245, D12*: 1.1246933345786707
Epoch: 16 , Coefficient 1: 0.9933962566719214 , Coefficient 2: 1.0056530615630401 , Coefficient 3: 0.734422921375139
Epoch: 17 , Train Loss: 0.0028423082517110747
Epoch: 17 , Test Loss: 0.002860466980491765
Epoch: 17 , D11: 0.8268235934310587 , D22: 0.8059120091437418
Epoch: 17 , D11*: 0.8076766819275125, D22*: 0.7836229933777814, D12*: 1.1287760477354405
Epoch: 17 , Coefficient 1: 0.9768428094509344 , Coefficient 2: 0.9723431149888908 , Coefficient 3: 0.7048783850870028
Epoch: 18 , Train Loss: 0.0028344747200026174
Epoch: 18 , Test Loss: 0.0028715244680643085
Epoch: 18 , D11: 0.8416100540053881 , D22: 0.8382649802354117
Epoch: 18 , D11*: 0.8495298997401858, D22*: 0.8302622587656842, D12*: 1.1135204251243391
Epoch: 18 , Coefficient 1: 1.0094103506690606 , Coefficient 2: 0.9904532317842024 , Coefficient 3: 0.7542709233727344
Epoch: 19 , Train Loss: 0.002831918694864726
Epoch: 19 , Test Loss: 0.0028629793127765875
Epoch: 19 , D11: 0.8422594481755463 , D22: 0.8049153210794192
Epoch: 19 , D11*: 0.8747472536445956, D22*: 0.8045049746898391, D12*: 1.113975191850224
Epoch: 19 , Coefficient 1: 1.0385722066275689 , Coefficient 2: 0.9994901993056489 , Coefficient 3: 0.7537206576141657
Epoch: 20 , Train Loss: 0.0028363977583649095
Epoch: 20 , Test Loss: 0.0028696942690294236
Epoch: 20 , D11: 0.8367366781464879 , D22: 0.8335121984293551
Epoch: 20 , D11*: 0.8394269926926115, D22*: 0.8262946775493822, D12*: 1.1221217464578543
Epoch: 20 , Coefficient 1: 1.0032152463449828 , Coefficient 2: 0.9913408335312028 , Coefficient 3: 0.7422196724642821
Epoch: 21 , Train Loss: 0.0028430936412769366
Epoch: 21 , Test Loss: 0.0028731946146581316
Epoch: 21 , D11: 0.8424217818138733 , D22: 0.8262501712006861
Epoch: 21 , D11*: 0.8443354828291514, D22*: 0.8405478498693026, D12*: 1.081571955437558
Epoch: 21 , Coefficient 1: 1.0022716661138054 , Coefficient 2: 1.0173042973750184 , Coefficient 3: 0.7789048727769674
Epoch: 22 , Train Loss: 0.002836475521908141
Epoch: 22 , Test Loss: 0.002871261410764418
Epoch: 22 , D11: 0.8272286976928671 , D22: 0.8061614915554204
Epoch: 22 , D11*: 0.8060424619407611, D22*: 0.8066118928081298, D12*: 1.1265633537167217
Epoch: 22 , Coefficient 1: 0.9743889013870116 , Coefficient 2: 1.0005586985454247 , Coefficient 3: 0.715740641406661
Epoch: 23 , Train Loss: 0.0028322461173229388
Epoch: 23 , Test Loss: 0.0028627645311644304
Epoch: 23 , D11: 0.8512764872197738 , D22: 0.8255339514936801
Epoch: 23 , D11*: 0.8536784408106184, D22*: 0.8198398646507883, D12*: 1.126434826466926
Epoch: 23 , Coefficient 1: 1.0028215904314346 , Coefficient 2: 0.9931025406858321 , Coefficient 3: 0.7428384963515438
Epoch: 24 , Train Loss: 0.0028403664885263426
Epoch: 24 , Test Loss: 0.002871724751894362
Epoch: 24 , D11: 0.8349278824058329 , D22: 0.8248287752834005
Epoch: 24 , D11*: 0.8570681952347378, D22*: 0.8098589788078795, D12*: 1.1444761380838417
Epoch: 24 , Coefficient 1: 1.0265176349903513 , Coefficient 2: 0.9818510254199394 , Coefficient 3: 0.7282489859655343
Epoch: 25 , Train Loss: 0.002841859758045757
Epoch: 25 , Test Loss: 0.0028562359057832513
Epoch: 25 , D11: 0.8548339456305586 , D22: 0.8325845883145774
Epoch: 25 , D11*: 0.8379592993440085, D22*: 0.8750508086383904, D12*: 1.1070719122538928
Epoch: 25 , Coefficient 1: 0.9802597377270709 , Coefficient 2: 1.0510052923388582 , Coefficient 3: 0.7736670441285397
Epoch: 26 , Train Loss: 0.0028280784549133387
Epoch: 26 , Test Loss: 0.0028646883508190515
Epoch: 26 , D11: 0.8324287626417115 , D22: 0.8199516781852172
Epoch: 26 , D11*: 0.8584012111920337, D22*: 0.8100642084941643, D12*: 1.125366597629629
Epoch: 26 , Coefficient 1: 1.0312008062622664 , Coefficient 2: 0.9879413995310837 , Coefficient 3: 0.7412986235776429
Epoch: 27 , Train Loss: 0.0028426992469758263
Epoch: 27 , Test Loss: 0.0028686711291084064
Epoch: 27 , D11: 0.8195880434444996 , D22: 0.8220482582635092
Epoch: 27 , D11*: 0.8108417792921351, D22*: 0.8147846314300401, D12*: 1.1115783319083983
Epoch: 27 , Coefficient 1: 0.9893284629731707 , Coefficient 2: 0.9911639897530921 , Coefficient 3: 0.7312244059000504
Epoch: 28 , Train Loss: 0.002842898493690882
Epoch: 28 , Test Loss: 0.0028699374402640387
Epoch: 28 , D11: 0.8384940983680991 , D22: 0.8360550678160726
Epoch: 28 , D11*: 0.8773375413084304, D22*: 0.8861008635364256, D12*: 1.1186381699151704
Epoch: 28 , Coefficient 1: 1.0463252430946497 , Coefficient 2: 1.059859449032564 , Coefficient 3: 0.7882076851438847
Epoch: 29 , Train Loss: 0.0028433336947637144
Epoch: 29 , Test Loss: 0.0028462221403606235
Epoch: 29 , D11: 0.8329880355311612 , D22: 0.84789498547778
Epoch: 29 , D11*: 0.8623745728435808, D22*: 0.8436005670414312, D12*: 1.1293220240679287
Epoch: 29 , Coefficient 1: 1.0352784626656504 , Coefficient 2: 0.9949352001015445 , Coefficient 3: 0.7553094261546066
Epoch: 30 , Train Loss: 0.0028475168855220546
Epoch: 30 , Test Loss: 0.00285130912088789
Epoch: 30 , D11: 0.8339839330976563 , D22: 0.8241891649426253
Epoch: 30 , D11*: 0.8471745628174344, D22*: 0.8345438975124021, D12*: 1.0840867939939682
Epoch: 30 , Coefficient 1: 1.015816407482557 , Coefficient 2: 1.0125635388212093 , Coefficient 3: 0.775638292822518
Epoch: 31 , Train Loss: 0.0028444590413710105
Epoch: 31 , Test Loss: 0.0028668949170969427
Epoch: 31 , D11: 0.8263072011180107 , D22: 0.8412747065803653
Epoch: 31 , D11*: 0.8105945612510527, D22*: 0.8209692594756682, D12*: 1.1069373796335669
Epoch: 31 , Coefficient 1: 0.9809845057072013 , Coefficient 2: 0.97586347604906 , Coefficient 3: 0.7369720504274699
Epoch: 32 , Train Loss: 0.0028359253678354435
Epoch: 32 , Test Loss: 0.0028665349545190116
Epoch: 32 , D11: 0.8353985824986577 , D22: 0.826974037854696
Epoch: 32 , D11*: 0.8287998207761597, D22*: 0.7961861133893872, D12*: 1.1278457989376005
Epoch: 32 , Coefficient 1: 0.9921010618634744 , Coefficient 2: 0.9627703857001634 , Coefficient 3: 0.720393663609085
Epoch: 33 , Train Loss: 0.002835879452468362
Epoch: 33 , Test Loss: 0.0028727631596848374
Epoch: 33 , D11: 0.8421377181945648 , D22: 0.8328091398612347
Epoch: 33 , D11*: 0.8232361218368829, D22*: 0.8383315694933846, D12*: 1.131638829303795
Epoch: 33 , Coefficient 1: 0.97755521935509 , Coefficient 2: 1.0066310867254291 , Coefficient 3: 0.7341422229000814
Epoch: 34 , Train Loss: 0.0028381580463610586
Epoch: 34 , Test Loss: 0.0028646264848066496
Epoch: 34 , D11: 0.8573967212826923 , D22: 0.811585342103269
Epoch: 34 , D11*: 0.8610375396493981, D22*: 0.8292630263999513, D12*: 1.1280907739090595
Epoch: 34 , Coefficient 1: 1.004246363761759 , Coefficient 2: 1.021781670244154 , Coefficient 3: 0.7491864152882488
Epoch: 35 , Train Loss: 0.0028417292836820708
Epoch: 35 , Test Loss: 0.0028749984910245987
Epoch: 35 , D11: 0.8439499900529319 , D22: 0.8106160605868151
Epoch: 35 , D11*: 0.8805705771674351, D22*: 0.8385239788055753, D12*: 1.08897559592161
Epoch: 35 , Coefficient 1: 1.0433918923468515 , Coefficient 2: 1.034428035139789 , Coefficient 3: 0.7893173007785013
Epoch: 36 , Train Loss: 0.002848541039129486
Epoch: 36 , Test Loss: 0.002860512436018325
Epoch: 36 , D11: 0.8564968037120055 , D22: 0.8196710470312983
Epoch: 36 , D11*: 0.8742799299017623, D22*: 0.8366299021591748, D12*: 1.1023547842090393
Epoch: 36 , Coefficient 1: 1.020762629951082 , Coefficient 2: 1.0206898306208305 , Coefficient 3: 0.7760250404721324
Epoch: 37 , Train Loss: 0.0028400029765907673
Epoch: 37 , Test Loss: 0.002874333597137593
Epoch: 37 , D11: 0.840410241164927 , D22: 0.8248585964507948
Epoch: 37 , D11*: 0.860327275912758, D22*: 0.8012096803331039, D12*: 1.0701543190785645
Epoch: 37 , Coefficient 1: 1.0236991813905352 , Coefficient 2: 0.9713297330967422 , Coefficient 3: 0.7763071767427412
Epoch: 38 , Train Loss: 0.0028400571538077205
Epoch: 38 , Test Loss: 0.002861646527308039
Epoch: 38 , D11: 0.8317366687108365 , D22: 0.8353113068499318
Epoch: 38 , D11*: 0.8226307102393323, D22*: 0.8427672389892188, D12*: 1.1315409269360766
Epoch: 38 , Coefficient 1: 0.9890518732501982 , Coefficient 2: 1.0089259322580035 , Coefficient 3: 0.7358982382272389
Epoch: 39 , Train Loss: 0.0028454190821503287
Epoch: 39 , Test Loss: 0.0028680588613497096
Epoch: 39 , D11: 0.8546377822466493 , D22: 0.829543066055024
Epoch: 39 , D11*: 0.8631016049699205, D22*: 0.8083947555631543, D12*: 1.092610828646907
Epoch: 39 , Coefficient 1: 1.0099034034056178 , Coefficient 2: 0.9745060728523202 , Coefficient 3: 0.7649092964798188
