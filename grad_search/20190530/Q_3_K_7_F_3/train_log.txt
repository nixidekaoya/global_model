Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.003294825734337792
Epoch: 0 , Test Loss: 0.0029738782893400637
Epoch: 0 , D11: 0.8488951265057505 , D22: 0.8158509119557055
Epoch: 0 , D11*: 0.8529327465522418, D22*: 0.8354107794900504, D12*: 1.1190674819864896
Epoch: 0 , Coefficient 1: 1.0047563237441486 , Coefficient 2: 1.023974806239362 , Coefficient 3: 0.7543528666587933
Epoch: 1 , Train Loss: 0.002837025282497052
Epoch: 1 , Test Loss: 0.0028642852918710562
Epoch: 1 , D11: 0.8519749160948938 , D22: 0.817443824389197
Epoch: 1 , D11*: 0.8491214235654279, D22*: 0.7924775949759838, D12*: 1.0895569981334512
Epoch: 1 , Coefficient 1: 0.9966507317579898 , Coefficient 2: 0.9694581711081268 , Coefficient 3: 0.7533332452334657
Epoch: 2 , Train Loss: 0.0028359003945661243
Epoch: 2 , Test Loss: 0.002857175890239887
Epoch: 2 , D11: 0.8468796085196467 , D22: 0.8239731904955986
Epoch: 2 , D11*: 0.8508986605870448, D22*: 0.8221243424956906, D12*: 1.1304197451274571
Epoch: 2 , Coefficient 1: 1.0047457183134016 , Coefficient 2: 0.9977561794227844 , Coefficient 3: 0.7400007874482494
Epoch: 3 , Train Loss: 0.002833680349722272
Epoch: 3 , Test Loss: 0.0028544928826158868
Epoch: 3 , D11: 0.8420664530237446 , D22: 0.8052430137795029
Epoch: 3 , D11*: 0.8533496797652462, D22*: 0.8442488908209325, D12*: 1.1246304733748167
Epoch: 3 , Coefficient 1: 1.0133994492964125 , Coefficient 2: 1.0484398825869359 , Coefficient 3: 0.7547361603549592
Epoch: 4 , Train Loss: 0.0028396174240333492
Epoch: 4 , Test Loss: 0.002853635216597467
Epoch: 4 , D11: 0.8266641829867137 , D22: 0.8343521695470124
Epoch: 4 , D11*: 0.8014526200144515, D22*: 0.8481816080364376, D12*: 1.109977656646076
Epoch: 4 , Coefficient 1: 0.9695020499361983 , Coefficient 2: 1.0165750614598792 , Coefficient 3: 0.7430934389415761
Epoch: 5 , Train Loss: 0.0028365936920454263
Epoch: 5 , Test Loss: 0.002858546252246015
Epoch: 5 , D11: 0.8395496569878487 , D22: 0.8136265147457262
Epoch: 5 , D11*: 0.8630270207346985, D22*: 0.8399452123389224, D12*: 1.1150388584017932
Epoch: 5 , Coefficient 1: 1.0279642348149869 , Coefficient 2: 1.0323473941866572 , Coefficient 3: 0.763638065275377
Epoch: 6 , Train Loss: 0.002837021130253561
Epoch: 6 , Test Loss: 0.0028684405429521575
Epoch: 6 , D11: 0.8355550691258158 , D22: 0.8273510879975312
Epoch: 6 , D11*: 0.8131919886485864, D22*: 0.8191235924314056, D12*: 1.1037447522019252
Epoch: 6 , Coefficient 1: 0.9732356593795471 , Coefficient 2: 0.990055617638651 , Coefficient 3: 0.7394443225318127
Epoch: 7 , Train Loss: 0.00283829476320534
Epoch: 7 , Test Loss: 0.0028517452615778893
Epoch: 7 , D11: 0.8225791081779498 , D22: 0.8316540767875572
Epoch: 7 , D11*: 0.7981542054455424, D22*: 0.8690157903704164, D12*: 1.1261032472512773
Epoch: 7 , Coefficient 1: 0.9703069255107759 , Coefficient 2: 1.0449245841818955 , Coefficient 3: 0.7402385171543461
Epoch: 8 , Train Loss: 0.0028433982119895514
Epoch: 8 , Test Loss: 0.002880872130044736
Epoch: 8 , D11: 0.840738528467611 , D22: 0.8214893882478618
Epoch: 8 , D11*: 0.7886148347422198, D22*: 0.8850968858498807, D12*: 1.0875855915029973
Epoch: 8 , Coefficient 1: 0.9380024919038795 , Coefficient 2: 1.0774294817583536 , Coefficient 3: 0.7694620697756311
Epoch: 9 , Train Loss: 0.0028398636341444216
Epoch: 9 , Test Loss: 0.002851595518877729
Epoch: 9 , D11: 0.8478944541836184 , D22: 0.8078321335183779
Epoch: 9 , D11*: 0.8564555737185107, D22*: 0.8146554817727345, D12*: 1.1216293522035996
Epoch: 9 , Coefficient 1: 1.0100969165356024 , Coefficient 2: 1.0084464927442767 , Coefficient 3: 0.7449479866981508
Epoch: 10 , Train Loss: 0.002835014430893352
Epoch: 10 , Test Loss: 0.002879979207064025
Epoch: 10 , D11: 0.8388018971556204 , D22: 0.8195678331414203
Epoch: 10 , D11*: 0.8257339427056903, D22*: 0.8447517852384905, D12*: 1.11067707576539
Epoch: 10 , Coefficient 1: 0.984420690398718 , Coefficient 2: 1.0307283315409532 , Coefficient 3: 0.7520123375162916
Epoch: 11 , Train Loss: 0.0028395163899403997
Epoch: 11 , Test Loss: 0.002877615918405354
Epoch: 11 , D11: 0.8516555536573152 , D22: 0.8341994848430742
Epoch: 11 , D11*: 0.8678183831964936, D22*: 0.7897634675081584, D12*: 1.1177021916610055
Epoch: 11 , Coefficient 1: 1.0189781296790346 , Coefficient 2: 0.9467321448379042 , Coefficient 3: 0.7415131969283056
Epoch: 12 , Train Loss: 0.002839789283752907
Epoch: 12 , Test Loss: 0.002873108515632339
Epoch: 12 , D11: 0.8329848436220358 , D22: 0.8152944249687644
Epoch: 12 , D11*: 0.8547489783718115, D22*: 0.8374346508729686, D12*: 1.1173574451881823
Epoch: 12 , Coefficient 1: 1.026127888059931 , Coefficient 2: 1.0271561110025407 , Coefficient 3: 0.7572257367291213
Epoch: 13 , Train Loss: 0.0028422600563499144
Epoch: 13 , Test Loss: 0.0028674886579392483
Epoch: 13 , D11: 0.8318809834278764 , D22: 0.8406956936991761
Epoch: 13 , D11*: 0.829139850247372, D22*: 0.798682985388942, D12*: 1.1021518151302345
Epoch: 13 , Coefficient 1: 0.996704897413078 , Coefficient 2: 0.9500262596500615 , Coefficient 3: 0.7384748694733875
Epoch: 14 , Train Loss: 0.0028353500229422934
Epoch: 14 , Test Loss: 0.002867215480073355
Epoch: 14 , D11: 0.8334873676170224 , D22: 0.8218093832667477
Epoch: 14 , D11*: 0.8329567307553316, D22*: 0.772814536080761, D12*: 1.0644258731913145
Epoch: 14 , Coefficient 1: 0.9993633534444465 , Coefficient 2: 0.9403817379265872 , Coefficient 3: 0.7542898511202759
Epoch: 15 , Train Loss: 0.0028387326517258773
Epoch: 15 , Test Loss: 0.0028631781233707447
Epoch: 15 , D11: 0.8321534178261099 , D22: 0.8321056958903877
Epoch: 15 , D11*: 0.8080462662158244, D22*: 0.8652163120415314, D12*: 1.1013619694915795
Epoch: 15 , Coefficient 1: 0.9710304000513966 , Coefficient 2: 1.0397913586154628 , Coefficient 3: 0.7596333560662996
Epoch: 16 , Train Loss: 0.00284265409965883
Epoch: 16 , Test Loss: 0.002875409628031776
Epoch: 16 , D11: 0.8486363159488962 , D22: 0.8436955740824944
Epoch: 16 , D11*: 0.8731356889769499, D22*: 0.8342402487399263, D12*: 1.0855798762331608
Epoch: 16 , Coefficient 1: 1.0288691074935439 , Coefficient 2: 0.9887929655754677 , Coefficient 3: 0.786388903800095
Epoch: 17 , Train Loss: 0.002838687545154244
Epoch: 17 , Test Loss: 0.0028679959749570117
Epoch: 17 , D11: 0.8467110625056851 , D22: 0.818278542866652
Epoch: 17 , D11*: 0.8414122382114751, D22*: 0.8599513829702491, D12*: 1.0889334149270624
Epoch: 17 , Coefficient 1: 0.993741874260472 , Coefficient 2: 1.0509274506424253 , Coefficient 3: 0.7812064529655759
Epoch: 18 , Train Loss: 0.002828374200762483
Epoch: 18 , Test Loss: 0.0028652829304337503
Epoch: 18 , D11: 0.8359958514924286 , D22: 0.8072649726160233
Epoch: 18 , D11*: 0.8550171532359763, D22*: 0.8259412287037617, D12*: 1.0994587497872323
Epoch: 18 , Coefficient 1: 1.0227528661889775 , Coefficient 2: 1.0231352241473035 , Coefficient 3: 0.7644481351687991
Epoch: 19 , Train Loss: 0.002842252737755189
Epoch: 19 , Test Loss: 0.0028595865005627275
Epoch: 19 , D11: 0.8492861216978773 , D22: 0.8140346044976593
Epoch: 19 , D11*: 0.8245386892297071, D22*: 0.8286879531891209, D12*: 1.0855785465536556
Epoch: 19 , Coefficient 1: 0.9708609008955714 , Coefficient 2: 1.0180008916211911 , Coefficient 3: 0.7614495734404769
Epoch: 20 , Train Loss: 0.0028363760920183264
Epoch: 20 , Test Loss: 0.0028667211404535924
Epoch: 20 , D11: 0.8500928077282769 , D22: 0.8203613401521568
Epoch: 20 , D11*: 0.8276124230160551, D22*: 0.8634040442221249, D12*: 1.1289510904796374
Epoch: 20 , Coefficient 1: 0.973555375945014 , Coefficient 2: 1.0524679820504277 , Coefficient 3: 0.7489325629331506
Epoch: 21 , Train Loss: 0.0028452869884495156
Epoch: 21 , Test Loss: 0.0028710680606309326
Epoch: 21 , D11: 0.8145821477882487 , D22: 0.8066980701145091
Epoch: 21 , D11*: 0.8293756738772864, D22*: 0.7983932358377268, D12*: 1.1263220008400543
Epoch: 21 , Coefficient 1: 1.0181608768731367 , Coefficient 2: 0.9897051516739052 , Coefficient 3: 0.7226037085757716
Epoch: 22 , Train Loss: 0.0028454949504521207
Epoch: 22 , Test Loss: 0.002867586709326133
Epoch: 22 , D11: 0.8315767542478407 , D22: 0.8274202955617767
Epoch: 22 , D11*: 0.8214115239881742, D22*: 0.7999884633626129, D12*: 1.0957155199497302
Epoch: 22 , Coefficient 1: 0.9877759566898175 , Coefficient 2: 0.9668465562830569 , Coefficient 3: 0.7398818205227096
Epoch: 23 , Train Loss: 0.0028383515898894986
Epoch: 23 , Test Loss: 0.0028650281933369115
Epoch: 23 , D11: 0.8523575518871022 , D22: 0.8107870070198955
Epoch: 23 , D11*: 0.8515947276413036, D22*: 0.8220719674316156, D12*: 1.1094471814371272
Epoch: 23 , Coefficient 1: 0.9991050419579088 , Coefficient 2: 1.0139185264613437 , Coefficient 3: 0.7542795741321041
Epoch: 24 , Train Loss: 0.0028429099968343505
Epoch: 24 , Test Loss: 0.0028655167785473167
Epoch: 24 , D11: 0.8344347475922579 , D22: 0.8244590632355223
Epoch: 24 , D11*: 0.849145415946135, D22*: 0.8193405625194953, D12*: 1.1034803478048727
Epoch: 24 , Coefficient 1: 1.017629501163901 , Coefficient 2: 0.9937916860347924 , Coefficient 3: 0.7560107353903991
Epoch: 25 , Train Loss: 0.00283658606276731
Epoch: 25 , Test Loss: 0.0028621123905759305
Epoch: 25 , D11: 0.832528399608566 , D22: 0.8159590558357099
Epoch: 25 , D11*: 0.8042019348386197, D22*: 0.7902228224271549, D12*: 1.0822395494413504
Epoch: 25 , Coefficient 1: 0.965975377196424 , Coefficient 2: 0.9684589156471879 , Coefficient 3: 0.7366320876412311
Epoch: 26 , Train Loss: 0.0028506667508918326
Epoch: 26 , Test Loss: 0.002866952965268865
Epoch: 26 , D11: 0.839980990657834 , D22: 0.8183885570765377
Epoch: 26 , D11*: 0.8432244112949644, D22*: 0.8031523186840198, D12*: 1.1009232075144353
Epoch: 26 , Coefficient 1: 1.0038613024261303 , Coefficient 2: 0.9813826351055726 , Coefficient 3: 0.747725508346774
Epoch: 27 , Train Loss: 0.0028407830781361555
Epoch: 27 , Test Loss: 0.002854222373571247
Epoch: 27 , D11: 0.8429112947736205 , D22: 0.8158649227048008
Epoch: 27 , D11*: 0.8252313845781004, D22*: 0.8036618081181461, D12*: 1.071233807567506
Epoch: 27 , Coefficient 1: 0.9790251829520586 , Coefficient 2: 0.9850427267467288 , Coefficient 3: 0.7602883615086049
Epoch: 28 , Train Loss: 0.002834084209462162
Epoch: 28 , Test Loss: 0.002864112232928164
Epoch: 28 , D11: 0.8443904502821586 , D22: 0.8101180628967537
Epoch: 28 , D11*: 0.8332965196452824, D22*: 0.8069044918015413, D12*: 1.0994177554988729
Epoch: 28 , Coefficient 1: 0.9868616104869861 , Coefficient 2: 0.9960332064641029 , Coefficient 3: 0.7459407505669056
Epoch: 29 , Train Loss: 0.0028400009156030136
Epoch: 29 , Test Loss: 0.0028732864151243117
Epoch: 29 , D11: 0.8294285524075927 , D22: 0.8219738900089176
Epoch: 29 , D11*: 0.8336365425076064, D22*: 0.8110632770823825, D12*: 1.1163493328081764
Epoch: 29 , Coefficient 1: 1.0050733605538404 , Coefficient 2: 0.9867263266398684 , Coefficient 3: 0.7366420936772305
Epoch: 30 , Train Loss: 0.002840739399543963
Epoch: 30 , Test Loss: 0.0028689344227313994
Epoch: 30 , D11: 0.8459794833878235 , D22: 0.8323812902580906
Epoch: 30 , D11*: 0.8478572542817121, D22*: 0.8580391887055179, D12*: 1.0810683503441867
Epoch: 30 , Coefficient 1: 1.0022196411742386 , Coefficient 2: 1.0308246938605163 , Coefficient 3: 0.7889863959314473
Epoch: 31 , Train Loss: 0.002842836033087224
Epoch: 31 , Test Loss: 0.002876178792212158
Epoch: 31 , D11: 0.8525678924537506 , D22: 0.7941264795965185
Epoch: 31 , D11*: 0.8581559798616953, D22*: 0.8110174347606354, D12*: 1.1164064602853727
Epoch: 31 , Coefficient 1: 1.0065544192520104 , Coefficient 2: 1.0212698551151433 , Coefficient 3: 0.7475652793139791
Epoch: 32 , Train Loss: 0.0028424068150343373
Epoch: 32 , Test Loss: 0.0028580381028587
Epoch: 32 , D11: 0.8409601540268343 , D22: 0.833946125652842
Epoch: 32 , D11*: 0.8105953271950732, D22*: 0.8145288833234122, D12*: 1.093175831110489
Epoch: 32 , Coefficient 1: 0.9638926687710911 , Coefficient 2: 0.9767164307955394 , Coefficient 3: 0.7433041255895784
Epoch: 33 , Train Loss: 0.00284506166484789
Epoch: 33 , Test Loss: 0.0028554393054218965
Epoch: 33 , D11: 0.833216325417673 , D22: 0.8144509115051416
Epoch: 33 , D11*: 0.839756901646462, D22*: 0.7949955507809467, D12*: 1.1138807458903244
Epoch: 33 , Coefficient 1: 1.0078497936601403 , Coefficient 2: 0.9761122979305893 , Coefficient 3: 0.7338094578162188
Epoch: 34 , Train Loss: 0.0028444664367998484
Epoch: 34 , Test Loss: 0.0028675895737251267
Epoch: 34 , D11: 0.8548393484563944 , D22: 0.8201468034458151
Epoch: 34 , D11*: 0.8649356803224417, D22*: 0.8703173232456025, D12*: 1.0907673667534987
Epoch: 34 , Coefficient 1: 1.0118107944893722 , Coefficient 2: 1.0611726090853466 , Coefficient 3: 0.7954276303354939
Epoch: 35 , Train Loss: 0.0028413801954593506
Epoch: 35 , Test Loss: 0.002878620995907113
Epoch: 35 , D11: 0.8431138734204922 , D22: 0.798650838844299
Epoch: 35 , D11*: 0.8340242252399163, D22*: 0.8275018442960496, D12*: 1.0979104845642298
Epoch: 35 , Coefficient 1: 0.9892189555087032 , Coefficient 2: 1.0361246793323349 , Coefficient 3: 0.7566764744921075
Epoch: 36 , Train Loss: 0.002841095178009709
Epoch: 36 , Test Loss: 0.002859128692070953
Epoch: 36 , D11: 0.8469493122717989 , D22: 0.8349236033613588
Epoch: 36 , D11*: 0.8742665112328372, D22*: 0.8155183633147699, D12*: 1.1049837513004155
Epoch: 36 , Coefficient 1: 1.0322536408793632 , Coefficient 2: 0.9767580650870756 , Coefficient 3: 0.7646197840280278
Epoch: 37 , Train Loss: 0.0028384077016380617
Epoch: 37 , Test Loss: 0.0028775374154793093
Epoch: 37 , D11: 0.8598600107153866 , D22: 0.8411209507077603
Epoch: 37 , D11*: 0.8463343720880443, D22*: 0.8493480309817975, D12*: 1.128689086176508
Epoch: 37 , Coefficient 1: 0.984269952714641 , Coefficient 2: 1.0097810906589766 , Coefficient 3: 0.7511733850524118
Epoch: 38 , Train Loss: 0.0028360721288481724
Epoch: 38 , Test Loss: 0.002875218146364205
Epoch: 38 , D11: 0.8240654094131755 , D22: 0.8211391757620722
Epoch: 38 , D11*: 0.7783320376434995, D22*: 0.8042888569685324, D12*: 1.1390469525342648
Epoch: 38 , Coefficient 1: 0.9445027406231706 , Coefficient 2: 0.9794793388369254 , Coefficient 3: 0.6947127557344585
Epoch: 39 , Train Loss: 0.0028430505288997666
Epoch: 39 , Test Loss: 0.0028593029081821443
Epoch: 39 , D11: 0.8522126008860963 , D22: 0.8396527691183363
Epoch: 39 , D11*: 0.8612584426191693, D22*: 0.8218507175671187, D12*: 1.1045061259708258
Epoch: 39 , Coefficient 1: 1.0106145364709083 , Coefficient 2: 0.9787983173450254 , Coefficient 3: 0.7619283952394961
