Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.003292423576349393
Epoch: 0 , Test Loss: 0.0030008142866427084
Epoch: 0 , D11: 0.849585367801306 , D22: 0.8085476272962976
Epoch: 0 , D11*: 0.7871555993975298, D22*: 0.787166119643245, D12*: 1.1163910671135668
Epoch: 0 , Coefficient 1: 0.926517368624954 , Coefficient 2: 0.9735556608773311 , Coefficient 3: 0.7050941938792064
Epoch: 1 , Train Loss: 0.0028395960865600497
Epoch: 1 , Test Loss: 0.002878792980918661
Epoch: 1 , D11: 0.8441970172862219 , D22: 0.8070340927686079
Epoch: 1 , D11*: 0.8401570316541264, D22*: 0.8425781326626234, D12*: 1.1071003292224701
Epoch: 1 , Coefficient 1: 0.9952144042807891 , Coefficient 2: 1.0440427984548686 , Coefficient 3: 0.7599741052821087
Epoch: 2 , Train Loss: 0.0028439777577295897
Epoch: 2 , Test Loss: 0.002862223242409528
Epoch: 2 , D11: 0.8412352353029093 , D22: 0.8362110421371532
Epoch: 2 , D11*: 0.8545418058761147, D22*: 0.858917766310708, D12*: 1.0902864537908363
Epoch: 2 , Coefficient 1: 1.0158178949416141 , Coefficient 2: 1.0271542984119437 , Coefficient 3: 0.7857841240846681
Epoch: 3 , Train Loss: 0.002844058475311613
Epoch: 3 , Test Loss: 0.0028657116717658937
Epoch: 3 , D11: 0.841218525964799 , D22: 0.8261877283284577
Epoch: 3 , D11*: 0.8684355201013845, D22*: 0.811829414869671, D12*: 1.091061840136085
Epoch: 3 , Coefficient 1: 1.0323542495754836 , Coefficient 2: 0.9826210037180818 , Coefficient 3: 0.7700136111265155
Epoch: 4 , Train Loss: 0.002838966432464076
Epoch: 4 , Test Loss: 0.0028636016487143933
Epoch: 4 , D11: 0.8297738834610222 , D22: 0.8063097039326258
Epoch: 4 , D11*: 0.8543701401116259, D22*: 0.8182199626458263, D12*: 1.0692074949676451
Epoch: 4 , Coefficient 1: 1.0296421195470888 , Coefficient 2: 1.0147713200710724 , Coefficient 3: 0.7821634765140072
Epoch: 5 , Train Loss: 0.002852789266471518
Epoch: 5 , Test Loss: 0.0028685766819398855
Epoch: 5 , D11: 0.8547196551208683 , D22: 0.8259467285478406
Epoch: 5 , D11*: 0.8314913240219892, D22*: 0.8257154791926666, D12*: 1.1044791125761115
Epoch: 5 , Coefficient 1: 0.9728234504030514 , Coefficient 2: 0.9997200190433825 , Coefficient 3: 0.750220979439507
Epoch: 6 , Train Loss: 0.002835292408126406
Epoch: 6 , Test Loss: 0.002864972995594144
Epoch: 6 , D11: 0.828977575307822 , D22: 0.8062972650982476
Epoch: 6 , D11*: 0.8462934664676468, D22*: 0.8406692847801117, D12*: 1.1503754448406667
Epoch: 6 , Coefficient 1: 1.0208882503889143 , Coefficient 2: 1.0426294633129827 , Coefficient 3: 0.7332226877814713
Epoch: 7 , Train Loss: 0.002838775498676114
Epoch: 7 , Test Loss: 0.0028589344309875742
Epoch: 7 , D11: 0.8435550717725154 , D22: 0.8155869476230865
Epoch: 7 , D11*: 0.8493770726552972, D22*: 0.8258794609172128, D12*: 1.1292547129984085
Epoch: 7 , Coefficient 1: 1.0069017436769698 , Coefficient 2: 1.0126197621530388 , Coefficient 3: 0.7417531732607747
Epoch: 8 , Train Loss: 0.002841892433207249
Epoch: 8 , Test Loss: 0.0028624091605888675
Epoch: 8 , D11: 0.832566845210194 , D22: 0.8041350526142872
Epoch: 8 , D11*: 0.8347546522148022, D22*: 0.8250744929488022, D12*: 1.0885034177734516
Epoch: 8 , Coefficient 1: 1.0026277854050936 , Coefficient 2: 1.0260397059753081 , Coefficient 3: 0.7624363497906177
Epoch: 9 , Train Loss: 0.002831835960969329
Epoch: 9 , Test Loss: 0.00286345949745737
Epoch: 9 , D11: 0.8317697012619263 , D22: 0.8231724305961481
Epoch: 9 , D11*: 0.8116943105284301, D22*: 0.8549107276786502, D12*: 1.1230123326764752
Epoch: 9 , Coefficient 1: 0.9758642437888293 , Coefficient 2: 1.0385560739194302 , Coefficient 3: 0.7420243703980796
Epoch: 10 , Train Loss: 0.0028477930299413852
Epoch: 10 , Test Loss: 0.0028715288295643408
Epoch: 10 , D11: 0.8324521069329851 , D22: 0.8194679157319853
Epoch: 10 , D11*: 0.8320540860673892, D22*: 0.8334213164965395, D12*: 1.1020772176611944
Epoch: 10 , Coefficient 1: 0.9995218693516648 , Coefficient 2: 1.0170273911847914 , Coefficient 3: 0.7556074002229927
Epoch: 11 , Train Loss: 0.002840888543141773
Epoch: 11 , Test Loss: 0.002872832864522934
Epoch: 11 , D11: 0.8161942465743194 , D22: 0.8168375725810801
Epoch: 11 , D11*: 0.8007088792862757, D22*: 0.8371400160113214, D12*: 1.1192354895175387
Epoch: 11 , Coefficient 1: 0.9810273505932712 , Coefficient 2: 1.0248549333572998 , Coefficient 3: 0.7316819876769693
Epoch: 12 , Train Loss: 0.0028382554888958115
Epoch: 12 , Test Loss: 0.002870007778401487
Epoch: 12 , D11: 0.8502071491582021 , D22: 0.8374102891407105
Epoch: 12 , D11*: 0.7992213088376331, D22*: 0.8440900436484013, D12*: 1.110758521720384
Epoch: 12 , Coefficient 1: 0.9400312731184977 , Coefficient 2: 1.0079766807194896 , Coefficient 3: 0.7397248458381454
Epoch: 13 , Train Loss: 0.002842273096612189
Epoch: 13 , Test Loss: 0.0028669747308595105
Epoch: 13 , D11: 0.8099777057707023 , D22: 0.8351472963884239
Epoch: 13 , D11*: 0.7827273203755052, D22*: 0.7942498251513673, D12*: 1.0713635340016727
Epoch: 13 , Coefficient 1: 0.9663566229032587 , Coefficient 2: 0.9510296310436294 , Coefficient 3: 0.7359673423066173
Epoch: 14 , Train Loss: 0.0028358313774515405
Epoch: 14 , Test Loss: 0.0028563428635243323
Epoch: 14 , D11: 0.8536943492297924 , D22: 0.8376372425497048
Epoch: 14 , D11*: 0.827174437867074, D22*: 0.8027265995950967, D12*: 1.1252088120483685
Epoch: 14 , Coefficient 1: 0.9689351213503465 , Coefficient 2: 0.9583224799695597 , Coefficient 3: 0.7242660295625677
Epoch: 15 , Train Loss: 0.0028431881211872677
Epoch: 15 , Test Loss: 0.0028681152738863603
Epoch: 15 , D11: 0.8391507779888836 , D22: 0.8086828048136939
Epoch: 15 , D11*: 0.8633011033051564, D22*: 0.8315064707743417, D12*: 1.1260624533145083
Epoch: 15 , Coefficient 1: 1.0287794827219867 , Coefficient 2: 1.0282232611164595 , Coefficient 3: 0.7525371124358676
Epoch: 16 , Train Loss: 0.0028394706218387
Epoch: 16 , Test Loss: 0.002851925213471986
Epoch: 16 , D11: 0.8554129147591978 , D22: 0.8229495876643543
Epoch: 16 , D11*: 0.8673026918148404, D22*: 0.8130675262122985, D12*: 1.1088143479325738
Epoch: 16 , Coefficient 1: 1.0138994593727753 , Coefficient 2: 0.9879918993821937 , Coefficient 3: 0.7577328978292229
Epoch: 17 , Train Loss: 0.0028423072223085913
Epoch: 17 , Test Loss: 0.002865850644302554
Epoch: 17 , D11: 0.8355001732966205 , D22: 0.8174366522744657
Epoch: 17 , D11*: 0.8396428036700238, D22*: 0.8234825362078984, D12*: 1.1162296817045585
Epoch: 17 , Coefficient 1: 1.0049582639307635 , Coefficient 2: 1.0073961498014683 , Coefficient 3: 0.7449745187469916
Epoch: 18 , Train Loss: 0.0028463540467782876
Epoch: 18 , Test Loss: 0.002858321126550436
Epoch: 18 , D11: 0.8341988700528736 , D22: 0.8194774778870743
Epoch: 18 , D11*: 0.8242035674651116, D22*: 0.7818003254692163, D12*: 1.111896685633867
Epoch: 18 , Coefficient 1: 0.9880180818428482 , Coefficient 2: 0.9540229555606531 , Coefficient 3: 0.7221911503490009
Epoch: 19 , Train Loss: 0.0028373033610114362
Epoch: 19 , Test Loss: 0.002866217075497844
Epoch: 19 , D11: 0.8275389077382456 , D22: 0.8190585027172538
Epoch: 19 , D11*: 0.798249965583194, D22*: 0.7839231035969476, D12*: 1.1031162805849049
Epoch: 19 , Coefficient 1: 0.9646071720843901 , Coefficient 2: 0.9571026990089923 , Coefficient 3: 0.7171379377798807
Epoch: 20 , Train Loss: 0.0028430267774092496
Epoch: 20 , Test Loss: 0.0028747936594299968
Epoch: 20 , D11: 0.8484223657994104 , D22: 0.8166436821410131
Epoch: 20 , D11*: 0.8314624169396201, D22*: 0.8035412163991213, D12*: 1.1152223528670797
Epoch: 20 , Coefficient 1: 0.9800100167753002 , Coefficient 2: 0.9839557128421776 , Coefficient 3: 0.733039303388861
Epoch: 21 , Train Loss: 0.002844581329991342
Epoch: 21 , Test Loss: 0.002868664091802202
Epoch: 21 , D11: 0.8453172017463841 , D22: 0.8130608321775971
Epoch: 21 , D11*: 0.8323323005580882, D22*: 0.7918826401690334, D12*: 1.119363340570168
Epoch: 21 , Coefficient 1: 0.9846390193391666 , Coefficient 2: 0.9739525123208276 , Coefficient 3: 0.7255083679530716
Epoch: 22 , Train Loss: 0.0028410852747038006
Epoch: 22 , Test Loss: 0.0028922108473489064
Epoch: 22 , D11: 0.8352482574051033 , D22: 0.8022474915285922
Epoch: 22 , D11*: 0.8523724723804115, D22*: 0.8210781677668636, D12*: 1.1235734690391692
Epoch: 22 , Coefficient 1: 1.0205019463656333 , Coefficient 2: 1.023472402764877 , Coefficient 3: 0.7447001403381021
Epoch: 23 , Train Loss: 0.002839736531750532
Epoch: 23 , Test Loss: 0.0028590420732507484
Epoch: 23 , D11: 0.8277083535203441 , D22: 0.7808833708081077
Epoch: 23 , D11*: 0.8324950611605425, D22*: 0.7414809863335415, D12*: 1.132121443473783
Epoch: 23 , Coefficient 1: 1.0057830848508897 , Coefficient 2: 0.949541268328214 , Coefficient 3: 0.6951445256016535
Epoch: 24 , Train Loss: 0.0028395446471404283
Epoch: 24 , Test Loss: 0.0028572891821386295
Epoch: 24 , D11: 0.8332871337692688 , D22: 0.8295454116994514
Epoch: 24 , D11*: 0.8233524993880936, D22*: 0.8326771419476792, D12*: 1.0885548784248025
Epoch: 24 , Coefficient 1: 0.9880777777808267 , Coefficient 2: 1.003775236658608 , Coefficient 3: 0.7606551007020136
Epoch: 25 , Train Loss: 0.0028416171982826193
Epoch: 25 , Test Loss: 0.0028560677653877062
Epoch: 25 , D11: 0.8355532499743696 , D22: 0.8101148384772984
Epoch: 25 , D11*: 0.8261385373145093, D22*: 0.8325190919935157, D12*: 1.1314339059649339
Epoch: 25 , Coefficient 1: 0.9887323606722263 , Coefficient 2: 1.0276556513374433 , Coefficient 3: 0.7329891832671626
Epoch: 26 , Train Loss: 0.002836338660417823
Epoch: 26 , Test Loss: 0.0028698121244087817
Epoch: 26 , D11: 0.8564933553345512 , D22: 0.8127017934149905
Epoch: 26 , D11*: 0.8494227540919282, D22*: 0.8244050519196053, D12*: 1.1105682247270274
Epoch: 26 , Coefficient 1: 0.9917447097533394 , Coefficient 2: 1.0144004339592232 , Coefficient 3: 0.7535907154299111
Epoch: 27 , Train Loss: 0.002837626961263595
Epoch: 27 , Test Loss: 0.002874631510931067
Epoch: 27 , D11: 0.8390912870573545 , D22: 0.8186540635681094
Epoch: 27 , D11*: 0.8409775980068627, D22*: 0.8124771936409948, D12*: 1.1008479728331966
Epoch: 27 , Coefficient 1: 1.0022480402056413 , Coefficient 2: 0.9924548472889847 , Coefficient 3: 0.7509914322649134
Epoch: 28 , Train Loss: 0.0028365643999131865
Epoch: 28 , Test Loss: 0.0028743501513963563
Epoch: 28 , D11: 0.8436385501978704 , D22: 0.8004415036359941
Epoch: 28 , D11*: 0.8544570067505911, D22*: 0.791744417955379, D12*: 1.1218052340367777
Epoch: 28 , Coefficient 1: 1.0128235682807327 , Coefficient 2: 0.9891346392695672 , Coefficient 3: 0.7337287145568802
Epoch: 29 , Train Loss: 0.0028480689419666306
Epoch: 29 , Test Loss: 0.002850802242173813
Epoch: 29 , D11: 0.827639843402454 , D22: 0.8355383284008915
Epoch: 29 , D11*: 0.8224500232060316, D22*: 0.8251143268104261, D12*: 1.1275547556182575
Epoch: 29 , Coefficient 1: 0.9937293736668272 , Coefficient 2: 0.9875242089606882 , Coefficient 3: 0.7305917259481869
Epoch: 30 , Train Loss: 0.002837680860684486
Epoch: 30 , Test Loss: 0.0028597163734957578
Epoch: 30 , D11: 0.8350668551834707 , D22: 0.8111553214716565
Epoch: 30 , D11*: 0.8096890380708905, D22*: 0.7888334695732261, D12*: 1.1021564820804601
Epoch: 30 , Coefficient 1: 0.9696098378769872 , Coefficient 2: 0.9724814085446268 , Coefficient 3: 0.7251794702630168
Epoch: 31 , Train Loss: 0.0028420358878793192
Epoch: 31 , Test Loss: 0.0028642424358986318
Epoch: 31 , D11: 0.8334469215573177 , D22: 0.7939969096746514
Epoch: 31 , D11*: 0.8187788533936526, D22*: 0.7818703782977038, D12*: 1.1061347740230303
Epoch: 31 , Coefficient 1: 0.982400717089149 , Coefficient 2: 0.9847272310141401 , Coefficient 3: 0.7235326423514239
Epoch: 32 , Train Loss: 0.002836667150113499
Epoch: 32 , Test Loss: 0.002862368376227096
Epoch: 32 , D11: 0.8415957163512713 , D22: 0.799077857485509
Epoch: 32 , D11*: 0.8471790112503738, D22*: 0.7893652041644166, D12*: 1.1267441613430174
Epoch: 32 , Coefficient 1: 1.006634176945801 , Coefficient 2: 0.9878451727449242 , Coefficient 3: 0.7262270671383463
Epoch: 33 , Train Loss: 0.002829077466594754
Epoch: 33 , Test Loss: 0.002880857773125172
Epoch: 33 , D11: 0.8283633255539109 , D22: 0.8262817113618216
Epoch: 33 , D11*: 0.8231022315046826, D22*: 0.8123392593978738, D12*: 1.1011316683148251
Epoch: 33 , Coefficient 1: 0.9936488085759829 , Coefficient 2: 0.983126273070998 , Coefficient 3: 0.7426184978429694
Epoch: 34 , Train Loss: 0.002834728716843529
Epoch: 34 , Test Loss: 0.00285891319217626
Epoch: 34 , D11: 0.8240401396616199 , D22: 0.8235968587765181
Epoch: 34 , D11*: 0.8430071819982066, D22*: 0.8326265237375164, D12*: 1.099909369662821
Epoch: 34 , Coefficient 1: 1.0230171340250187 , Coefficient 2: 1.0109636952409122 , Coefficient 3: 0.761714443004241
Epoch: 35 , Train Loss: 0.0028369301598286253
Epoch: 35 , Test Loss: 0.0028713018412236126
Epoch: 35 , D11: 0.8392365046948104 , D22: 0.8378968933114572
Epoch: 35 , D11*: 0.848777543002845, D22*: 0.8699303206820346, D12*: 1.1108574414697707
Epoch: 35 , Coefficient 1: 1.011368712221955 , Coefficient 2: 1.0382307508552489 , Coefficient 3: 0.773595152502586
Epoch: 36 , Train Loss: 0.0028382194854202677
Epoch: 36 , Test Loss: 0.0028527451836271216
Epoch: 36 , D11: 0.8475369760862959 , D22: 0.8050764875728114
Epoch: 36 , D11*: 0.826256852950428, D22*: 0.8268298349554392, D12*: 1.1089079434571232
Epoch: 36 , Coefficient 1: 0.9748918056246537 , Coefficient 2: 1.0270202244363278 , Coefficient 3: 0.7453669610987799
Epoch: 37 , Train Loss: 0.0028498067322652787
Epoch: 37 , Test Loss: 0.0028685942356241863
Epoch: 37 , D11: 0.8239046916667537 , D22: 0.8260204872064806
Epoch: 37 , D11*: 0.8255140658205203, D22*: 0.7895043840873125, D12*: 1.1586300843973503
Epoch: 37 , Coefficient 1: 1.0019533499081197 , Coefficient 2: 0.9557927391817339 , Coefficient 3: 0.6969517155028252
Epoch: 38 , Train Loss: 0.0028376855824899395
Epoch: 38 , Test Loss: 0.0028606727340957155
Epoch: 38 , D11: 0.832334182853007 , D22: 0.8313815113733373
Epoch: 38 , D11*: 0.8293747596697357, D22*: 0.8565239846299773, D12*: 1.1571139575977332
Epoch: 38 , Coefficient 1: 0.996444429119651 , Coefficient 2: 1.0302417998388103 , Coefficient 3: 0.7284929601055811
Epoch: 39 , Train Loss: 0.002834988661779789
Epoch: 39 , Test Loss: 0.002876848604646512
Epoch: 39 , D11: 0.8459241565895881 , D22: 0.8473940730024546
Epoch: 39 , D11*: 0.8901762977133053, D22*: 0.860687640576759, D12*: 1.098880377055148
Epoch: 39 , Coefficient 1: 1.0523121851752328 , Coefficient 2: 1.0156875862102777 , Coefficient 3: 0.7966581144082965
