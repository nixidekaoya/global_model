Optimizer: Adam
Learning Rate: 0.05
Betas: (0.9, 0.999)
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.0033312588033732027
Epoch: 0 , Test Loss: 0.0030276136117754504
Epoch: 0 , D11: 0.8276566411511016 , D22: 0.8172265643583073
Epoch: 0 , D11*: 0.830493815107099, D22*: 0.8041387477388675, D12*: 1.0770371437849762
Epoch: 0 , Coefficient 1: 1.0034279601164697 , Coefficient 2: 0.9839850817505957 , Coefficient 3: 0.758856169575295
Epoch: 1 , Train Loss: 0.002836288053658791
Epoch: 1 , Test Loss: 0.0028622115036705514
Epoch: 1 , D11: 0.8168716522178002 , D22: 0.8145306639606268
Epoch: 1 , D11*: 0.8121421417102817, D22*: 0.7917895359052215, D12*: 1.1274622291708083
Epoch: 1 , Coefficient 1: 0.9942102158953883 , Coefficient 2: 0.9720806974352232 , Coefficient 3: 0.7113017341588082
Epoch: 2 , Train Loss: 0.002837590524868574
Epoch: 2 , Test Loss: 0.002873776482301764
Epoch: 2 , D11: 0.8424394464572484 , D22: 0.8265425061508457
Epoch: 2 , D11*: 0.8488747930802079, D22*: 0.861145702308591, D12*: 1.1315664315477707
Epoch: 2 , Coefficient 1: 1.0076389426563799 , Coefficient 2: 1.0418649929074915 , Coefficient 3: 0.7555988087459485
Epoch: 3 , Train Loss: 0.002836165760090807
Epoch: 3 , Test Loss: 0.0028826042771106586
Epoch: 3 , D11: 0.8597662091061301 , D22: 0.8039112800474099
Epoch: 3 , D11*: 0.8892279929728929, D22*: 0.8077397534600791, D12*: 1.115868874277804
Epoch: 3 , Coefficient 1: 1.0342672037522773 , Coefficient 2: 1.0047623083637331 , Coefficient 3: 0.7603795506578934
Epoch: 4 , Train Loss: 0.0028315606599790045
Epoch: 4 , Test Loss: 0.002862004522467032
Epoch: 4 , D11: 0.8409235204612284 , D22: 0.8232118906040264
Epoch: 4 , D11*: 0.8550784588559162, D22*: 0.8506493851007939, D12*: 1.1343324054980526
Epoch: 4 , Coefficient 1: 1.016832610873964 , Coefficient 2: 1.0333298082910773 , Coefficient 3: 0.7518641959310747
Epoch: 5 , Train Loss: 0.00283735347649781
Epoch: 5 , Test Loss: 0.0028644311224343263
Epoch: 5 , D11: 0.8348419139237939 , D22: 0.8335211512351232
Epoch: 5 , D11*: 0.8174339078468714, D22*: 0.8334014747980192, D12*: 1.0941362001725776
Epoch: 5 , Coefficient 1: 0.9791481407598427 , Coefficient 2: 0.9998564206356052 , Coefficient 3: 0.7544012264581434
Epoch: 6 , Train Loss: 0.002842438227817183
Epoch: 6 , Test Loss: 0.002872147953603416
Epoch: 6 , D11: 0.8408867142798672 , D22: 0.82670183753495
Epoch: 6 , D11*: 0.8136750456420542, D22*: 0.8368616002262239, D12*: 1.1076711490031041
Epoch: 6 , Coefficient 1: 0.9676393167168577 , Coefficient 2: 1.0122895126513427 , Coefficient 3: 0.7450481342561595
Epoch: 7 , Train Loss: 0.0028367319933022372
Epoch: 7 , Test Loss: 0.002852736094500869
Epoch: 7 , D11: 0.8312193122576745 , D22: 0.837321589483569
Epoch: 7 , D11*: 0.8291664091989567, D22*: 0.8685351183585812, D12*: 1.1260334705840356
Epoch: 7 , Coefficient 1: 0.9975302510078333 , Coefficient 2: 1.0372778264254043 , Coefficient 3: 0.7538415028982209
Epoch: 8 , Train Loss: 0.0028420217175153086
Epoch: 8 , Test Loss: 0.002867369119776413
Epoch: 8 , D11: 0.824874678892306 , D22: 0.8179606646196566
Epoch: 8 , D11*: 0.8361666589782184, D22*: 0.8318483131868354, D12*: 1.124450672655706
Epoch: 8 , Coefficient 1: 1.0136893280577797 , Coefficient 2: 1.0169783819294493 , Coefficient 3: 0.7417021540951939
Epoch: 9 , Train Loss: 0.0028350245587353126
Epoch: 9 , Test Loss: 0.0028634268388850618
Epoch: 9 , D11: 0.8209468144889897 , D22: 0.8178981667049574
Epoch: 9 , D11*: 0.8252997400446339, D22*: 0.7988996902947664, D12*: 1.1335235578272507
Epoch: 9 , Coefficient 1: 1.0053023234621523 , Coefficient 2: 0.9767715869975236 , Coefficient 3: 0.7164383215169705
Epoch: 10 , Train Loss: 0.002834079966996796
Epoch: 10 , Test Loss: 0.0028573435230646285
Epoch: 10 , D11: 0.8294991479936428 , D22: 0.818403568690292
Epoch: 10 , D11*: 0.8380035173215047, D22*: 0.8252563310348714, D12*: 1.1071528881778747
Epoch: 10 , Coefficient 1: 1.0102524147835859 , Coefficient 2: 1.0083733290111945 , Coefficient 3: 0.7511428033637381
Epoch: 11 , Train Loss: 0.0028438636634382417
Epoch: 11 , Test Loss: 0.0028565380815416576
Epoch: 11 , D11: 0.8423904159400506 , D22: 0.8387993180982366
Epoch: 11 , D11*: 0.8088404604474303, D22*: 0.8039758976545245, D12*: 1.1392536570895795
Epoch: 11 , Coefficient 1: 0.9601729140576928 , Coefficient 2: 0.9584842051103888 , Coefficient 3: 0.7078390084883173
Epoch: 12 , Train Loss: 0.0028415214217966424
Epoch: 12 , Test Loss: 0.002855276296613738
Epoch: 12 , D11: 0.8392305006236012 , D22: 0.8155781255079897
Epoch: 12 , D11*: 0.8410893449223235, D22*: 0.8267945781797672, D12*: 1.1346872974637299
Epoch: 12 , Coefficient 1: 1.0022149389200476 , Coefficient 2: 1.0137527630045144 , Coefficient 3: 0.7349531129986957
Epoch: 13 , Train Loss: 0.0028373327366716695
Epoch: 13 , Test Loss: 0.0028675171238137414
Epoch: 13 , D11: 0.839862167107348 , D22: 0.8155175061927741
Epoch: 13 , D11*: 0.8406967666589218, D22*: 0.8088288705352185, D12*: 1.0992433967777193
Epoch: 13 , Coefficient 1: 1.0009937339533324 , Coefficient 2: 0.9917982929774477 , Coefficient 3: 0.750300453034104
Epoch: 14 , Train Loss: 0.0028482590916974002
Epoch: 14 , Test Loss: 0.0028693731210660193
Epoch: 14 , D11: 0.8348865292304938 , D22: 0.8144432346009272
Epoch: 14 , D11*: 0.8433692096317975, D22*: 0.8460837430892031, D12*: 1.147094360233187
Epoch: 14 , Coefficient 1: 1.0101602793964375 , Coefficient 2: 1.0388492495781854 , Coefficient 3: 0.7364053957939259
Epoch: 15 , Train Loss: 0.002847525768447667
Epoch: 15 , Test Loss: 0.002872026169206947
Epoch: 15 , D11: 0.8575208299047957 , D22: 0.8092798516001781
Epoch: 15 , D11*: 0.8478594055289534, D22*: 0.7881261831336684, D12*: 1.1295109927398144
Epoch: 15 , Coefficient 1: 0.9887333064819954 , Coefficient 2: 0.9738611205695004 , Coefficient 3: 0.7242008263656958
Epoch: 16 , Train Loss: 0.0028446683006768574
Epoch: 16 , Test Loss: 0.002876737774349749
Epoch: 16 , D11: 0.8462095430979842 , D22: 0.8156898796545294
Epoch: 16 , D11*: 0.8535604001652971, D22*: 0.8354137292854106, D12*: 1.1071904192166278
Epoch: 16 , Coefficient 1: 1.0086868047368047 , Coefficient 2: 1.0241805741653125 , Coefficient 3: 0.7627297437444005
Epoch: 17 , Train Loss: 0.00283539042036864
Epoch: 17 , Test Loss: 0.0028694241319317374
Epoch: 17 , D11: 0.8301603181960093 , D22: 0.8284045062579625
Epoch: 17 , D11*: 0.8315184647966062, D22*: 0.8199170804748694, D12*: 1.1399955243243682
Epoch: 17 , Coefficient 1: 1.001636005203848 , Coefficient 2: 0.9897544910499919 , Coefficient 3: 0.7243166793353064
Epoch: 18 , Train Loss: 0.0028371811326360326
Epoch: 18 , Test Loss: 0.002872213507653214
Epoch: 18 , D11: 0.832505030868095 , D22: 0.8306198067207724
Epoch: 18 , D11*: 0.8333865562225532, D22*: 0.7608984168451545, D12*: 1.1042879643109027
Epoch: 18 , Coefficient 1: 1.0010588829157452 , Coefficient 2: 0.9160610073206983 , Coefficient 3: 0.7218610654977902
Epoch: 19 , Train Loss: 0.002842740581399994
Epoch: 19 , Test Loss: 0.0028693407605169343
Epoch: 19 , D11: 0.8304502406997593 , D22: 0.8032979300841266
Epoch: 19 , D11*: 0.8043454183736682, D22*: 0.7808489371970189, D12*: 1.1535781443398891
Epoch: 19 , Coefficient 1: 0.9685654587755982 , Coefficient 2: 0.9720539639822591 , Coefficient 3: 0.687077144859476
Epoch: 20 , Train Loss: 0.0028415696692536585
Epoch: 20 , Test Loss: 0.0028599367197602987
Epoch: 20 , D11: 0.8364977142523868 , D22: 0.8087091144661073
Epoch: 20 , D11*: 0.8365379177223513, D22*: 0.7867852439486958, D12*: 1.1241194913560384
Epoch: 20 , Coefficient 1: 1.000048061661472 , Coefficient 2: 0.9728902888254386 , Coefficient 3: 0.7220420845620307
Epoch: 21 , Train Loss: 0.002832369427051162
Epoch: 21 , Test Loss: 0.002865213052136823
Epoch: 21 , D11: 0.8368769150127824 , D22: 0.7977760971229004
Epoch: 21 , D11*: 0.8535687894295455, D22*: 0.7909622478041596, D12*: 1.0959342533313339
Epoch: 21 , Coefficient 1: 1.0199454353648985 , Coefficient 2: 0.9914589452563015 , Coefficient 3: 0.7502872696216906
Epoch: 22 , Train Loss: 0.0028426355344709003
Epoch: 22 , Test Loss: 0.002858919386053458
Epoch: 22 , D11: 0.8322879302890944 , D22: 0.803918222004739
Epoch: 22 , D11*: 0.8499169826894875, D22*: 0.8377967821598571, D12*: 1.1332892927111753
Epoch: 22 , Coefficient 1: 1.0211814346439814 , Coefficient 2: 1.0421417990385078 , Coefficient 3: 0.7446085371599233
Epoch: 23 , Train Loss: 0.002842053767817561
Epoch: 23 , Test Loss: 0.002863466814742424
Epoch: 23 , D11: 0.8420428862369516 , D22: 0.8252147096888345
Epoch: 23 , D11*: 0.8579542449455337, D22*: 0.8679566381049973, D12*: 1.1073848575833034
Epoch: 23 , Coefficient 1: 1.0188961381524038 , Coefficient 2: 1.0517949182368302 , Coefficient 3: 0.7792732902349168
Epoch: 24 , Train Loss: 0.002839248047675938
Epoch: 24 , Test Loss: 0.0028718607127666473
Epoch: 24 , D11: 0.8141753680304679 , D22: 0.843835899642502
Epoch: 24 , D11*: 0.8373382112661253, D22*: 0.8576363811484764, D12*: 1.1106757309159325
Epoch: 24 , Coefficient 1: 1.0284494522251264 , Coefficient 2: 1.016354461230935 , Coefficient 3: 0.7630375568829706
Epoch: 25 , Train Loss: 0.0028380651070619932
Epoch: 25 , Test Loss: 0.002866545714787207
Epoch: 25 , D11: 0.8277416959857276 , D22: 0.8016187698661542
Epoch: 25 , D11*: 0.8193579265297377, D22*: 0.8171342908347377, D12*: 1.0903553173110199
Epoch: 25 , Coefficient 1: 0.9898715148739657 , Coefficient 2: 1.0193552366184915 , Coefficient 3: 0.7504398755995941
Epoch: 26 , Train Loss: 0.0028462561337801165
Epoch: 26 , Test Loss: 0.0028738073428394273
Epoch: 26 , D11: 0.8419583229099881 , D22: 0.8206848285834611
Epoch: 26 , D11*: 0.8535197362534972, D22*: 0.7935500866709371, D12*: 1.1145616364244189
Epoch: 26 , Coefficient 1: 1.0137315743890392 , Coefficient 2: 0.9669364645629432 , Coefficient 3: 0.7388868273845912
Epoch: 27 , Train Loss: 0.002847889424301684
Epoch: 27 , Test Loss: 0.0028689721279079095
Epoch: 27 , D11: 0.8398796440678284 , D22: 0.8005636791182605
Epoch: 27 , D11*: 0.8518943946319748, D22*: 0.7709812939548215, D12*: 1.1288216129332354
Epoch: 27 , Coefficient 1: 1.0143053241604414 , Coefficient 2: 0.9630480548455296 , Coefficient 3: 0.7188362049384246
Epoch: 28 , Train Loss: 0.002840373582876054
Epoch: 28 , Test Loss: 0.002864261211361736
Epoch: 28 , D11: 0.8343122008508327 , D22: 0.8175114094898371
Epoch: 28 , D11*: 0.8298140093457943, D22*: 0.8320783907246014, D12*: 1.1104500107978674
Epoch: 28 , Coefficient 1: 0.9946085032671809 , Coefficient 2: 1.0178186886025906 , Coefficient 3: 0.7482968093612393
Epoch: 29 , Train Loss: 0.0028409937396645544
Epoch: 29 , Test Loss: 0.002860017303028144
Epoch: 29 , D11: 0.8542805571961307 , D22: 0.8103200835432784
Epoch: 29 , D11*: 0.8361388081042007, D22*: 0.7822742442128395, D12*: 1.1152755113090935
Epoch: 29 , Coefficient 1: 0.9787637106579204 , Coefficient 2: 0.9653891839780113 , Coefficient 3: 0.7255664792717325
Epoch: 30 , Train Loss: 0.0028439506582799367
Epoch: 30 , Test Loss: 0.002877239465015009
Epoch: 30 , D11: 0.8145951819667483 , D22: 0.8052604984483765
Epoch: 30 , D11*: 0.814399036298102, D22*: 0.8187543647927881, D12*: 1.1307895511240358
Epoch: 30 , Coefficient 1: 0.9997592108657299 , Coefficient 2: 1.0167571442662495 , Coefficient 3: 0.7221296834001918
Epoch: 31 , Train Loss: 0.002842709086398827
Epoch: 31 , Test Loss: 0.002864069722709246
Epoch: 31 , D11: 0.8552915096960769 , D22: 0.8148555528724191
Epoch: 31 , D11*: 0.8483571709990267, D22*: 0.8199685500126066, D12*: 1.124270143612006
Epoch: 31 , Coefficient 1: 0.991892426595566 , Coefficient 2: 1.0062747282290265 , Coefficient 3: 0.7419594527573726
Epoch: 32 , Train Loss: 0.002843274506303715
Epoch: 32 , Test Loss: 0.002869044445105828
Epoch: 32 , D11: 0.841739271064304 , D22: 0.8083910862983038
Epoch: 32 , D11*: 0.8684407472184337, D22*: 0.7707927524058173, D12*: 1.1290710078464439
Epoch: 32 , Coefficient 1: 1.0317217897180537 , Coefficient 2: 0.9534899202505404 , Coefficient 3: 0.7259213496017738
Epoch: 33 , Train Loss: 0.002843037681159331
Epoch: 33 , Test Loss: 0.0028663586755283176
Epoch: 33 , D11: 0.8398615073324359 , D22: 0.8348467197634679
Epoch: 33 , D11*: 0.8430011797974328, D22*: 0.8100874451859739, D12*: 1.1275151317782208
Epoch: 33 , Coefficient 1: 1.0037383216608762 , Coefficient 2: 0.9703427299989764 , Coefficient 3: 0.7330671573233328
Epoch: 34 , Train Loss: 0.002844995239574928
Epoch: 34 , Test Loss: 0.002878375782747753
Epoch: 34 , D11: 0.8352201018726431 , D22: 0.811748996951152
Epoch: 34 , D11*: 0.8271819710122404, D22*: 0.7983745596362367, D12*: 1.1123365817103594
Epoch: 34 , Coefficient 1: 0.9903760328057474 , Coefficient 2: 0.9835239250493092 , Coefficient 3: 0.7306945385851541
Epoch: 35 , Train Loss: 0.002834300825197716
Epoch: 35 , Test Loss: 0.002863973563653417
Epoch: 35 , D11: 0.8158413641103505 , D22: 0.8307220667078851
Epoch: 35 , D11*: 0.8182112436987358, D22*: 0.7972890814119802, D12*: 1.1255476355467087
Epoch: 35 , Coefficient 1: 1.0029048289197369 , Coefficient 2: 0.959754306962859 , Coefficient 3: 0.7176508013035025
Epoch: 36 , Train Loss: 0.00283489368550363
Epoch: 36 , Test Loss: 0.0028709441580576827
Epoch: 36 , D11: 0.8417327774349193 , D22: 0.8255942697770979
Epoch: 36 , D11*: 0.8501227369823915, D22*: 0.8091229180826572, D12*: 1.1043939204070476
Epoch: 36 , Coefficient 1: 1.0099674858487033 , Coefficient 2: 0.9800490963934527 , Coefficient 3: 0.7512019146454096
Epoch: 37 , Train Loss: 0.0028415061032865197
Epoch: 37 , Test Loss: 0.0028609359567053614
Epoch: 37 , D11: 0.8491769962381323 , D22: 0.8166666879540089
Epoch: 37 , D11*: 0.8694850724810625, D22*: 0.7797974823708935, D12*: 1.1088463700186464
Epoch: 37 , Coefficient 1: 1.0239150098659 , Coefficient 2: 0.9548540351566395 , Coefficient 3: 0.7436929945598423
Epoch: 38 , Train Loss: 0.0028426825300266498
Epoch: 38 , Test Loss: 0.0028634275478543712
Epoch: 38 , D11: 0.8297959986429679 , D22: 0.8387120658646103
Epoch: 38 , D11*: 0.7962698150970602, D22*: 0.8635455726879016, D12*: 1.1048661225491927
Epoch: 38 , Coefficient 1: 0.9595970773530653 , Coefficient 2: 1.029609096892735 , Coefficient 3: 0.7511386917880002
Epoch: 39 , Train Loss: 0.00283827474253485
Epoch: 39 , Test Loss: 0.0028674732008948925
Epoch: 39 , D11: 0.8265412272494238 , D22: 0.8284942614641541
Epoch: 39 , D11*: 0.8278998713439852, D22*: 0.8085094858098465, D12*: 1.0942900616925082
Epoch: 39 , Coefficient 1: 1.0016437705098906 , Coefficient 2: 0.9758781966467824 , Coefficient 3: 0.7477036548348263
