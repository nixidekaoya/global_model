Optimizer: SGD
Learning Rate: 0.05
Momentum: 0.9
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.0016551429521758111
Epoch: 0 , Test Loss: 0.0015116651279618964
Epoch: 0 , D11: 0.6955281685750395 , D22: 1.3336796277775704
Epoch: 0 , D11*: 0.6970333791494824, D22*: 1.3318971140284874, D12*: 1.6734507419981484
Epoch: 0 , Coefficient 1: 1.0021641259728225 , Coefficient 2: 0.9986634618149988 , Coefficient 3: 0.6062115968694031
Epoch: 1 , Train Loss: 0.0004921725863547182
Epoch: 1 , Test Loss: 0.0004454424623341766
Epoch: 1 , D11: 0.5652889502528468 , D22: 0.9922713725086615
Epoch: 1 , D11*: 0.565732497642641, D22*: 0.9912932956941207, D12*: 1.4206504883347173
Epoch: 1 , Coefficient 1: 1.000784638351052 , Coefficient 2: 0.9990143051168875 , Coefficient 3: 0.5479974864056476
Epoch: 2 , Train Loss: 0.00023341639718673838
Epoch: 2 , Test Loss: 0.00021938513555942333
Epoch: 2 , D11: 0.5434611691246386 , D22: 0.7722799209754848
Epoch: 2 , D11*: 0.5439541813026652, D22*: 0.7718515923669008, D12*: 1.406839420007643
Epoch: 2 , Coefficient 1: 1.0009071709370159 , Coefficient 2: 0.9994453713000294 , Coefficient 3: 0.46764604224070483
Epoch: 3 , Train Loss: 0.0001399793404700176
Epoch: 3 , Test Loss: 0.00013484272563364362
Epoch: 3 , D11: 0.5229266142225298 , D22: 0.6758265794239439
Epoch: 3 , D11*: 0.5232708880142087, D22*: 0.6751933061904043, D12*: 1.4319649762586748
Epoch: 3 , Coefficient 1: 1.0006583596671415 , Coefficient 2: 0.9990629648894849 , Coefficient 3: 0.41846840323422774
Epoch: 4 , Train Loss: 0.00010721995743806475
Epoch: 4 , Test Loss: 0.00010542540305177681
Epoch: 4 , D11: 0.5461168316488216 , D22: 0.6173596139708913
Epoch: 4 , D11*: 0.546434317832382, D22*: 0.6166906512050407, D12*: 1.4818078596822306
Epoch: 4 , Coefficient 1: 1.0005813521304625 , Coefficient 2: 0.9989164131395836 , Coefficient 3: 0.39246821422814276
Epoch: 5 , Train Loss: 9.500817723746878e-05
Epoch: 5 , Test Loss: 9.426922199490948e-05
Epoch: 5 , D11: 0.5438027917979321 , D22: 0.6032728294921506
Epoch: 5 , D11*: 0.544114039003266, D22*: 0.6026563752785122, D12*: 1.4686484650493334
Epoch: 5 , Coefficient 1: 1.000572353084663 , Coefficient 2: 0.9989781502108138 , Coefficient 3: 0.3904169178576226
Epoch: 6 , Train Loss: 8.95375677253469e-05
Epoch: 6 , Test Loss: 8.919559384812603e-05
Epoch: 6 , D11: 0.5636547028529509 , D22: 0.6099041092907892
Epoch: 6 , D11*: 0.5638660732039776, D22*: 0.6095133315582584, D12*: 1.4827176781111602
Epoch: 6 , Coefficient 1: 1.0003749997116265 , Coefficient 2: 0.999359280046522 , Coefficient 3: 0.3956853762804691
Epoch: 7 , Train Loss: 8.672546974448778e-05
Epoch: 7 , Test Loss: 8.654401663225145e-05
Epoch: 7 , D11: 0.5734071385939707 , D22: 0.5894046298793192
Epoch: 7 , D11*: 0.5736095872911808, D22*: 0.5890043232957919, D12*: 1.42598381642716
Epoch: 7 , Coefficient 1: 1.000353062743004 , Coefficient 2: 0.9993208289123734 , Coefficient 3: 0.40765326267865104
Epoch: 8 , Train Loss: 8.515664000406106e-05
Epoch: 8 , Test Loss: 8.508141475031152e-05
Epoch: 8 , D11: 0.5457170190869628 , D22: 0.6099842672493186
Epoch: 8 , D11*: 0.5459407833686015, D22*: 0.6096610908962014, D12*: 1.4432439937259127
Epoch: 8 , Coefficient 1: 1.0004100372057538 , Coefficient 2: 0.9994701890352441 , Coefficient 3: 0.40034875575039597
Epoch: 9 , Train Loss: 8.423781496239824e-05
Epoch: 9 , Test Loss: 8.419512369146109e-05
Epoch: 9 , D11: 0.534586238871571 , D22: 0.545532858309161
Epoch: 9 , D11*: 0.5347741356262325, D22*: 0.5451665064814932, D12*: 1.4511327926689332
Epoch: 9 , Coefficient 1: 1.0003514807172331 , Coefficient 2: 0.999328451399237 , Coefficient 3: 0.372102624778223
Epoch: 10 , Train Loss: 8.36690092819481e-05
Epoch: 10 , Test Loss: 8.36655324907042e-05
Epoch: 10 , D11: 0.5042246280785269 , D22: 0.5966527922045644
Epoch: 10 , D11*: 0.5045685590887536, D22*: 0.5964368981676161, D12*: 1.4179303303185757
Epoch: 10 , Coefficient 1: 1.000682098793027 , Coefficient 2: 0.9996381580045063 , Coefficient 3: 0.38824384869777057
Epoch: 11 , Train Loss: 8.329536043274856e-05
Epoch: 11 , Test Loss: 8.329981942806623e-05
Epoch: 11 , D11: 0.543401389419936 , D22: 0.5720324159710747
Epoch: 11 , D11*: 0.5435405936961941, D22*: 0.5718338121333029, D12*: 1.4671391194361194
Epoch: 11 , Coefficient 1: 1.0002561721021854 , Coefficient 2: 0.9996528101690974 , Coefficient 3: 0.3801188282192967
Epoch: 12 , Train Loss: 8.300998286285904e-05
Epoch: 12 , Test Loss: 8.302160459570585e-05
Epoch: 12 , D11: 0.524344684430224 , D22: 0.5722192301896243
Epoch: 12 , D11*: 0.5244779900508636, D22*: 0.5719984365351096, D12*: 1.4280908225322984
Epoch: 12 , Coefficient 1: 1.0002542328063924 , Coefficient 2: 0.9996141449939712 , Coefficient 3: 0.3838959011870461
Epoch: 13 , Train Loss: 8.276310320397898e-05
Epoch: 13 , Test Loss: 8.279701928549913e-05
Epoch: 13 , D11: 0.5384774169725888 , D22: 0.540509635248213
Epoch: 13 , D11*: 0.5385727896020482, D22*: 0.5403149744847455, D12*: 1.4497648576831064
Epoch: 13 , Coefficient 1: 1.000177115374672 , Coefficient 2: 0.9996398569964842 , Coefficient 3: 0.37209060433806573
Epoch: 14 , Train Loss: 8.255160447624802e-05
Epoch: 14 , Test Loss: 8.258397816534853e-05
Epoch: 14 , D11: 0.5225031034112525 , D22: 0.5920452660316555
Epoch: 14 , D11*: 0.5226042889070388, D22*: 0.5919743296322363, D12*: 1.4804491850102226
Epoch: 14 , Coefficient 1: 1.0001936553010418 , Coefficient 2: 0.9998801841624464 , Coefficient 3: 0.3764325820246167
Epoch: 15 , Train Loss: 8.236331819971382e-05
Epoch: 15 , Test Loss: 8.23839531673002e-05
Epoch: 15 , D11: 0.5278523618677231 , D22: 0.6231357725539965
Epoch: 15 , D11*: 0.5279193213516032, D22*: 0.6230780557162601, D12*: 1.4487820566335647
Epoch: 15 , Coefficient 1: 1.0001268526745684 , Coefficient 2: 0.9999073767864427 , Coefficient 3: 0.39722930436561205
Epoch: 16 , Train Loss: 8.219783641834509e-05
Epoch: 16 , Test Loss: 8.22174938424723e-05
Epoch: 16 , D11: 0.5398429165070439 , D22: 0.5679157461878727
Epoch: 16 , D11*: 0.5398761271005241, D22*: 0.567845088693522, D12*: 1.473684401728193
Epoch: 16 , Coefficient 1: 1.0000615189946274 , Coefficient 2: 0.9998755845478402 , Coefficient 3: 0.3758339351678755
Epoch: 17 , Train Loss: 8.204085467586992e-05
Epoch: 17 , Test Loss: 8.205371278745589e-05
Epoch: 17 , D11: 0.5558819177640674 , D22: 0.5538118911250811
Epoch: 17 , D11*: 0.5559009535445438, D22*: 0.5537609670740677, D12*: 1.3999462072978774
Epoch: 17 , Coefficient 1: 1.000034244287983 , Coefficient 2: 0.9999080481083389 , Coefficient 3: 0.39632305685531966
Epoch: 18 , Train Loss: 8.18819678050204e-05
Epoch: 18 , Test Loss: 8.192193140275775e-05
Epoch: 18 , D11: 0.5194971221288097 , D22: 0.5503377497030828
Epoch: 18 , D11*: 0.5195184624871477, D22*: 0.5503266442150699, D12*: 1.4394177552701213
Epoch: 18 , Coefficient 1: 1.0000410788769156 , Coefficient 2: 0.9999798205955909 , Coefficient 3: 0.3716242566778157
Epoch: 19 , Train Loss: 8.175075291474059e-05
Epoch: 19 , Test Loss: 8.178400409669849e-05
Epoch: 19 , D11: 0.5489254608853701 , D22: 0.5937282172399903
Epoch: 19 , D11*: 0.548929557380243, D22*: 0.5937216784944723, D12*: 1.49544823246793
Epoch: 19 , Coefficient 1: 1.0000074627525315 , Coefficient 2: 0.9999889869719376 , Coefficient 3: 0.38204305942072103
Epoch: 20 , Train Loss: 8.161622214174712e-05
Epoch: 20 , Test Loss: 8.165321480191777e-05
Epoch: 20 , D11: 0.5135664318162237 , D22: 0.5781333440616413
Epoch: 20 , D11*: 0.5135664987720585, D22*: 0.57813313562928, D12*: 1.4433903631507772
Epoch: 20 , Coefficient 1: 1.000000130374243 , Coefficient 2: 0.9999996394735515 , Coefficient 3: 0.3781719977741389
Epoch: 21 , Train Loss: 8.147593931207666e-05
Epoch: 21 , Test Loss: 8.150908692041413e-05
Epoch: 21 , D11: 0.526606092146021 , D22: 0.6074152398931498
Epoch: 21 , D11*: 0.5266060930395106, D22*: 0.6074152399021616, D12*: 1.3986199072017296
Epoch: 21 , Coefficient 1: 1.0000000016966941 , Coefficient 2: 1.0000000000148364 , Coefficient 3: 0.405407261509151
Epoch: 22 , Train Loss: 8.136255506469752e-05
Epoch: 22 , Test Loss: 8.138888986140958e-05
Epoch: 22 , D11: 0.52084503058109 , D22: 0.5787421714541979
Epoch: 22 , D11*: 0.5208450324575759, D22*: 0.5787421708296688, D12*: 1.4457053578204162
Epoch: 22 , Coefficient 1: 1.0000000036027719 , Coefficient 2: 0.9999999989208854 , Coefficient 3: 0.380294365424851
Epoch: 23 , Train Loss: 8.125942249243964e-05
Epoch: 23 , Test Loss: 8.126689570635788e-05
Epoch: 23 , D11: 0.5125643658072208 , D22: 0.5781705791569292
Epoch: 23 , D11*: 0.5125643718132229, D22*: 0.5781705715751905, D12*: 1.415257139253159
Epoch: 23 , Coefficient 1: 1.000000011717557 , Coefficient 2: 0.999999986886675 , Coefficient 3: 0.3853486808637481
Epoch: 24 , Train Loss: 8.115531539115183e-05
Epoch: 24 , Test Loss: 8.11909105934319e-05
Epoch: 24 , D11: 0.5002990348963802 , D22: 0.5897278531166837
Epoch: 24 , D11*: 0.5002990348963802, D22*: 0.5897278531166837, D12*: 1.4165736538286793
Epoch: 24 , Coefficient 1: 1.0 , Coefficient 2: 1.0 , Coefficient 3: 0.3847406328174207
Epoch: 25 , Train Loss: 8.105835471542378e-05
Epoch: 25 , Test Loss: 8.109107689087977e-05
Epoch: 25 , D11: 0.4956826526362833 , D22: 0.5934725647783075
Epoch: 25 , D11*: 0.4956826522236845, D22*: 0.593472560702743, D12*: 1.4626224250754245
Epoch: 25 , Coefficient 1: 0.9999999991676151 , Coefficient 2: 0.9999999931326826 , Coefficient 3: 0.37232958904970365
Epoch: 26 , Train Loss: 8.096827245717576e-05
Epoch: 26 , Test Loss: 8.098207154107513e-05
Epoch: 26 , D11: 0.523245644799436 , D22: 0.5947140207730371
Epoch: 26 , D11*: 0.5232456455448042, D22*: 0.5947140072430046, D12*: 1.4568573990723044
Epoch: 26 , Coefficient 1: 1.0000000014245092 , Coefficient 2: 0.9999999772495147 , Coefficient 3: 0.3836887719757959
Epoch: 27 , Train Loss: 8.08583108799212e-05
Epoch: 27 , Test Loss: 8.08920079784002e-05
Epoch: 27 , D11: 0.5420680391518463 , D22: 0.6374158858578752
Epoch: 27 , D11*: 0.5420680400623256, D22*: 0.6374158853203042, D12*: 1.4458244755581178
Epoch: 27 , Coefficient 1: 1.0000000016796402 , Coefficient 2: 0.9999999991566401 , Coefficient 3: 0.40789319357985176
Epoch: 28 , Train Loss: 8.077377231420542e-05
Epoch: 28 , Test Loss: 8.083441582275555e-05
Epoch: 28 , D11: 0.5226207024908699 , D22: 0.5937391702340008
Epoch: 28 , D11*: 0.5226207113995371, D22*: 0.5937391726019124, D12*: 1.3997553390037092
Epoch: 28 , Coefficient 1: 1.000000017046143 , Coefficient 2: 1.0000000039881345 , Coefficient 3: 0.3987696466998406
Epoch: 29 , Train Loss: 8.06969234297867e-05
Epoch: 29 , Test Loss: 8.071348091471006e-05
Epoch: 29 , D11: 0.5182430749962238 , D22: 0.5772040480284385
Epoch: 29 , D11*: 0.5182430749962238, D22*: 0.5772040480284385, D12*: 1.4207720985025838
Epoch: 29 , Coefficient 1: 1.0 , Coefficient 2: 1.0 , Coefficient 3: 0.38551120344325585
