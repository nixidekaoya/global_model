Optimizer: SGD
Learning Rate: 0.05
Momentum: 0.9
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.001960890396824107
Epoch: 0 , Test Loss: 0.0018246521288994705
Epoch: 0 , D11: 0.8197806180735074 , D22: 1.3715736853104092
Epoch: 0 , D11*: 0.8260091680788153, D22*: 1.3691433302429181, D12*: 1.4276652574356
Epoch: 0 , Coefficient 1: 1.0075978254035147 , Coefficient 2: 0.9982280535901787 , Coefficient 3: 0.7687910337836157
Epoch: 1 , Train Loss: 0.000612271084211534
Epoch: 1 , Test Loss: 0.0005390781088237417
Epoch: 1 , D11: 0.528238830515865 , D22: 0.9678233529011563
Epoch: 1 , D11*: 0.530099023467639, D22*: 0.9643666616352043, D12*: 1.2925782312565053
Epoch: 1 , Coefficient 1: 1.0035214998298354 , Coefficient 2: 0.9964283861764751 , Coefficient 3: 0.5780948684437014
Epoch: 2 , Train Loss: 0.0002609065211363486
Epoch: 2 , Test Loss: 0.00024378044496697833
Epoch: 2 , D11: 0.5242520671684869 , D22: 0.712892825056901
Epoch: 2 , D11*: 0.5253082405960124, D22*: 0.7113172343655753, D12*: 1.3512286180712627
Epoch: 2 , Coefficient 1: 1.0020146290184986 , Coefficient 2: 0.9977898631660377 , Coefficient 3: 0.45759298553295186
Epoch: 3 , Train Loss: 0.00014823892308013457
Epoch: 3 , Test Loss: 0.00014206298432691255
Epoch: 3 , D11: 0.5506392975102169 , D22: 0.631914873929625
Epoch: 3 , D11*: 0.5514691545430871, D22*: 0.6310398283292621, D12*: 1.3890488859600603
Epoch: 3 , Coefficient 1: 1.001507079201616 , Coefficient 2: 0.9986152476599873 , Coefficient 3: 0.4256541993678796
Epoch: 4 , Train Loss: 0.00011024278962795506
Epoch: 4 , Test Loss: 0.00010824584045622036
Epoch: 4 , D11: 0.5447549884490515 , D22: 0.6264759308520144
Epoch: 4 , D11*: 0.5453726376408536, D22*: 0.6253731999439164, D12*: 1.4595706932896462
Epoch: 4 , Coefficient 1: 1.0011338109882402 , Coefficient 2: 0.9982397872706805 , Coefficient 3: 0.40105828479814515
Epoch: 5 , Train Loss: 9.752497740118998e-05
Epoch: 5 , Test Loss: 9.678616477758626e-05
Epoch: 5 , D11: 0.5392877896050426 , D22: 0.64224179806174
Epoch: 5 , D11*: 0.5398195950172694, D22*: 0.6412343381752496, D12*: 1.4257086923851299
Epoch: 5 , Coefficient 1: 1.000986125446334 , Coefficient 2: 0.9984313386491959 , Coefficient 3: 0.41419889613518546
Epoch: 6 , Train Loss: 9.235065978318744e-05
Epoch: 6 , Test Loss: 9.200396928208649e-05
Epoch: 6 , D11: 0.5400565286470582 , D22: 0.5965143898208426
Epoch: 6 , D11*: 0.5406876485037846, D22*: 0.5958146175137912, D12*: 1.465164442208622
Epoch: 6 , Coefficient 1: 1.0011686181413406 , Coefficient 2: 0.9988268978603155 , Coefficient 3: 0.3878411983246012
Epoch: 7 , Train Loss: 8.966368772598799e-05
Epoch: 7 , Test Loss: 8.946586936363021e-05
Epoch: 7 , D11: 0.5490964158531723 , D22: 0.5583560550489022
Epoch: 7 , D11*: 0.549523289127396, D22*: 0.5577462146486744, D12*: 1.4924801827269378
Epoch: 7 , Coefficient 1: 1.0007774104180966 , Coefficient 2: 0.998907792984936 , Coefficient 3: 0.3709494828108732
Epoch: 8 , Train Loss: 8.798891254991761e-05
Epoch: 8 , Test Loss: 8.786045180750081e-05
Epoch: 8 , D11: 0.5629657183622548 , D22: 0.5982268083082052
Epoch: 8 , D11*: 0.5634671006516606, D22*: 0.5978338101042442, D12*: 1.4551352795141597
Epoch: 8 , Coefficient 1: 1.0008906089181848 , Coefficient 2: 0.9993430615303376 , Coefficient 3: 0.3990353773649278
Epoch: 9 , Train Loss: 8.684375114644354e-05
Epoch: 9 , Test Loss: 8.674986646947219e-05
Epoch: 9 , D11: 0.5334534227999427 , D22: 0.6063931716547069
Epoch: 9 , D11*: 0.5338719263939368, D22*: 0.6059467041070712, D12*: 1.4597093462742152
Epoch: 9 , Coefficient 1: 1.0007845175906782 , Coefficient 2: 0.9992637325608114 , Coefficient 3: 0.390426571361723
Epoch: 10 , Train Loss: 8.593654901960689e-05
Epoch: 10 , Test Loss: 8.586530755856075e-05
Epoch: 10 , D11: 0.5194520332600073 , D22: 0.6013768434112596
Epoch: 10 , D11*: 0.5197122796438226, D22*: 0.6011253366820085, D12*: 1.4275975392245286
Epoch: 10 , Coefficient 1: 1.0005010017617642 , Coefficient 2: 0.999581781819492 , Coefficient 3: 0.392560783249413
Epoch: 11 , Train Loss: 8.518694061021962e-05
Epoch: 11 , Test Loss: 8.512669118354097e-05
Epoch: 11 , D11: 0.5195261178058282 , D22: 0.5945606450905276
Epoch: 11 , D11*: 0.5198096217902647, D22*: 0.5942454085410405, D12*: 1.4933950264232225
Epoch: 11 , Coefficient 1: 1.000545697270493 , Coefficient 2: 0.9994697991666784 , Coefficient 3: 0.3729940875052794
Epoch: 12 , Train Loss: 8.450246193460771e-05
Epoch: 12 , Test Loss: 8.44527194276452e-05
Epoch: 12 , D11: 0.5364360293521774 , D22: 0.5562375274821793
Epoch: 12 , D11*: 0.5367235203481814, D22*: 0.555886358107317, D12*: 1.4635514313284206
Epoch: 12 , Coefficient 1: 1.0005359278278738 , Coefficient 2: 0.9993686701139137 , Coefficient 3: 0.3732734822526087
Epoch: 13 , Train Loss: 8.39181996707339e-05
Epoch: 13 , Test Loss: 8.389385298651178e-05
Epoch: 13 , D11: 0.5308324751554694 , D22: 0.6119400672279861
Epoch: 13 , D11*: 0.5310493109836197, D22*: 0.611713348928945, D12*: 1.418645600355464
Epoch: 13 , Coefficient 1: 1.000408482597239 , Coefficient 2: 0.9996295089810542 , Coefficient 3: 0.40276537692931474
Epoch: 14 , Train Loss: 8.344575642659038e-05
Epoch: 14 , Test Loss: 8.341256958810846e-05
Epoch: 14 , D11: 0.5229789381375034 , D22: 0.5623617063602893
Epoch: 14 , D11*: 0.5231584715901167, D22*: 0.5621977406275713, D12*: 1.4031653784113758
Epoch: 14 , Coefficient 1: 1.000343290024743 , Coefficient 2: 0.9997084336809148 , Coefficient 3: 0.3867527765852154
Epoch: 15 , Train Loss: 8.306582150544274e-05
Epoch: 15 , Test Loss: 8.30602107773302e-05
Epoch: 15 , D11: 0.5292302308446859 , D22: 0.5839001469118721
Epoch: 15 , D11*: 0.5293504833543567, D22*: 0.5837986233918049, D12*: 1.39934152309229
Epoch: 15 , Coefficient 1: 1.0002272215430303 , Coefficient 2: 0.9998261286272934 , Coefficient 3: 0.3977403258520853
Epoch: 16 , Train Loss: 8.275528259437123e-05
Epoch: 16 , Test Loss: 8.275337326194862e-05
Epoch: 16 , D11: 0.5562051330705526 , D22: 0.5680013331353523
Epoch: 16 , D11*: 0.5562697626499511, D22*: 0.5679335043593287, D12*: 1.4635711018759836
Epoch: 16 , Coefficient 1: 1.0001161973803472 , Coefficient 2: 0.9998805834210824 , Coefficient 3: 0.3840617191635899
Epoch: 17 , Train Loss: 8.249369474360718e-05
Epoch: 17 , Test Loss: 8.249699288426201e-05
Epoch: 17 , D11: 0.5116573854722343 , D22: 0.572050496157152
Epoch: 17 , D11*: 0.5116830592960478, D22*: 0.572011486998081, D12*: 1.3945597640611906
Epoch: 17 , Coefficient 1: 1.0000501777645403 , Coefficient 2: 0.9999318081894291 , Coefficient 3: 0.38854360143671063
Epoch: 18 , Train Loss: 8.226700077357236e-05
Epoch: 18 , Test Loss: 8.228589795617154e-05
Epoch: 18 , D11: 0.57505646922535 , D22: 0.5705184698674525
Epoch: 18 , D11*: 0.575065370655247, D22*: 0.5705068023831695, D12*: 1.4091219533004418
Epoch: 18 , Coefficient 1: 1.000015479227473 , Coefficient 2: 0.99997954933118 , Coefficient 3: 0.40648439631334266
Epoch: 19 , Train Loss: 8.20871669344342e-05
Epoch: 19 , Test Loss: 8.209952140896349e-05
Epoch: 19 , D11: 0.5568226368793836 , D22: 0.6002303469019191
Epoch: 19 , D11*: 0.5568235274145475, D22*: 0.600229215987335, D12*: 1.462775182468924
Epoch: 19 , Coefficient 1: 1.0000015993156617 , Coefficient 2: 0.9999981158657006 , Coefficient 3: 0.3954991707778935
Epoch: 20 , Train Loss: 8.192877135552408e-05
Epoch: 20 , Test Loss: 8.195663080259692e-05
Epoch: 20 , D11: 0.5227823057628097 , D22: 0.5696513632862416
Epoch: 20 , D11*: 0.5227823073962669, D22*: 0.5696513630788352, D12*: 1.4319220924236478
Epoch: 20 , Coefficient 1: 1.0000000031245455 , Coefficient 2: 0.9999999996359066 , Coefficient 3: 0.38145709052720417
Epoch: 21 , Train Loss: 8.179683151538483e-05
Epoch: 21 , Test Loss: 8.180938694858926e-05
Epoch: 21 , D11: 0.5480026358644864 , D22: 0.5618320094540846
Epoch: 21 , D11*: 0.5480026426450915, D22*: 0.5618320099688536, D12*: 1.4452989157599263
Epoch: 21 , Coefficient 1: 1.0000000123733075 , Coefficient 2: 1.0000000009162329 , Coefficient 3: 0.3839464073874307
Epoch: 22 , Train Loss: 8.167602303547028e-05
Epoch: 22 , Test Loss: 8.166559305536794e-05
Epoch: 22 , D11: 0.5292945958503693 , D22: 0.5854295467875071
Epoch: 22 , D11*: 0.529294595838267, D22*: 0.5854295464407888, D12*: 1.442142683845942
Epoch: 22 , Coefficient 1: 0.999999999977135 , Coefficient 2: 0.999999999407754 , Coefficient 3: 0.38648191845562807
Epoch: 23 , Train Loss: 8.155051876710786e-05
Epoch: 23 , Test Loss: 8.157174433290489e-05
Epoch: 23 , D11: 0.5568167944804023 , D22: 0.584051111826709
Epoch: 23 , D11*: 0.5568168006408597, D22*: 0.584051109473658, D12*: 1.4844351301499512
Epoch: 23 , Coefficient 1: 1.0000000110637062 , Coefficient 2: 0.9999999959711557 , Coefficient 3: 0.38427678210474314
Epoch: 24 , Train Loss: 8.14382219581603e-05
Epoch: 24 , Test Loss: 8.143733824545056e-05
Epoch: 24 , D11: 0.5379866878487648 , D22: 0.5888606923853722
Epoch: 24 , D11*: 0.537986688501523, D22*: 0.5888606916909895, D12*: 1.4422315931511915
Epoch: 24 , Coefficient 1: 1.0000000012133352 , Coefficient 2: 0.9999999988208031 , Coefficient 3: 0.3906610372230222
Epoch: 25 , Train Loss: 8.132546903798357e-05
Epoch: 25 , Test Loss: 8.13462639009231e-05
Epoch: 25 , D11: 0.5147175196986205 , D22: 0.549514185000512
Epoch: 25 , D11*: 0.5147175240193841, D22*: 0.5495141846650411, D12*: 1.4302925142880214
Epoch: 25 , Coefficient 1: 1.0000000083944367 , Coefficient 2: 0.9999999993895137 , Coefficient 3: 0.37203288769716597
Epoch: 26 , Train Loss: 8.12163281476387e-05
Epoch: 26 , Test Loss: 8.12299499855726e-05
Epoch: 26 , D11: 0.5445791933589745 , D22: 0.5732202953588934
Epoch: 26 , D11*: 0.5445791954003053, D22*: 0.5732202946153914, D12*: 1.4239783419972836
Epoch: 26 , Coefficient 1: 1.0000000037484553 , Coefficient 2: 0.9999999987029384 , Coefficient 3: 0.39249174550220406
Epoch: 27 , Train Loss: 8.111489062102919e-05
Epoch: 27 , Test Loss: 8.112960544240196e-05
Epoch: 27 , D11: 0.5279279132620468 , D22: 0.6108341690969378
Epoch: 27 , D11*: 0.5279279078296452, D22*: 0.6108341709930835, D12*: 1.4462978200208345
Epoch: 27 , Coefficient 1: 0.9999999897099556 , Coefficient 2: 1.0000000031041907 , Coefficient 3: 0.39368173797230926
Epoch: 28 , Train Loss: 8.101320243222287e-05
Epoch: 28 , Test Loss: 8.102358622127211e-05
Epoch: 28 , D11: 0.5421330300879903 , D22: 0.5525142891790811
Epoch: 28 , D11*: 0.5421330390987482, D22*: 0.5525142853593438, D12*: 1.4410541924781564
Epoch: 28 , Coefficient 1: 1.000000016620935 , Coefficient 2: 0.9999999930866271 , Coefficient 3: 0.3798078275514558
Epoch: 29 , Train Loss: 8.090932872946723e-05
Epoch: 29 , Test Loss: 8.090576047543437e-05
Epoch: 29 , D11: 0.5393855935575874 , D22: 0.5622147678450463
Epoch: 29 , D11*: 0.5393855997313356, D22*: 0.5622147618253198, D12*: 1.4180171179615235
Epoch: 29 , Coefficient 1: 1.00000001144589 , Coefficient 2: 0.9999999892928346 , Coefficient 3: 0.38842985306844025
