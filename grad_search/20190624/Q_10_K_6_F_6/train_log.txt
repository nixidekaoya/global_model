Optimizer: SGD
Learning Rate: 0.05
Momentum: 0.9
Regularization: L1
Loss: MSE
Parameters: 
key_matrix
value_matrix
linear_layer1.weight
linear_layer1.bias
linear_layer2.weight
linear_layer2.bias
Epoch: 0 , Train Loss: 0.0018838468252099117
Epoch: 0 , Test Loss: 0.00172442263844423
Epoch: 0 , D11: 0.7683503434086834 , D22: 1.2245110870589415
Epoch: 0 , D11*: 0.7720361675959845, D22*: 1.2226997549633911, D12*: 1.5331475401477583
Epoch: 0 , Coefficient 1: 1.0047970619378517 , Coefficient 2: 0.9985207711757834 , Coefficient 3: 0.650536191176725
Epoch: 1 , Train Loss: 0.0005494435241045721
Epoch: 1 , Test Loss: 0.0004896431986635435
Epoch: 1 , D11: 0.5326430228979642 , D22: 0.9699666475192713
Epoch: 1 , D11*: 0.5336107513450303, D22*: 0.967312074308785, D12*: 1.406250169318801
Epoch: 1 , Coefficient 1: 1.001816842435673 , Coefficient 2: 0.9972632324861113 , Coefficient 3: 0.5336613848661346
Epoch: 2 , Train Loss: 0.0002453421899543173
Epoch: 2 , Test Loss: 0.00022916251751157684
Epoch: 2 , D11: 0.5178303642154457 , D22: 0.7121774453766622
Epoch: 2 , D11*: 0.5187649429485234, D22*: 0.710686814925075, D12*: 1.4481184629679957
Epoch: 2 , Coefficient 1: 1.0018047970873505 , Coefficient 2: 0.9979069395397677 , Coefficient 3: 0.4244997178455179
Epoch: 3 , Train Loss: 0.0001414836246673076
Epoch: 3 , Test Loss: 0.00013585635144554542
Epoch: 3 , D11: 0.5214462490155729 , D22: 0.633836696520959
Epoch: 3 , D11*: 0.5221701172013283, D22*: 0.6327918421594576, D12*: 1.422439281199689
Epoch: 3 , Coefficient 1: 1.0013881932934066 , Coefficient 2: 0.9983515401250252 , Coefficient 3: 0.40597935343387315
Epoch: 4 , Train Loss: 0.00010766838529270898
Epoch: 4 , Test Loss: 0.00010590870720043309
Epoch: 4 , D11: 0.4977836606505538 , D22: 0.6446402412493117
Epoch: 4 , D11*: 0.4983978980034946, D22*: 0.6441099197483776, D12*: 1.3923971789323788
Epoch: 4 , Coefficient 1: 1.0012339443848721 , Coefficient 2: 0.9991773372696896 , Coefficient 3: 0.410266494014262
Epoch: 5 , Train Loss: 9.674258260602072e-05
Epoch: 5 , Test Loss: 9.614030882075896e-05
Epoch: 5 , D11: 0.5058089075818407 , D22: 0.6225929480062594
Epoch: 5 , D11*: 0.5064348859527861, D22*: 0.6217298173416648, D12*: 1.4548271573793188
Epoch: 5 , Coefficient 1: 1.0012375787803698 , Coefficient 2: 0.99861365171681 , Coefficient 3: 0.3877315245223674
Epoch: 6 , Train Loss: 9.264994525838119e-05
Epoch: 6 , Test Loss: 9.240385186276398e-05
Epoch: 6 , D11: 0.547859329585615 , D22: 0.5847514924563941
Epoch: 6 , D11*: 0.5482324775963031, D22*: 0.5842288823608938, D12*: 1.4437001042002036
Epoch: 6 , Coefficient 1: 1.0006811018641781 , Coefficient 2: 0.9991062697534896 , Coefficient 3: 0.392207965027671
Epoch: 7 , Train Loss: 9.068445433767919e-05
Epoch: 7 , Test Loss: 9.05496802472044e-05
Epoch: 7 , D11: 0.525794670097805 , D22: 0.6113714287211135
Epoch: 7 , D11*: 0.5260798995927866, D22*: 0.6111650487311244, D12*: 1.4781640466671344
Epoch: 7 , Coefficient 1: 1.0005424731576844 , Coefficient 2: 0.9996624310847814 , Coefficient 3: 0.3846815753935075
Epoch: 8 , Train Loss: 8.94525141447957e-05
Epoch: 8 , Test Loss: 8.935901166114493e-05
Epoch: 8 , D11: 0.5455894519499978 , D22: 0.551227044644688
Epoch: 8 , D11*: 0.5459806026944655, D22*: 0.5509536102880126, D12*: 1.4138827397143852
Epoch: 8 , Coefficient 1: 1.0007169323803269 , Coefficient 2: 0.9995039532995853 , Coefficient 3: 0.38791555415835505
Epoch: 9 , Train Loss: 8.844583854443046e-05
Epoch: 9 , Test Loss: 8.837470939324703e-05
Epoch: 9 , D11: 0.5478893254145358 , D22: 0.6181611827731551
Epoch: 9 , D11*: 0.5481675316221023, D22*: 0.6178063927122945, D12*: 1.4171279086238864
Epoch: 9 , Coefficient 1: 1.0005077781125886 , Coefficient 2: 0.999426055742826 , Coefficient 3: 0.4113862683950051
Epoch: 10 , Train Loss: 8.758353497323698e-05
Epoch: 10 , Test Loss: 8.752846568531825e-05
Epoch: 10 , D11: 0.5217927320631202 , D22: 0.5691978376456787
Epoch: 10 , D11*: 0.5220206170401426, D22*: 0.5689552048324295, D12*: 1.4111119236922203
Epoch: 10 , Coefficient 1: 1.0004367346707215 , Coefficient 2: 0.9995737285049205 , Coefficient 3: 0.3865660134945208
Epoch: 11 , Train Loss: 8.676330282469282e-05
Epoch: 11 , Test Loss: 8.670204315130833e-05
Epoch: 11 , D11: 0.5089888770328194 , D22: 0.5559110140830154
Epoch: 11 , D11*: 0.5092068275702227, D22*: 0.5556289163275925, D12*: 1.4312534919434428
Epoch: 11 , Coefficient 1: 1.000428202947526 , Coefficient 2: 0.9994925487204311 , Coefficient 3: 0.3719941121163369
Epoch: 12 , Train Loss: 8.600527853486709e-05
Epoch: 12 , Test Loss: 8.594468260125725e-05
Epoch: 12 , D11: 0.5379169842464452 , D22: 0.6335020164696844
Epoch: 12 , D11*: 0.5380522485005439, D22*: 0.6333415874218831, D12*: 1.4642525252722762
Epoch: 12 , Coefficient 1: 1.0002514593479293 , Coefficient 2: 0.9997467584259709 , Coefficient 3: 0.39999720529920463
Epoch: 13 , Train Loss: 8.530901463891494e-05
Epoch: 13 , Test Loss: 8.526313500769903e-05
Epoch: 13 , D11: 0.5159422729913535 , D22: 0.5892183785307358
Epoch: 13 , D11*: 0.5161325693501116, D22*: 0.5890788958534521, D12*: 1.4395404854979252
Epoch: 13 , Coefficient 1: 1.0003688326557443 , Coefficient 2: 0.9997632750736127 , Coefficient 3: 0.3838764787574836
Epoch: 14 , Train Loss: 8.470381997722142e-05
Epoch: 14 , Test Loss: 8.467565685132286e-05
Epoch: 14 , D11: 0.554691614690449 , D22: 0.5320184939103185
Epoch: 14 , D11*: 0.554807629248484, D22*: 0.5318869867906646, D12*: 1.4462934999814856
Epoch: 14 , Coefficient 1: 1.0002091514545424 , Coefficient 2: 0.9997528147589619 , Coefficient 3: 0.37568260386050956
Epoch: 15 , Train Loss: 8.416219942409953e-05
Epoch: 15 , Test Loss: 8.412423285335535e-05
Epoch: 15 , D11: 0.5444805960438902 , D22: 0.5910426436633396
Epoch: 15 , D11*: 0.5445685747893586, D22*: 0.5909216096498133, D12*: 1.476367300544999
Epoch: 15 , Coefficient 1: 1.000161582884877 , Coefficient 2: 0.9997952194908034 , Coefficient 3: 0.3845554504018096
Epoch: 16 , Train Loss: 8.37020206497982e-05
Epoch: 16 , Test Loss: 8.366975057579107e-05
Epoch: 16 , D11: 0.5309590096861 , D22: 0.5950463627145129
Epoch: 16 , D11*: 0.5310167480770979, D22*: 0.5949779000255025, D12*: 1.4600183108718485
Epoch: 16 , Coefficient 1: 1.0001087435940337 , Coefficient 2: 0.9998849456222233 , Coefficient 3: 0.38560976931522656
Epoch: 17 , Train Loss: 8.330492561181018e-05
Epoch: 17 , Test Loss: 8.327291094028624e-05
Epoch: 17 , D11: 0.5465478193807792 , D22: 0.5765634039820046
Epoch: 17 , D11*: 0.5465782434523181, D22*: 0.5765109939567111, D12*: 1.3768016847302402
Epoch: 17 , Coefficient 1: 1.000055665891364 , Coefficient 2: 0.9999090992856441 , Coefficient 3: 0.40786165860520374
Epoch: 18 , Train Loss: 8.295943472912767e-05
Epoch: 18 , Test Loss: 8.294269874604653e-05
Epoch: 18 , D11: 0.5264901188406764 , D22: 0.6116995641761512
Epoch: 18 , D11*: 0.5265071424792569, D22*: 0.611684333433138, D12*: 1.4753279283998888
Epoch: 18 , Coefficient 1: 1.0000323342033806 , Coefficient 2: 0.999975100941859 , Coefficient 3: 0.38574185914952974
Epoch: 19 , Train Loss: 8.265972589215381e-05
Epoch: 19 , Test Loss: 8.264959941589045e-05
Epoch: 19 , D11: 0.5229589179009749 , D22: 0.5918229414923376
Epoch: 19 , D11*: 0.5229603529373535, D22*: 0.5918166651853247, D12*: 1.4685876816496197
Epoch: 19 , Coefficient 1: 1.0000027440709576 , Coefficient 2: 0.9999893949582335 , Coefficient 3: 0.3795405041360837
Epoch: 20 , Train Loss: 8.238374326101618e-05
Epoch: 20 , Test Loss: 8.239795758272518e-05
Epoch: 20 , D11: 0.5019453512833201 , D22: 0.5913055055965396
Epoch: 20 , D11*: 0.5019453501063859, D22*: 0.5913055058355321, D12*: 1.4787144146194502
Epoch: 20 , Coefficient 1: 0.9999999976552543 , Coefficient 2: 1.0000000004041776 , Coefficient 3: 0.36966260865972156
Epoch: 21 , Train Loss: 8.21435635087255e-05
Epoch: 21 , Test Loss: 8.215984761482102e-05
Epoch: 21 , D11: 0.5513997294753586 , D22: 0.6063329576930238
Epoch: 21 , D11*: 0.5513997365051174, D22*: 0.606332956112217, D12*: 1.492679911822911
Epoch: 21 , Coefficient 1: 1.0000000127489341 , Coefficient 2: 0.9999999973928405 , Coefficient 3: 0.3878034009325791
Epoch: 22 , Train Loss: 8.194268009974621e-05
Epoch: 22 , Test Loss: 8.195415886293632e-05
Epoch: 22 , D11: 0.537533944520373 , D22: 0.5813324358732154
Epoch: 22 , D11*: 0.537533944520373, D22*: 0.5813324358732154, D12*: 1.4773893954221995
Epoch: 22 , Coefficient 1: 1.0 , Coefficient 2: 1.0 , Coefficient 3: 0.37866333136696345
Epoch: 23 , Train Loss: 8.173727494795457e-05
Epoch: 23 , Test Loss: 8.17469016110408e-05
Epoch: 23 , D11: 0.5217360876298394 , D22: 0.5766992159315655
Epoch: 23 , D11*: 0.521736097023234, D22*: 0.576699209152965, D12*: 1.4536021474932563
Epoch: 23 , Coefficient 1: 1.0000000180041113 , Coefficient 2: 0.999999988245865 , Coefficient 3: 0.3778321695762681
Epoch: 24 , Train Loss: 8.156607945202268e-05
Epoch: 24 , Test Loss: 8.156318545661631e-05
Epoch: 24 , D11: 0.543450315903891 , D22: 0.618690276278279
Epoch: 24 , D11*: 0.5434503254709369, D22*: 0.6186902662157588, D12*: 1.4754620850176343
Epoch: 24 , Coefficient 1: 1.0000000176042696 , Coefficient 2: 0.9999999837357713 , Coefficient 3: 0.39382258733975056
Epoch: 25 , Train Loss: 8.140255425423674e-05
Epoch: 25 , Test Loss: 8.141566249978496e-05
Epoch: 25 , D11: 0.5457413029116464 , D22: 0.5717825226825377
Epoch: 25 , D11*: 0.5457413114620826, D22*: 0.5717825242302137, D12*: 1.4704083178953573
Epoch: 25 , Coefficient 1: 1.000000015667563 , Coefficient 2: 1.0000000027067564 , Coefficient 3: 0.38000459535343356
Epoch: 26 , Train Loss: 8.125057317374739e-05
Epoch: 26 , Test Loss: 8.127091951610052e-05
Epoch: 26 , D11: 0.5134519234672024 , D22: 0.5671110640082351
Epoch: 26 , D11*: 0.5134519274038959, D22*: 0.5671110679433694, D12*: 1.4225048573917234
Epoch: 26 , Coefficient 1: 1.0000000076671123 , Coefficient 2: 1.000000006938913 , Coefficient 3: 0.3798099492358023
Epoch: 27 , Train Loss: 8.113144794951948e-05
Epoch: 27 , Test Loss: 8.11392141476972e-05
Epoch: 27 , D11: 0.5287421697212152 , D22: 0.5706721304427922
Epoch: 27 , D11*: 0.5287421714552606, D22*: 0.570672129800949, D12*: 1.396493048318295
Epoch: 27 , Coefficient 1: 1.000000003279567 , Coefficient 2: 0.9999999988752855 , Coefficient 3: 0.39363400432968937
Epoch: 28 , Train Loss: 8.101204881022568e-05
Epoch: 28 , Test Loss: 8.102119727991519e-05
Epoch: 28 , D11: 0.5399884655806074 , D22: 0.5886788673326292
Epoch: 28 , D11*: 0.5399884698780447, D22*: 0.5886788720985695, D12*: 1.4339397486765264
Epoch: 28 , Coefficient 1: 1.0000000079583873 , Coefficient 2: 1.0000000080959937 , Coefficient 3: 0.3935546605142694
Epoch: 29 , Train Loss: 8.09070244689792e-05
Epoch: 29 , Test Loss: 8.090711837576236e-05
Epoch: 29 , D11: 0.489500942223428 , D22: 0.561968247531832
Epoch: 29 , D11*: 0.489500942223428, D22*: 0.561968247531832, D12*: 1.4934209162737144
Epoch: 29 , Coefficient 1: 1.0 , Coefficient 2: 1.0 , Coefficient 3: 0.3520337696818981
